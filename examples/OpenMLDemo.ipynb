{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenML in Python \n",
    "(Work in progress)  \n",
    "Joaquin Vanschoren @joavanschoren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to...\n",
    "- Download datasets and tasks\n",
    "- Use scikit-learn to build classifiers\n",
    "- Upload the results to the server\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "Via API key (e.g. 'rgu9hw1h03g24j974hr3586g4j598fgh')  \n",
    "Always keep it secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to your OpenML account settings and see 'API authentication' to retrieve your key. \n",
    "<center><img src=\"files/openml_login.png\" width=\"800\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "Via source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! git clone https://github.com/openml/openml-python.\n",
    "#! cd openml-python\n",
    "#! python setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, ensemble\n",
    "\n",
    "import openml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# assumes you have your api key in ~/.openml/config\n",
    "# amueller's read/write key that he will throw away later\n",
    "openml.config.apikey='610344db6388d9ba34f6db45a3cf71de'\n",
    "# we also want to use the test server so as not to polute the production system\n",
    "openml.config.server = \"http://test.openml.org/api/v1/xml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List ALL the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 of 2806 datasets...\n",
      "   did             name  NumberOfInstances  NumberOfFeatures\n",
      "0    1           anneal                898                39\n",
      "1    2           anneal                898                39\n",
      "2    3         kr-vs-kp               3196                37\n",
      "3    4            labor                 57                17\n",
      "4    5       arrhythmia                452               280\n",
      "5    6           letter              20000                17\n",
      "6    7        audiology                226                70\n",
      "7    8  liver-disorders                345                 7\n",
      "8    9            autos                205                26\n",
      "9   10            lymph                148                19\n"
     ]
    }
   ],
   "source": [
    "datasets = openml.datasets.list_datasets()\n",
    "\n",
    "data = pd.DataFrame(datasets)\n",
    "print(\"First 10 of %s datasets...\" % len(datasets))\n",
    "print(data[:10][['did','name','NumberOfInstances','NumberOfFeatures']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset based on any property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 of 738 datasets...\n",
      "    did            name  NumberOfInstances  NumberOfFeatures\n",
      "2     3        kr-vs-kp               3196                37\n",
      "3     4           labor                 57                17\n",
      "12   13   breast-cancer                286                10\n",
      "14   15        breast-w                699                10\n",
      "23   24        mushroom               8124                23\n",
      "24   25           colic                368                28\n",
      "26   27           colic                368                23\n",
      "28   29        credit-a                690                16\n",
      "30   31        credit-g               1000                21\n",
      "32   33  cylinder-bands                540                40\n"
     ]
    }
   ],
   "source": [
    "bin_data = data.loc[data['NumberOfClasses'] == 2]\n",
    "print(\"First 10 of %s datasets...\" % len(bin_data))\n",
    "print(bin_data[:10][['did','name', 'NumberOfInstances','NumberOfFeatures']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset based on any property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 of 738 datasets...\n",
      "       did                          name  NumberOfInstances\n",
      "1302  1588                           w8a              64700\n",
      "2421  4533  KEGGMetabolicReactionNetwork              65554\n",
      "1305  1591                     connect-4              67557\n",
      "423    554                     mnist_784              70000\n",
      "1293  1578                      real-sim              72309\n",
      "1062  1213                       BNG(mv)              78732\n",
      "2420  4532                         higgs              98050\n",
      "247    357                vehicle_sensIT              98528\n",
      "1080  1242                   vehicleNorm              98528\n",
      "1307  1593       SensIT-Vehicle-Combined              98528\n"
     ]
    }
   ],
   "source": [
    "big_data = data.loc[data['NumberOfInstances'] > 60000]\n",
    "big_data = big_data.sort_values(by='NumberOfInstances', ascending=True)\n",
    "print(\"First 10 of %s datasets...\" % len(bin_data))\n",
    "print(big_data[:10][['did','name', 'NumberOfInstances']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download a specific dataset. This is done based on the dataset ID (called 'did' in the table above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is dataset 'iris', the target feature is called 'class'\n",
      "URL: http://www.openml.org/data/download/61/dataset_61_iris.arff\n",
      "**Author**: R.A. Fisher  \n",
      "**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Iris) - 1936 - Donated by Michael Marshall  \n",
      "**Please cite**:   \n",
      "\n",
      "**Iris Plants Database**  \n",
      "This is perhaps the best known database to be found in the pattern recognition literature.  Fisher's paper is a classic in the field and is referenced frequently to this day.  (See Duda & Hart, for example.)  The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.  One class \n"
     ]
    }
   ],
   "source": [
    "dataset = openml.datasets.get_dataset(61)\n",
    "\n",
    "print(\"This is dataset '%s', the target feature is called '%s'\" % (dataset.name, dataset.default_target_attribute))\n",
    "print(\"URL: %s\" % dataset.url)\n",
    "print(dataset.description[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'citation': None,\n",
      " 'collection_date': '1936',\n",
      " 'contributor': None,\n",
      " 'creator': 'R.A. Fisher',\n",
      " 'data_file': '/home/andy/.openml/cache/datasets/61/dataset.arff',\n",
      " 'data_pickle_file': '/home/andy/.openml/cache/datasets/61/dataset.pkl',\n",
      " 'default_target_attribute': 'class',\n",
      " 'description': '**Author**: R.A. Fisher  \\n'\n",
      "                '**Source**: '\n",
      "                '[UCI](https://archive.ics.uci.edu/ml/datasets/Iris) - 1936 - '\n",
      "                'Donated by Michael Marshall  \\n'\n",
      "                '**Please cite**:   \\n'\n",
      "                '\\n'\n",
      "                '**Iris Plants Database**  \\n'\n",
      "                'This is perhaps the best known database to be found in the '\n",
      "                \"pattern recognition literature.  Fisher's paper is a classic \"\n",
      "                'in the field and is referenced frequently to this day.  (See '\n",
      "                'Duda & Hart, for example.)  The data set contains 3 classes '\n",
      "                'of 50 instances each, where each class refers to a type of '\n",
      "                'iris plant.  One class is     linearly separable from the '\n",
      "                'other 2; the latter are NOT linearly separable from each '\n",
      "                'other.\\n'\n",
      "                '\\n'\n",
      "                'Predicted attribute: class of iris plant.  \\n'\n",
      "                'This is an exceedingly simple domain.  \\n'\n",
      "                ' \\n'\n",
      "                '### Attribute Information:\\n'\n",
      "                '    1. sepal length in cm\\n'\n",
      "                '    2. sepal width in cm\\n'\n",
      "                '    3. petal length in cm\\n'\n",
      "                '    4. petal width in cm\\n'\n",
      "                '    5. class: \\n'\n",
      "                '       -- Iris Setosa\\n'\n",
      "                '       -- Iris Versicolour\\n'\n",
      "                '       -- Iris Virginica',\n",
      " 'format': 'ARFF',\n",
      " 'id': 61,\n",
      " 'ignore_attributes': None,\n",
      " 'language': None,\n",
      " 'licence': 'Public',\n",
      " 'md5_cheksum': '3a212cce13fc6f9b94f4793285813d95',\n",
      " 'name': 'iris',\n",
      " 'original_data_url': 'https://archive.ics.uci.edu/ml/datasets/Iris',\n",
      " 'paper_url': 'http://digital.library.adelaide.edu.au/dspace/handle/2440/15227',\n",
      " 'row_id_attribute': None,\n",
      " 'tag': ['study_1', 'study_4', 'study_7', 'uci'],\n",
      " 'update_comment': None,\n",
      " 'upload_date': '2014-04-06 23:23:39',\n",
      " 'url': 'http://www.openml.org/data/download/61/dataset_61_iris.arff',\n",
      " 'version': 1,\n",
      " 'version_label': '1',\n",
      " 'visibility': 'public'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(vars(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepallength  sepalwidth  petallength  petalwidth  class\n",
      "0          5.1         3.5          1.4         0.2      0\n",
      "1          4.9         3.0          1.4         0.2      0\n",
      "2          4.7         3.2          1.3         0.2      0\n",
      "3          4.6         3.1          1.5         0.2      0\n",
      "4          5.0         3.6          1.4         0.2      0\n",
      "5          5.4         3.9          1.7         0.4      0\n",
      "6          4.6         3.4          1.4         0.3      0\n",
      "7          5.0         3.4          1.5         0.2      0\n",
      "8          4.4         2.9          1.4         0.2      0\n",
      "9          4.9         3.1          1.5         0.1      0\n"
     ]
    }
   ],
   "source": [
    "X, y, attribute_names = dataset.get_data(target=dataset.default_target_attribute, return_attribute_names=True)\n",
    "iris = pd.DataFrame(X, columns=attribute_names)\n",
    "iris['class'] = y\n",
    "print(iris[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have fun with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# iris.plot(kind='scatter', x='petallength', y='petalwidth', c='class', s=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a scikit-learn model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = openml.datasets.get_dataset(61)\n",
    "X, y = dataset.get_data(target=dataset.default_target_attribute)\n",
    "clf = ensemble.RandomForestClassifier()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper code by Gilles Louppe\n",
    "# % matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_surface(clf, X, y, \n",
    "                 xlim=(0, 7), ylim=(0, 3), n_steps=250, \n",
    "                 subplot=None):\n",
    "    if subplot is None:\n",
    "        fig = plt.figure()\n",
    "    else:\n",
    "        plt.subplot(*subplot)\n",
    "        \n",
    "    xx, yy = np.meshgrid(np.linspace(xlim[0], xlim[1], n_steps), \n",
    "                         np.linspace(ylim[0], ylim[1], n_steps))\n",
    "    \n",
    "    if hasattr(clf, \"decision_function\"):\n",
    "        z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    else:\n",
    "        z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "        \n",
    "    z = z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, z, alpha=0.8, cmap=plt.cm.RdBu_r)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "    plt.xlim(*xlim)\n",
    "    plt.ylim(*ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2d = X[:,2:4]\n",
    "clf.fit(X_2d, y)\n",
    "# plot_surface(clf, X_2d, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also ask which features are categorical to do your own encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, categorical = dataset.get_data(target=dataset.default_target_attribute,return_categorical_indicator=True)\n",
    "enc = preprocessing.OneHotEncoder(categorical_features=categorical)\n",
    "X = enc.fit_transform(X)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run benchmarks consistently (also across studies and tools), OpenML offers Tasks, which include specific train-test splits and other information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List ALL the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 of 8566 tasks:\n",
      "   tid  did        name                  task_type     estimation_procedure\n",
      "0    1    1      anneal  Supervised Classification  10-fold Crossvalidation\n",
      "1    2    2      anneal  Supervised Classification  10-fold Crossvalidation\n",
      "2    3    3    kr-vs-kp  Supervised Classification  10-fold Crossvalidation\n",
      "3    4    4       labor  Supervised Classification  10-fold Crossvalidation\n",
      "4    5    5  arrhythmia  Supervised Classification  10-fold Crossvalidation\n"
     ]
    }
   ],
   "source": [
    "task_list = openml.tasks.list_tasks()\n",
    "\n",
    "tasks = pd.DataFrame(task_list)\n",
    "print(\"First 5 of %s tasks:\" % len(tasks))\n",
    "print(tasks[:5][['tid','did','name','task_type','estimation_procedure']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenMLTask instance.\n",
      "Task ID: 10\n",
      "Task type: Supervised Classification\n",
      "Dataset id: 10\n"
     ]
    }
   ],
   "source": [
    "task = openml.tasks.get_task(10)\n",
    "print(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a scikit-learn classifier on the task (using the right splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2823\n",
      "RandomForest has run on the task.\n"
     ]
    }
   ],
   "source": [
    "from openml.runs import run_task\n",
    "\n",
    "clf = ensemble.RandomForestClassifier()\n",
    "run = run_task(task, clf)\n",
    "print(\"RandomForest has run on the task.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the run to the OpenML server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded run with id 538241\n",
      "Check it at www.openml.org/r/538241\n"
     ]
    }
   ],
   "source": [
    "import xmltodict\n",
    "\n",
    "return_code, response = run.publish()\n",
    "\n",
    "if(return_code == 200):\n",
    "    response_dict = xmltodict.parse(response)\n",
    "    run_id = response_dict['oml:upload_run']['oml:run_id']\n",
    "    print(\"Uploaded run with id %s\" % (run_id))\n",
    "    print(\"Check it at www.openml.org/r/%s\" % (run_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More to come soon..."
   ]
  }
 ],
 "metadata": {
  "colabVersion": "0.1",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
