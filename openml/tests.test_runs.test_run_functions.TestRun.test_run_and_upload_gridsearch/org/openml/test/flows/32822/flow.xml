
<oml:flow xmlns:oml="http://openml.org/openml">
  <oml:id>32822</oml:id>
<oml:uploader>1159</oml:uploader>
<oml:name>TEST703e81171fsklearn.model_selection._search.GridSearchCV(estimator=sklearn.ensemble._bagging.BaggingClassifier(estimator=sklearn.svm._classes.SVC))</oml:name>
<oml:custom_name>sklearn.GridSearchCV(BaggingClassifier)</oml:custom_name>
<oml:class_name>sklearn.model_selection._search.GridSearchCV</oml:class_name>
<oml:version>1</oml:version>
<oml:external_version>openml==0.15.1,sklearn==1.7.0</oml:external_version>
<oml:description>Exhaustive search over specified parameter values for an estimator.

Important members are fit, predict.

GridSearchCV implements a &quot;fit&quot; and a &quot;score&quot; method.
It also implements &quot;score_samples&quot;, &quot;predict&quot;, &quot;predict_proba&quot;,
&quot;decision_function&quot;, &quot;transform&quot; and &quot;inverse_transform&quot; if they are
implemented in the estimator used.

The parameters of the estimator used to apply these methods are optimized
by cross-validated grid-search over a parameter grid.</oml:description>
<oml:upload_date>2025-06-17T15:50:01</oml:upload_date>
<oml:language>English</oml:language>
<oml:dependencies>sklearn==1.7.0
numpy&gt;=1.22.0
scipy&gt;=1.8.0
joblib&gt;=1.2.0
threadpoolctl&gt;=3.1.0</oml:dependencies>
<oml:parameter>
	<oml:name>cv</oml:name>
	<oml:data_type>int</oml:data_type>
	<oml:default_value>3</oml:default_value>
	<oml:description>Determines the cross-validation splitting strategy
    Possible inputs for cv are:

    - None, to use the default 5-fold cross validation,
    - integer, to specify the number of folds in a `(Stratified)KFold`,
    - :term:`CV splitter`,
    - An iterable yielding (train, test) splits as arrays of indices

    For integer/None inputs, if the estimator is a classifier and ``y`` is
    either binary or multiclass, :class:`StratifiedKFold` is used. In all
    other cases, :class:`KFold` is used. These splitters are instantiated
    with `shuffle=False` so the splits will be the same across calls

    Refer :ref:`User Guide &lt;cross_validation&gt;` for the various
    cross-validation strategies that can be used here

    .. versionchanged:: 0.22
        ``cv`` default value if None changed from 3-fold to 5-fold</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>error_score</oml:name>
	<oml:data_type>'raise' or numeric</oml:data_type>
	<oml:default_value>NaN</oml:default_value>
	<oml:description>Value to assign to the score if an error occurs in estimator fitting
    If set to 'raise', the error is raised. If a numeric value is given,
    FitFailedWarning is raised. This parameter does not affect the refit
    step, which will always raise the error</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>estimator</oml:name>
	<oml:data_type>estimator object</oml:data_type>
	<oml:default_value>{&quot;oml-python:serialized_object&quot;: &quot;component_reference&quot;, &quot;value&quot;: {&quot;key&quot;: &quot;estimator&quot;, &quot;step_name&quot;: null}}</oml:default_value>
	<oml:description>This is assumed to implement the scikit-learn estimator interface
    Either estimator needs to provide a ``score`` function,
    or ``scoring`` must be passed</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>n_jobs</oml:name>
	<oml:data_type>int</oml:data_type>
	<oml:default_value>null</oml:default_value>
	<oml:description>Number of jobs to run in parallel
    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context
    ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`
    for more details

    .. versionchanged:: v0.20
       `n_jobs` default changed from 1 to None</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>param_grid</oml:name>
	<oml:data_type>dict or list of dictionaries</oml:data_type>
	<oml:default_value>{&quot;estimator__C&quot;: [0.01, 0.1, 10], &quot;estimator__gamma&quot;: [0.01, 0.1, 10]}</oml:default_value>
	<oml:description>Dictionary with parameters names (`str`) as keys and lists of
    parameter settings to try as values, or a list of such
    dictionaries, in which case the grids spanned by each dictionary
    in the list are explored. This enables searching over any sequence
    of parameter settings</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>pre_dispatch</oml:name>
	<oml:data_type>int</oml:data_type>
	<oml:default_value>&quot;2*n_jobs&quot;</oml:default_value>
	<oml:description>Controls the number of jobs that get dispatched during parallel
    execution. Reducing this number can be useful to avoid an
    explosion of memory consumption when more jobs get dispatched
    than CPUs can process. This parameter can be:

    - None, in which case all the jobs are immediately created and spawned. Use
      this for lightweight and fast-running jobs, to avoid delays due to on-demand
      spawning of the jobs
    - An int, giving the exact number of total jobs that are spawned
    - A str, giving an expression as a function of n_jobs, as in '2*n_jobs'</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>refit</oml:name>
	<oml:data_type>bool</oml:data_type>
	<oml:default_value>true</oml:default_value>
	<oml:description>Refit an estimator using the best found parameters on the whole
    dataset

    For multiple metric evaluation, this needs to be a `str` denoting the
    scorer that would be used to find the best parameters for refitting
    the estimator at the end

    Where there are considerations other than maximum score in
    choosing a best estimator, ``refit`` can be set to a function which
    returns the selected ``best_index_`` given ``cv_results_``. In that
    case, the ``best_estimator_`` and ``best_params_`` will be set
    according to the returned ``best_index_`` while the ``best_score_``
    attribute will not be available

    The refitted estimator is made available at the ``best_estimator_``
    attribute and permits using ``predict`` directly on this
    ``GridSearchCV`` instance

    Also for multiple metric evaluation, the attributes ``best_index_``,
    ``best_score_`` and ``best_params_`` will only be available if
    ``refit`` is set and all of them will be determined w.r.t this specific
    s...</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>return_train_score</oml:name>
	<oml:data_type>bool</oml:data_type>
	<oml:default_value>false</oml:default_value>
	<oml:description>If ``False``, the ``cv_results_`` attribute will not include training
    scores
    Computing training scores is used to get insights on how different
    parameter settings impact the overfitting/underfitting trade-off
    However computing the scores on the training set can be computationally
    expensive and is not strictly required to select the parameters that
    yield the best generalization performance

    .. versionadded:: 0.19

    .. versionchanged:: 0.21
        Default value was changed from ``True`` to ``False``</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>scoring</oml:name>
	<oml:data_type>str</oml:data_type>
	<oml:default_value>null</oml:default_value>
	<oml:description>Strategy to evaluate the performance of the cross-validated model on
    the test set

    If `scoring` represents a single score, one can use:

    - a single string (see :ref:`scoring_string_names`);
    - a callable (see :ref:`scoring_callable`) that returns a single value;
    - `None`, the `estimator`'s
      :ref:`default evaluation criterion &lt;scoring_api_overview&gt;` is used

    If `scoring` represents multiple scores, one can use:

    - a list or tuple of unique strings;
    - a callable returning a dictionary where the keys are the metric
      names and the values are the metric scores;
    - a dictionary with metric names as keys and callables as values

    See :ref:`multimetric_grid_search` for an example</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>verbose</oml:name>
	<oml:data_type>int</oml:data_type>
	<oml:default_value>0</oml:default_value>
	<oml:description>Controls the verbosity: the higher, the more messages</oml:description>
</oml:parameter>
<oml:component>
  <oml:identifier>estimator</oml:identifier>
	
<oml:flow xmlns:oml="http://openml.org/openml">
  <oml:id>32823</oml:id>
<oml:uploader>1159</oml:uploader>
<oml:name>TEST703e81171fsklearn.ensemble._bagging.BaggingClassifier(estimator=sklearn.svm._classes.SVC)</oml:name>
<oml:custom_name>sklearn.BaggingClassifier</oml:custom_name>
<oml:class_name>sklearn.ensemble._bagging.BaggingClassifier</oml:class_name>
<oml:version>1</oml:version>
<oml:external_version>openml==0.15.1,sklearn==1.7.0</oml:external_version>
<oml:description>A Bagging classifier.

A Bagging classifier is an ensemble meta-estimator that fits base
classifiers each on random subsets of the original dataset and then
aggregate their individual predictions (either by voting or by averaging)
to form a final prediction. Such a meta-estimator can typically be used as
a way to reduce the variance of a black-box estimator (e.g., a decision
tree), by introducing randomization into its construction procedure and
then making an ensemble out of it.

This algorithm encompasses several works from the literature. When random
subsets of the dataset are drawn as random subsets of the samples, then
this algorithm is known as Pasting [1]_. If samples are drawn with
replacement, then the method is known as Bagging [2]_. When random subsets
of the dataset are drawn as random subsets of the features, then the method
is known as Random Subspaces [3]_. Finally, when base estimators are built
on subsets of both samples and features, then the method is known as
Random Patches [4]_.</oml:description>
<oml:upload_date>2025-06-17T15:50:01</oml:upload_date>
<oml:language>English</oml:language>
<oml:dependencies>sklearn==1.7.0
numpy&gt;=1.22.0
scipy&gt;=1.8.0
joblib&gt;=1.2.0
threadpoolctl&gt;=3.1.0</oml:dependencies>
<oml:parameter>
	<oml:name>bootstrap</oml:name>
	<oml:data_type>bool</oml:data_type>
	<oml:default_value>true</oml:default_value>
	<oml:description>Whether samples are drawn with replacement. If False, sampling
    without replacement is performed</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>bootstrap_features</oml:name>
	<oml:data_type>bool</oml:data_type>
	<oml:default_value>false</oml:default_value>
	<oml:description>Whether features are drawn with replacement</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>estimator</oml:name>
	<oml:data_type>object</oml:data_type>
	<oml:default_value>{&quot;oml-python:serialized_object&quot;: &quot;component_reference&quot;, &quot;value&quot;: {&quot;key&quot;: &quot;estimator&quot;, &quot;step_name&quot;: null}}</oml:default_value>
	<oml:description>The base estimator to fit on random subsets of the dataset
    If None, then the base estimator is a
    :class:`~sklearn.tree.DecisionTreeClassifier`

    .. versionadded:: 1.2
       `base_estimator` was renamed to `estimator`</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>max_features</oml:name>
	<oml:data_type>int or float</oml:data_type>
	<oml:default_value>1.0</oml:default_value>
	<oml:description>The number of features to draw from X to train each base estimator (
    without replacement by default, see `bootstrap_features` for more
    details)

    - If int, then draw `max_features` features
    - If float, then draw `max(1, int(max_features * n_features_in_))` features</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>max_samples</oml:name>
	<oml:data_type>int or float</oml:data_type>
	<oml:default_value>1.0</oml:default_value>
	<oml:description>The number of samples to draw from X to train each base estimator (with
    replacement by default, see `bootstrap` for more details)

    - If int, then draw `max_samples` samples
    - If float, then draw `max_samples * X.shape[0]` samples</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>n_estimators</oml:name>
	<oml:data_type>int</oml:data_type>
	<oml:default_value>10</oml:default_value>
	<oml:description>The number of base estimators in the ensemble</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>n_jobs</oml:name>
	<oml:data_type>int</oml:data_type>
	<oml:default_value>null</oml:default_value>
	<oml:description>The number of jobs to run in parallel for both :meth:`fit` and
    :meth:`predict`. ``None`` means 1 unless in a
    :obj:`joblib.parallel_backend` context. ``-1`` means using all
    processors. See :term:`Glossary &lt;n_jobs&gt;` for more details</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>oob_score</oml:name>
	<oml:data_type>bool</oml:data_type>
	<oml:default_value>false</oml:default_value>
	<oml:description>Whether to use out-of-bag samples to estimate
    the generalization error. Only available if bootstrap=True</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>random_state</oml:name>
	<oml:data_type>int</oml:data_type>
	<oml:default_value>null</oml:default_value>
	<oml:description>Controls the random resampling of the original dataset
    (sample wise and feature wise)
    If the base estimator accepts a `random_state` attribute, a different
    seed is generated for each instance in the ensemble
    Pass an int for reproducible output across multiple function calls
    See :term:`Glossary &lt;random_state&gt;`</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>verbose</oml:name>
	<oml:data_type>int</oml:data_type>
	<oml:default_value>0</oml:default_value>
	<oml:description>Controls the verbosity when fitting and predicting.</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>warm_start</oml:name>
	<oml:data_type>bool</oml:data_type>
	<oml:default_value>false</oml:default_value>
	<oml:description>When set to True, reuse the solution of the previous call to fit
    and add more estimators to the ensemble, otherwise, just fit
    a whole new ensemble. See :term:`the Glossary &lt;warm_start&gt;`

    .. versionadded:: 0.17
       *warm_start* constructor parameter</oml:description>
</oml:parameter>
<oml:component>
  <oml:identifier>estimator</oml:identifier>
	
<oml:flow xmlns:oml="http://openml.org/openml">
  <oml:id>32824</oml:id>
<oml:uploader>1159</oml:uploader>
<oml:name>TEST703e81171fsklearn.svm._classes.SVC</oml:name>
<oml:custom_name>sklearn.SVC</oml:custom_name>
<oml:class_name>sklearn.svm._classes.SVC</oml:class_name>
<oml:version>1</oml:version>
<oml:external_version>openml==0.15.1,sklearn==1.7.0</oml:external_version>
<oml:description>C-Support Vector Classification.

The implementation is based on libsvm. The fit time scales at least
quadratically with the number of samples and may be impractical
beyond tens of thousands of samples. For large datasets
consider using :class:`~sklearn.svm.LinearSVC` or
:class:`~sklearn.linear_model.SGDClassifier` instead, possibly after a
:class:`~sklearn.kernel_approximation.Nystroem` transformer or
other :ref:`kernel_approximation`.

The multiclass support is handled according to a one-vs-one scheme.

For details on the precise mathematical formulation of the provided
kernel functions and how `gamma`, `coef0` and `degree` affect each
other, see the corresponding section in the narrative documentation:
:ref:`svm_kernels`.

To learn how to tune SVC's hyperparameters, see the following example:
:ref:`sphx_glr_auto_examples_model_selection_plot_nested_cross_validation_iris.py`</oml:description>
<oml:upload_date>2025-06-17T15:50:01</oml:upload_date>
<oml:language>English</oml:language>
<oml:dependencies>sklearn==1.7.0
numpy&gt;=1.22.0
scipy&gt;=1.8.0
joblib&gt;=1.2.0
threadpoolctl&gt;=3.1.0</oml:dependencies>
<oml:parameter>
	<oml:name>C</oml:name>
	<oml:data_type>float</oml:data_type>
	<oml:default_value>1.0</oml:default_value>
	<oml:description>Regularization parameter. The strength of the regularization is
    inversely proportional to C. Must be strictly positive. The penalty
    is a squared l2 penalty. For an intuitive visualization of the effects
    of scaling the regularization parameter C, see
    :ref:`sphx_glr_auto_examples_svm_plot_svm_scale_c.py`

kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'} or callable,          default='rbf'
    Specifies the kernel type to be used in the algorithm. If
    none is given, 'rbf' will be used. If a callable is given it is used to
    pre-compute the kernel matrix from data matrices; that matrix should be
    an array of shape ``(n_samples, n_samples)``. For an intuitive
    visualization of different kernel types see
    :ref:`sphx_glr_auto_examples_svm_plot_svm_kernels.py`</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>break_ties</oml:name>
	<oml:data_type>bool</oml:data_type>
	<oml:default_value>false</oml:default_value>
	<oml:description>If true, ``decision_function_shape='ovr'``, and number of classes &gt; 2,
    :term:`predict` will break ties according to the confidence values of
    :term:`decision_function`; otherwise the first class among the tied
    classes is returned. Please note that breaking ties comes at a
    relatively high computational cost compared to a simple predict. See
    :ref:`sphx_glr_auto_examples_svm_plot_svm_tie_breaking.py` for an
    example of its usage with ``decision_function_shape='ovr'``

    .. versionadded:: 0.22</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>cache_size</oml:name>
	<oml:data_type>float</oml:data_type>
	<oml:default_value>200</oml:default_value>
	<oml:description>Specify the size of the kernel cache (in MB)</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>class_weight</oml:name>
	<oml:data_type>dict or</oml:data_type>
	<oml:default_value>null</oml:default_value>
	<oml:description>Set the parameter C of class i to class_weight[i]*C for
    SVC. If not given, all classes are supposed to have
    weight one
    The &quot;balanced&quot; mode uses the values of y to automatically adjust
    weights inversely proportional to class frequencies in the input data
    as ``n_samples / (n_classes * np.bincount(y))``</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>coef0</oml:name>
	<oml:data_type>float</oml:data_type>
	<oml:default_value>0.0</oml:default_value>
	<oml:description>Independent term in kernel function
    It is only significant in 'poly' and 'sigmoid'</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>decision_function_shape</oml:name>
	<oml:data_type></oml:data_type>
	<oml:default_value>&quot;ovr&quot;</oml:default_value>
	<oml:description></oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>degree</oml:name>
	<oml:data_type>int</oml:data_type>
	<oml:default_value>3</oml:default_value>
	<oml:description>Degree of the polynomial kernel function ('poly')
    Must be non-negative. Ignored by all other kernels

gamma : {'scale', 'auto'} or float, default='scale'
    Kernel coefficient for 'rbf', 'poly' and 'sigmoid'

    - if ``gamma='scale'`` (default) is passed then it uses
      1 / (n_features * X.var()) as value of gamma,
    - if 'auto', uses 1 / n_features
    - if float, must be non-negative

    .. versionchanged:: 0.22
       The default value of ``gamma`` changed from 'auto' to 'scale'</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>gamma</oml:name>
	<oml:data_type></oml:data_type>
	<oml:default_value>&quot;scale&quot;</oml:default_value>
	<oml:description></oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>kernel</oml:name>
	<oml:data_type></oml:data_type>
	<oml:default_value>&quot;rbf&quot;</oml:default_value>
	<oml:description></oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>max_iter</oml:name>
	<oml:data_type>int</oml:data_type>
	<oml:default_value>-1</oml:default_value>
	<oml:description>Hard limit on iterations within solver, or -1 for no limit

decision_function_shape : {'ovo', 'ovr'}, default='ovr'
    Whether to return a one-vs-rest ('ovr') decision function of shape
    (n_samples, n_classes) as all other classifiers, or the original
    one-vs-one ('ovo') decision function of libsvm which has shape
    (n_samples, n_classes * (n_classes - 1) / 2). However, note that
    internally, one-vs-one ('ovo') is always used as a multi-class strategy
    to train models; an ovr matrix is only constructed from the ovo matrix
    The parameter is ignored for binary classification

    .. versionchanged:: 0.19
        decision_function_shape is 'ovr' by default

    .. versionadded:: 0.17
       *decision_function_shape='ovr'* is recommended

    .. versionchanged:: 0.17
       Deprecated *decision_function_shape='ovo' and None*</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>probability</oml:name>
	<oml:data_type>bool</oml:data_type>
	<oml:default_value>false</oml:default_value>
	<oml:description>Whether to enable probability estimates. This must be enabled prior
    to calling `fit`, will slow down that method as it internally uses
    5-fold cross-validation, and `predict_proba` may be inconsistent with
    `predict`. Read more in the :ref:`User Guide &lt;scores_probabilities&gt;`</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>random_state</oml:name>
	<oml:data_type>int</oml:data_type>
	<oml:default_value>null</oml:default_value>
	<oml:description>Controls the pseudo random number generation for shuffling the data for
    probability estimates. Ignored when `probability` is False
    Pass an int for reproducible output across multiple function calls
    See :term:`Glossary &lt;random_state&gt;`.</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>shrinking</oml:name>
	<oml:data_type>bool</oml:data_type>
	<oml:default_value>true</oml:default_value>
	<oml:description>Whether to use the shrinking heuristic
    See the :ref:`User Guide &lt;shrinking_svm&gt;`</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>tol</oml:name>
	<oml:data_type>float</oml:data_type>
	<oml:default_value>0.001</oml:default_value>
	<oml:description>Tolerance for stopping criterion</oml:description>
</oml:parameter>
<oml:parameter>
	<oml:name>verbose</oml:name>
	<oml:data_type>bool</oml:data_type>
	<oml:default_value>false</oml:default_value>
	<oml:description>Enable verbose output. Note that this setting takes advantage of a
    per-process runtime setting in libsvm that, if enabled, may not work
    properly in a multithreaded context</oml:description>
</oml:parameter>
<oml:tag>openml-python</oml:tag>
<oml:tag>python</oml:tag>
<oml:tag>scikit-learn</oml:tag>
<oml:tag>sklearn</oml:tag>
<oml:tag>sklearn_1.7.0</oml:tag>
</oml:flow>
</oml:component>
<oml:tag>openml-python</oml:tag>
<oml:tag>python</oml:tag>
<oml:tag>scikit-learn</oml:tag>
<oml:tag>sklearn</oml:tag>
<oml:tag>sklearn_1.7.0</oml:tag>
</oml:flow>
</oml:component>
<oml:tag>openml-python</oml:tag>
<oml:tag>python</oml:tag>
<oml:tag>scikit-learn</oml:tag>
<oml:tag>sklearn</oml:tag>
<oml:tag>sklearn_1.7.0</oml:tag>
</oml:flow>
