{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Benchmark suites\n\nHow to list, download and upload benchmark suites.\n\nIf you want to learn more about benchmark suites, check out our\nbrief introductory tutorial `sphx_glr_examples_20_basic_simple_suites_tutorial.py` or the\n[OpenML benchmark docs](https://docs.openml.org/benchmark/#benchmarking-suites).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# License: BSD 3-Clause\n\nimport uuid\n\nimport numpy as np\n\nimport openml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Listing suites\n\n* Use the output_format parameter to select output type\n* Default gives ``dict``, but we'll use ``dataframe`` to obtain an\n  easier-to-work-with data structure\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "suites = openml.study.list_suites(output_format=\"dataframe\", status=\"all\")\nprint(suites.head(n=10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Downloading suites\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is done based on the dataset ID.\nhttps://www.openml.org/api/v1/study/99\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "suite = openml.study.get_suite(\"OpenML-CC18\")\nprint(suite)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Suites also feature a description:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(suite.description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Suites are a container for tasks:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(suite.tasks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And we can use the task listing functionality to learn more about them:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tasks = openml.tasks.list_tasks(output_format=\"dataframe\")\n\n# Using ``@`` in `pd.DataFrame.query <\n# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.query.html>`_\n# accesses variables outside of the current dataframe.\ntasks = tasks.query(\"tid in @suite.tasks\")\nprint(tasks.describe().transpose())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll use the test server for the rest of this tutorial.\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>.. include:: ../../test_server_usage_warning.txt</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "openml.config.start_using_configuration_for_example()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Uploading suites\n\nUploading suites is as simple as uploading any kind of other OpenML\nentity - the only reason why we need so much code in this example is\nbecause we upload some random data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We'll take a random subset of at least ten tasks of all available tasks on\n# the test server:\nall_tasks = list(openml.tasks.list_tasks(output_format=\"dataframe\")[\"tid\"])\ntask_ids_for_suite = sorted(np.random.choice(all_tasks, replace=False, size=20))\n\n# The study needs a machine-readable and unique alias. To obtain this,\n# we simply generate a random uuid.\n\nalias = uuid.uuid4().hex\n\nnew_suite = openml.study.create_benchmark_suite(\n    name=\"Test-Suite\",\n    description=\"Test suite for the Python tutorial on benchmark suites\",\n    task_ids=task_ids_for_suite,\n    alias=alias,\n)\nnew_suite.publish()\nprint(new_suite)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "openml.config.stop_using_configuration_for_example()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}