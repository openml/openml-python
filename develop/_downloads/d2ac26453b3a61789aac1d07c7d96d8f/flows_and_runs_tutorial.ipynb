{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Flows and Runs\n\nHow to train/run a model and how to upload the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# License: BSD 3-Clause\n\nimport openml\nfrom sklearn import compose, ensemble, impute, neighbors, preprocessing, pipeline, tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll use the test server for the rest of this tutorial.\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>.. include:: ../../test_server_usage_warning.txt</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "openml.config.start_using_configuration_for_example()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train machine learning models\n\nTrain a scikit-learn model on the data manually.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# NOTE: We are using dataset 68 from the test server: https://test.openml.org/d/68\ndataset = openml.datasets.get_dataset(68)\nX, y, categorical_indicator, attribute_names = dataset.get_data(\n    target=dataset.default_target_attribute\n)\nclf = neighbors.KNeighborsClassifier(n_neighbors=1)\nclf.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also ask for meta-data to automatically preprocess the data.\n\n* e.g. categorical features -> do feature encoding\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = openml.datasets.get_dataset(17)\nX, y, categorical_indicator, attribute_names = dataset.get_data(\n    target=dataset.default_target_attribute\n)\nprint(f\"Categorical features: {categorical_indicator}\")\ntransformer = compose.ColumnTransformer(\n    [(\"one_hot_encoder\", preprocessing.OneHotEncoder(categories=\"auto\"), categorical_indicator)]\n)\nX = transformer.fit_transform(X)\nclf.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Runs: Easily explore models\nWe can run (many) scikit-learn algorithms on (many) OpenML tasks.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Get a task\ntask = openml.tasks.get_task(403)\n\n# Build any classifier or pipeline\nclf = tree.DecisionTreeClassifier()\n\n# Run the flow\nrun = openml.runs.run_model_on_task(clf, task)\n\nprint(run)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Share the run on the OpenML server\n\nSo far the run is only available locally. By calling the publish function,\nthe run is sent to the OpenML server:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "myrun = run.publish()\n# For this tutorial, our configuration publishes to the test server\n# as to not pollute the main server.\nprint(f\"Uploaded to {myrun.openml_url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now also inspect the flow object which was automatically created:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "flow = openml.flows.get_flow(run.flow_id)\nprint(flow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### It also works with pipelines\n\nWhen you need to handle 'dirty' data, build pipelines to model then automatically.\nTo demonstrate this using the dataset [credit-a](https://test.openml.org/d/16) via\n[task](https://test.openml.org/t/96) as it contains both numerical and categorical\nvariables and missing values in both.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "task = openml.tasks.get_task(96)\n\n# OpenML helper functions for sklearn can be plugged in directly for complicated pipelines\nfrom openml.extensions.sklearn import cat, cont\n\npipe = pipeline.Pipeline(\n    steps=[\n        (\n            \"Preprocessing\",\n            compose.ColumnTransformer(\n                [\n                    (\n                        \"categorical\",\n                        preprocessing.OneHotEncoder(sparse=False, handle_unknown=\"ignore\"),\n                        cat,  # returns the categorical feature indices\n                    ),\n                    (\n                        \"continuous\",\n                        impute.SimpleImputer(strategy=\"median\"),\n                        cont,\n                    ),  # returns the numeric feature indices\n                ]\n            ),\n        ),\n        (\"Classifier\", ensemble.RandomForestClassifier(n_estimators=10)),\n    ]\n)\n\nrun = openml.runs.run_model_on_task(pipe, task, avoid_duplicate_runs=False)\nmyrun = run.publish()\nprint(f\"Uploaded to {myrun.openml_url}\")\n\n\n# The above pipeline works with the helper functions that internally deal with pandas DataFrame.\n# In the case, pandas is not available, or a NumPy based data processing is the requirement, the\n# above pipeline is presented below to work with NumPy.\n\n# Extracting the indices of the categorical columns\nfeatures = task.get_dataset().features\ncategorical_feature_indices = []\nnumeric_feature_indices = []\nfor i in range(len(features)):\n    if features[i].name == task.target_name:\n        continue\n    if features[i].data_type == \"nominal\":\n        categorical_feature_indices.append(i)\n    else:\n        numeric_feature_indices.append(i)\n\npipe = pipeline.Pipeline(\n    steps=[\n        (\n            \"Preprocessing\",\n            compose.ColumnTransformer(\n                [\n                    (\n                        \"categorical\",\n                        preprocessing.OneHotEncoder(sparse=False, handle_unknown=\"ignore\"),\n                        categorical_feature_indices,\n                    ),\n                    (\n                        \"continuous\",\n                        impute.SimpleImputer(strategy=\"median\"),\n                        numeric_feature_indices,\n                    ),\n                ]\n            ),\n        ),\n        (\"Classifier\", ensemble.RandomForestClassifier(n_estimators=10)),\n    ]\n)\n\nrun = openml.runs.run_model_on_task(pipe, task, avoid_duplicate_runs=False)\nmyrun = run.publish()\nprint(f\"Uploaded to {myrun.openml_url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running flows on tasks offline for later upload\nFor those scenarios where there is no access to internet, it is possible to run\na model on a task without uploading results or flows to the server immediately.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# To perform the following line offline, it is required to have been called before\n# such that the task is cached on the local openml cache directory:\ntask = openml.tasks.get_task(96)\n\n# The following lines can then be executed offline:\nrun = openml.runs.run_model_on_task(\n    pipe,\n    task,\n    avoid_duplicate_runs=False,\n    upload_flow=False,\n)\n\n# The run may be stored offline, and the flow will be stored along with it:\nrun.to_filesystem(directory=\"myrun\")\n\n# They may be loaded and uploaded at a later time\nrun = openml.runs.OpenMLRun.from_filesystem(directory=\"myrun\")\nrun.publish()\n\n# Publishing the run will automatically upload the related flow if\n# it does not yet exist on the server."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively, one can also directly run flows.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Get a task\ntask = openml.tasks.get_task(403)\n\n# Build any classifier or pipeline\nclf = tree.ExtraTreeClassifier()\n\n# Obtain the scikit-learn extension interface to convert the classifier\n# into a flow object.\nextension = openml.extensions.get_extension_by_model(clf)\nflow = extension.model_to_flow(clf)\n\nrun = openml.runs.run_flow_on_task(flow, task)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Challenge\n\nTry to build the best possible models on several OpenML tasks,\ncompare your results with the rest of the class and learn from\nthem. Some tasks you could try (or browse openml.org):\n\n* EEG eye state: data_id:[1471](https://www.openml.org/d/1471),\n  task_id:[14951](https://www.openml.org/t/14951)\n* Volcanoes on Venus: data_id:[1527](https://www.openml.org/d/1527),\n  task_id:[10103](https://www.openml.org/t/10103)\n* Walking activity: data_id:[1509](https://www.openml.org/d/1509),\n  task_id:[9945](https://www.openml.org/t/9945), 150k instances.\n* Covertype (Satellite): data_id:[150](https://www.openml.org/d/150),\n  task_id:[218](https://www.openml.org/t/218), 500k instances.\n* Higgs (Physics): data_id:[23512](https://www.openml.org/d/23512),\n  task_id:[52950](https://www.openml.org/t/52950), 100k instances, missing values.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Easy benchmarking:\nfor task_id in [115]:  # Add further tasks. Disclaimer: they might take some time\n    task = openml.tasks.get_task(task_id)\n    data = openml.datasets.get_dataset(task.dataset_id)\n    clf = neighbors.KNeighborsClassifier(n_neighbors=5)\n\n    run = openml.runs.run_model_on_task(clf, task, avoid_duplicate_runs=False)\n    myrun = run.publish()\n    print(f\"kNN on {data.name}: {myrun.openml_url}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "openml.config.stop_using_configuration_for_example()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}