{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Feurer et al. (2015)\n\nA tutorial on how to get the datasets used in the paper introducing *Auto-sklearn* by Feurer et al..\n\nAuto-sklearn website: https://automl.github.io/auto-sklearn/\n\n## Publication\n\n| Efficient and Robust Automated Machine Learning\n| Matthias Feurer, Aaron Klein, Katharina Eggensperger, Jost Springenberg, Manuel Blum and Frank Hutter\n| In *Advances in Neural Information Processing Systems 28*, 2015\n| Available at https://papers.nips.cc/paper/5872-efficient-and-robust-automated-machine-learning.pdf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# License: BSD 3-Clause\n\nimport pandas as pd\n\nimport openml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "List of dataset IDs given in the supplementary material of Feurer et al.:\nhttps://papers.nips.cc/paper/5872-efficient-and-robust-automated-machine-learning-supplemental.zip\nfmt: off\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_ids = [\n    3, 6, 12, 14, 16, 18, 21, 22, 23, 24, 26, 28, 30, 31, 32, 36, 38, 44, 46,\n    57, 60, 179, 180, 181, 182, 184, 185, 273, 293, 300, 351, 354, 357, 389,\n    390, 391, 392, 393, 395, 396, 398, 399, 401, 554, 679, 715, 718, 720, 722,\n    723, 727, 728, 734, 735, 737, 740, 741, 743, 751, 752, 761, 772, 797, 799,\n    803, 806, 807, 813, 816, 819, 821, 822, 823, 833, 837, 843, 845, 846, 847,\n    849, 866, 871, 881, 897, 901, 903, 904, 910, 912, 913, 914, 917, 923, 930,\n    934, 953, 958, 959, 962, 966, 971, 976, 977, 978, 979, 980, 991, 993, 995,\n    1000, 1002, 1018, 1019, 1020, 1021, 1036, 1040, 1041, 1049, 1050, 1053,\n    1056, 1067, 1068, 1069, 1111, 1112, 1114, 1116, 1119, 1120, 1128, 1130,\n    1134, 1138, 1139, 1142, 1146, 1161, 1166,\n]\n# fmt: on"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset IDs could be used directly to load the dataset and split the data into a training set\nand a test set. However, to be reproducible, we will first obtain the respective tasks from\nOpenML, which define both the target feature and the train/test split.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>It is discouraged to work directly on datasets and only provide dataset IDs in a paper as\n   this does not allow reproducibility (unclear splitting). Please do not use datasets but the\n   respective tasks as basis for a paper and publish task IDS. This example is only given to\n   showcase the use of OpenML-Python for a published paper and as a warning on how not to do it.\n   Please check the [OpenML documentation of tasks](https://docs.openml.org/#tasks) if you\n   want to learn more about them.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This lists both active and inactive tasks (because of ``status='all'``). Unfortunately,\nthis is necessary as some of the datasets contain issues found after the publication and became\ndeactivated, which also deactivated the tasks on them. More information on active or inactive\ndatasets can be found in the [online docs](https://docs.openml.org/#dataset-status).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tasks = openml.tasks.list_tasks(\n    task_type=openml.tasks.TaskType.SUPERVISED_CLASSIFICATION,\n    status=\"all\",\n    output_format=\"dataframe\",\n)\n\n# Query only those with holdout as the resampling startegy.\ntasks = tasks.query('estimation_procedure == \"33% Holdout set\"')\n\ntask_ids = []\nfor did in dataset_ids:\n    tasks_ = list(tasks.query(\"did == {}\".format(did)).tid)\n    if len(tasks_) >= 1:  # if there are multiple task, take the one with lowest ID (oldest).\n        task_id = min(tasks_)\n    else:\n        raise ValueError(did)\n\n    # Optional - Check that the task has the same target attribute as the\n    # dataset default target attribute\n    # (disabled for this example as it needs to run fast to be rendered online)\n    # task = openml.tasks.get_task(task_id)\n    # dataset = task.get_dataset()\n    # if task.target_name != dataset.default_target_attribute:\n    #     raise ValueError(\n    #         (task.target_name, dataset.default_target_attribute)\n    #     )\n\n    task_ids.append(task_id)\n\nassert len(task_ids) == 140\ntask_ids.sort()\n\n# These are the tasks to work with:\nprint(task_ids)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}