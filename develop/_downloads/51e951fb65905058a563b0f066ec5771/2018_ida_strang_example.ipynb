{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Strang et al. (2018)\n\nA tutorial on how to reproduce the analysis conducted for *Don't Rule Out Simple Models\nPrematurely: A Large Scale Benchmark Comparing Linear and Non-linear Classifiers in OpenML*.\n\n## Publication\n\n| Don't Rule Out Simple Models Prematurely: A Large Scale Benchmark Comparing Linear and Non-linear Classifiers in OpenML\n| Benjamin Strang, Peter van der Putten, Jan N. van Rijn and Frank Hutter\n| In *Advances in Intelligent Data Analysis XVII 17th International Symposium*, 2018\n| Available at https://link.springer.com/chapter/10.1007%2F978-3-030-01768-2_25\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# License: BSD 3-Clause\n\nimport matplotlib.pyplot as plt\nimport openml\nimport pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A basic step for each data-mining or machine learning task is to determine\nwhich model to choose based on the problem and the data at hand. In this\nwork we investigate when non-linear classifiers outperform linear\nclassifiers by means of a large scale experiment.\n\nThe paper is accompanied with a study object, containing all relevant tasks\nand runs (``study_id=123``). The paper features three experiment classes:\nSupport Vector Machines (SVM), Neural Networks (NN) and Decision Trees (DT).\nThis example demonstrates how to reproduce the plots, comparing two\nclassifiers given the OpenML flow ids. Note that this allows us to reproduce\nthe SVM and NN experiment, but not the DT experiment, as this requires a bit\nmore effort to distinguish the same flow with different hyperparameter\nvalues.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "study_id = 123\n# for comparing svms: flow_ids = [7754, 7756]\n# for comparing nns: flow_ids = [7722, 7729]\n# for comparing dts: flow_ids = [7725], differentiate on hyper-parameter value\nclassifier_family = \"SVM\"\nflow_ids = [7754, 7756]\nmeasure = \"predictive_accuracy\"\nmeta_features = [\"NumberOfInstances\", \"NumberOfFeatures\"]\nclass_values = [\"non-linear better\", \"linear better\", \"equal\"]\n\n# Downloads all evaluation records related to this study\nevaluations = openml.evaluations.list_evaluations(\n    measure, size=None, flows=flow_ids, study=study_id, output_format=\"dataframe\"\n)\n# gives us a table with columns data_id, flow1_value, flow2_value\nevaluations = evaluations.pivot(index=\"data_id\", columns=\"flow_id\", values=\"value\").dropna()\n# downloads all data qualities (for scatter plot)\ndata_qualities = openml.datasets.list_datasets(\n    data_id=list(evaluations.index.values), output_format=\"dataframe\"\n)\n# removes irrelevant data qualities\ndata_qualities = data_qualities[meta_features]\n# makes a join between evaluation table and data qualities table,\n# now we have columns data_id, flow1_value, flow2_value, meta_feature_1,\n# meta_feature_2\nevaluations = evaluations.join(data_qualities, how=\"inner\")\n\n# adds column that indicates the difference between the two classifiers\nevaluations[\"diff\"] = evaluations[flow_ids[0]] - evaluations[flow_ids[1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "makes the s-plot\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig_splot, ax_splot = plt.subplots()\nax_splot.plot(range(len(evaluations)), sorted(evaluations[\"diff\"]))\nax_splot.set_title(classifier_family)\nax_splot.set_xlabel(\"Dataset (sorted)\")\nax_splot.set_ylabel(\"difference between linear and non-linear classifier\")\nax_splot.grid(linestyle=\"--\", axis=\"y\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "adds column that indicates the difference between the two classifiers,\nneeded for the scatter plot\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def determine_class(val_lin, val_nonlin):\n    if val_lin < val_nonlin:\n        return class_values[0]\n    elif val_nonlin < val_lin:\n        return class_values[1]\n    else:\n        return class_values[2]\n\n\nevaluations[\"class\"] = evaluations.apply(\n    lambda row: determine_class(row[flow_ids[0]], row[flow_ids[1]]), axis=1\n)\n\n# does the plotting and formatting\nfig_scatter, ax_scatter = plt.subplots()\nfor class_val in class_values:\n    df_class = evaluations[evaluations[\"class\"] == class_val]\n    plt.scatter(df_class[meta_features[0]], df_class[meta_features[1]], label=class_val)\nax_scatter.set_title(classifier_family)\nax_scatter.set_xlabel(meta_features[0])\nax_scatter.set_ylabel(meta_features[1])\nax_scatter.legend()\nax_scatter.set_xscale(\"log\")\nax_scatter.set_yscale(\"log\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "makes a scatter plot where each data point represents the performance of the\ntwo algorithms on various axis (not in the paper)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig_diagplot, ax_diagplot = plt.subplots()\nax_diagplot.grid(linestyle=\"--\")\nax_diagplot.plot([0, 1], ls=\"-\", color=\"black\")\nax_diagplot.plot([0.2, 1.2], ls=\"--\", color=\"black\")\nax_diagplot.plot([-0.2, 0.8], ls=\"--\", color=\"black\")\nax_diagplot.scatter(evaluations[flow_ids[0]], evaluations[flow_ids[1]])\nax_diagplot.set_xlabel(measure)\nax_diagplot.set_ylabel(measure)\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}