
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/30_extended/flows_and_runs_tutorial.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_examples_30_extended_flows_and_runs_tutorial.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_30_extended_flows_and_runs_tutorial.py:


Flows and Runs
==============

How to train/run a model and how to upload the results.

.. GENERATED FROM PYTHON SOURCE LINES 7-13

.. code-block:: default


    # License: BSD 3-Clause

    import openml
    from sklearn import compose, ensemble, impute, neighbors, preprocessing, pipeline, tree








.. GENERATED FROM PYTHON SOURCE LINES 14-22

Train machine learning models
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Train a scikit-learn model on the data manually.

.. warning:: This example uploads data. For that reason, this example
  connects to the test server at test.openml.org. This prevents the main
  server from crowding with example datasets, tasks, runs, and so on.

.. GENERATED FROM PYTHON SOURCE LINES 22-32

.. code-block:: default


    openml.config.start_using_configuration_for_example()
    # NOTE: We are using dataset 68 from the test server: https://test.openml.org/d/68
    dataset = openml.datasets.get_dataset(68)
    X, y, categorical_indicator, attribute_names = dataset.get_data(
        dataset_format="array", target=dataset.default_target_attribute
    )
    clf = neighbors.KNeighborsClassifier(n_neighbors=1)
    clf.fit(X, y)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    KNeighborsClassifier(n_neighbors=1)



.. GENERATED FROM PYTHON SOURCE LINES 33-36

You can also ask for meta-data to automatically preprocess the data.

* e.g. categorical features -> do feature encoding

.. GENERATED FROM PYTHON SOURCE LINES 36-47

.. code-block:: default

    dataset = openml.datasets.get_dataset(17)
    X, y, categorical_indicator, attribute_names = dataset.get_data(
        dataset_format="array", target=dataset.default_target_attribute
    )
    print(f"Categorical features: {categorical_indicator}")
    transformer = compose.ColumnTransformer(
        [("one_hot_encoder", preprocessing.OneHotEncoder(categories="auto"), categorical_indicator)]
    )
    X = transformer.fit_transform(X)
    clf.fit(X, y)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Categorical features: [True, False, True, True, False, True, True, False, True, True, False, True, False, True, True, False, True, False, True, True]

    KNeighborsClassifier(n_neighbors=1)



.. GENERATED FROM PYTHON SOURCE LINES 48-51

Runs: Easily explore models
^^^^^^^^^^^^^^^^^^^^^^^^^^^
We can run (many) scikit-learn algorithms on (many) OpenML tasks.

.. GENERATED FROM PYTHON SOURCE LINES 51-63

.. code-block:: default


    # Get a task
    task = openml.tasks.get_task(403)

    # Build any classifier or pipeline
    clf = tree.DecisionTreeClassifier()

    # Run the flow
    run = openml.runs.run_model_on_task(clf, task)

    print(run)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    OpenML Run
    ==========
    Uploader Name: None
    Metric.......: None
    Run ID.......: None
    Task ID......: 403
    Task Type....: None
    Task URL.....: https://test.openml.org/t/403
    Flow ID......: 178
    Flow Name....: sklearn.tree._classes.DecisionTreeClassifier
    Flow URL.....: https://test.openml.org/f/178
    Setup ID.....: None
    Setup String.: Python_3.8.8. Sklearn_0.24.1. NumPy_1.20.1. SciPy_1.6.2.
    Dataset ID...: 68
    Dataset URL..: https://test.openml.org/d/68




.. GENERATED FROM PYTHON SOURCE LINES 64-68

Share the run on the OpenML server

So far the run is only available locally. By calling the publish function,
the run is sent to the OpenML server:

.. GENERATED FROM PYTHON SOURCE LINES 68-74

.. code-block:: default


    myrun = run.publish()
    # For this tutorial, our configuration publishes to the test server
    # as to not pollute the main server.
    print("Uploaded to http://test.openml.org/r/" + str(myrun.run_id))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Uploaded to http://test.openml.org/r/25574




.. GENERATED FROM PYTHON SOURCE LINES 75-76

We can now also inspect the flow object which was automatically created:

.. GENERATED FROM PYTHON SOURCE LINES 76-80

.. code-block:: default


    flow = openml.flows.get_flow(run.flow_id)
    print(flow)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    OpenML Flow
    ===========
    Flow ID.........: 178 (version 1)
    Flow URL........: https://test.openml.org/f/178
    Flow Name.......: sklearn.tree._classes.DecisionTreeClassifier
    Flow Description: A decision tree classifier.
    Upload Date.....: 2021-02-24 15:02:14
    Dependencies....: sklearn==0.24.1
    numpy>=1.6.1
    scipy>=0.9




.. GENERATED FROM PYTHON SOURCE LINES 81-88

It also works with pipelines
############################

When you need to handle 'dirty' data, build pipelines to model then automatically.
To demonstrate this using the dataset `credit-a <https://test.openml.org/d/16>`_ via
`task <https://test.openml.org/t/96>`_ as it contains both numerical and categorical
variables and missing values in both.

.. GENERATED FROM PYTHON SOURCE LINES 88-164

.. code-block:: default

    task = openml.tasks.get_task(96)

    # OpenML helper functions for sklearn can be plugged in directly for complicated pipelines
    from openml.extensions.sklearn import cat, cont

    pipe = pipeline.Pipeline(
        steps=[
            (
                "Preprocessing",
                compose.ColumnTransformer(
                    [
                        (
                            "categorical",
                            preprocessing.OneHotEncoder(sparse=False, handle_unknown="ignore"),
                            cat,  # returns the categorical feature indices
                        ),
                        (
                            "continuous",
                            impute.SimpleImputer(strategy="median"),
                            cont,
                        ),  # returns the numeric feature indices
                    ]
                ),
            ),
            ("Classifier", ensemble.RandomForestClassifier(n_estimators=10)),
        ]
    )

    run = openml.runs.run_model_on_task(pipe, task, avoid_duplicate_runs=False)
    myrun = run.publish()
    print("Uploaded to http://test.openml.org/r/" + str(myrun.run_id))


    # The above pipeline works with the helper functions that internally deal with pandas DataFrame.
    # In the case, pandas is not available, or a NumPy based data processing is the requirement, the
    # above pipeline is presented below to work with NumPy.

    # Extracting the indices of the categorical columns
    features = task.get_dataset().features
    categorical_feature_indices = []
    numeric_feature_indices = []
    for i in range(len(features)):
        if features[i].name == task.target_name:
            continue
        if features[i].data_type == "nominal":
            categorical_feature_indices.append(i)
        else:
            numeric_feature_indices.append(i)

    pipe = pipeline.Pipeline(
        steps=[
            (
                "Preprocessing",
                compose.ColumnTransformer(
                    [
                        (
                            "categorical",
                            preprocessing.OneHotEncoder(sparse=False, handle_unknown="ignore"),
                            categorical_feature_indices,
                        ),
                        (
                            "continuous",
                            impute.SimpleImputer(strategy="median"),
                            numeric_feature_indices,
                        ),
                    ]
                ),
            ),
            ("Classifier", ensemble.RandomForestClassifier(n_estimators=10)),
        ]
    )

    run = openml.runs.run_model_on_task(pipe, task, avoid_duplicate_runs=False, dataset_format="array")
    myrun = run.publish()
    print("Uploaded to http://test.openml.org/r/" + str(myrun.run_id))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Uploaded to http://test.openml.org/r/25578
    Uploaded to http://test.openml.org/r/25580




.. GENERATED FROM PYTHON SOURCE LINES 165-169

Running flows on tasks offline for later upload
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
For those scenarios where there is no access to internet, it is possible to run
a model on a task without uploading results or flows to the server immediately.

.. GENERATED FROM PYTHON SOURCE LINES 169-189

.. code-block:: default


    # To perform the following line offline, it is required to have been called before
    # such that the task is cached on the local openml cache directory:
    task = openml.tasks.get_task(6)

    # The following lines can then be executed offline:
    run = openml.runs.run_model_on_task(
        pipe, task, avoid_duplicate_runs=False, upload_flow=False, dataset_format="array",
    )

    # The run may be stored offline, and the flow will be stored along with it:
    run.to_filesystem(directory="myrun")

    # They may be loaded and uploaded at a later time
    run = openml.runs.OpenMLRun.from_filesystem(directory="myrun")
    run.publish()

    # Publishing the run will automatically upload the related flow if
    # it does not yet exist on the server.





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/runner/work/openml-python/openml-python/openml/extensions/sklearn/extension.py:1833: UserWarning: Estimator only predicted for 5/6 classes!
      warnings.warn(message)

    OpenML Run
    ==========
    Uploader Name: None
    Metric.......: None
    Run ID.......: 25581
    Run URL......: https://test.openml.org/r/25581
    Task ID......: 6
    Task Type....: None
    Task URL.....: https://test.openml.org/t/6
    Flow ID......: 385
    Flow Name....: sklearn.pipeline.Pipeline(Preprocessing=sklearn.compose._column_transformer.ColumnTransformer(categorical=sklearn.preprocessing._encoders.OneHotEncoder,continuous=sklearn.impute._base.SimpleImputer),Classifier=sklearn.ensemble._forest.RandomForestClassifier)
    Flow URL.....: https://test.openml.org/f/385
    Setup ID.....: None
    Setup String.: Python_3.8.8. Sklearn_0.24.1. NumPy_1.20.1. SciPy_1.6.2.
    Dataset ID...: None
    Dataset URL..: https://test.openml.org/d/None



.. GENERATED FROM PYTHON SOURCE LINES 190-191

Alternatively, one can also directly run flows.

.. GENERATED FROM PYTHON SOURCE LINES 191-205

.. code-block:: default


    # Get a task
    task = openml.tasks.get_task(403)

    # Build any classifier or pipeline
    clf = tree.ExtraTreeClassifier()

    # Obtain the scikit-learn extension interface to convert the classifier
    # into a flow object.
    extension = openml.extensions.get_extension_by_model(clf)
    flow = extension.model_to_flow(clf)

    run = openml.runs.run_flow_on_task(flow, task)








.. GENERATED FROM PYTHON SOURCE LINES 206-223

Challenge
^^^^^^^^^

Try to build the best possible models on several OpenML tasks,
compare your results with the rest of the class and learn from
them. Some tasks you could try (or browse openml.org):

* EEG eye state: data_id:`1471 <http://www.openml.org/d/1471>`_,
  task_id:`14951 <http://www.openml.org/t/14951>`_
* Volcanoes on Venus: data_id:`1527 <http://www.openml.org/d/1527>`_,
  task_id:`10103 <http://www.openml.org/t/10103>`_
* Walking activity: data_id:`1509 <http://www.openml.org/d/1509>`_,
  task_id:`9945 <http://www.openml.org/t/9945>`_, 150k instances.
* Covertype (Satellite): data_id:`150 <http://www.openml.org/d/150>`_,
  task_id:`218 <http://www.openml.org/t/218>`_, 500k instances.
* Higgs (Physics): data_id:`23512 <http://www.openml.org/d/23512>`_,
  task_id:`52950 <http://www.openml.org/t/52950>`_, 100k instances, missing values.

.. GENERATED FROM PYTHON SOURCE LINES 223-235

.. code-block:: default


    # Easy benchmarking:
    for task_id in [115]:  # Add further tasks. Disclaimer: they might take some time
        task = openml.tasks.get_task(task_id)
        data = openml.datasets.get_dataset(task.dataset_id)
        clf = neighbors.KNeighborsClassifier(n_neighbors=5)

        run = openml.runs.run_model_on_task(clf, task, avoid_duplicate_runs=False)
        myrun = run.publish()
        print(f"kNN on {data.name}: http://test.openml.org/r/{myrun.run_id}")






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    kNN on diabetes: http://test.openml.org/r/25588




.. GENERATED FROM PYTHON SOURCE LINES 236-237

.. code-block:: default

    openml.config.stop_using_configuration_for_example()








.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  51.919 seconds)


.. _sphx_glr_download_examples_30_extended_flows_and_runs_tutorial.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: flows_and_runs_tutorial.py <flows_and_runs_tutorial.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: flows_and_runs_tutorial.ipynb <flows_and_runs_tutorial.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
