============================= test session starts =============================
platform win32 -- Python 3.14.0, pytest-9.0.2, pluggy-1.6.0 -- C:\Users\ASUS\AppData\Local\Python\pythoncore-3.14-64\python.exe
cachedir: .pytest_cache
rootdir: C:\Users\ASUS\Documents\work\opensource\openml-python
configfile: pyproject.toml
testpaths: tests
plugins: anyio-4.12.0, flaky-3.8.1, asyncio-1.3.0, cov-7.0.0, mock-3.15.1, rerunfailures-16.1, timeout-2.4.0, xdist-3.8.0, requests-mock-1.12.1
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collecting ... collected 358 items

tests/test_datasets/test_dataset.py::OpenMLDatasetTest::test__unpack_categories_with_nan_likes PASSED [  0%]
tests/test_datasets/test_dataset.py::OpenMLDatasetTest::test_equality_comparison PASSED [  0%]
tests/test_datasets/test_dataset.py::OpenMLDatasetTest::test_get_data_boolean_pandas SKIPPED [  0%]
tests/test_datasets/test_dataset.py::OpenMLDatasetTest::test_get_data_corrupt_pickle PASSED [  1%]
tests/test_datasets/test_dataset.py::OpenMLDatasetTest::test_get_data_pandas PASSED [  1%]
tests/test_datasets/test_dataset.py::OpenMLDatasetTest::test_get_data_rowid_and_ignore_and_target PASSED [  1%]
tests/test_datasets/test_dataset.py::OpenMLDatasetTest::test_get_data_with_ignore_attributes SKIPPED [  1%]
tests/test_datasets/test_dataset.py::OpenMLDatasetTest::test_get_data_with_nonexisting_class PASSED [  2%]
tests/test_datasets/test_dataset.py::OpenMLDatasetTest::test_get_data_with_rowid SKIPPED [  2%]
tests/test_datasets/test_dataset.py::OpenMLDatasetTest::test_get_data_with_target_pandas SKIPPED [  2%]
tests/test_datasets/test_dataset.py::OpenMLDatasetTest::test_init_string_validation PASSED [  3%]
tests/test_datasets/test_dataset.py::OpenMLDatasetTest::test_lazy_loading_metadata PASSED [  3%]
tests/test_datasets/test_dataset.py::OpenMLDatasetTest::test_repr PASSED [  3%]
tests/test_datasets/test_dataset.py::test_tagging PASSED                 [  3%]
tests/test_datasets/test_dataset.py::test_get_feature_with_ontology_data_id_11 FAILED [  4%]
tests/test_datasets/test_dataset.py::test_add_remove_ontology_to_dataset FAILED [  4%]
tests/test_datasets/test_dataset.py::test_add_same_ontology_multiple_features FAILED [  4%]
tests/test_datasets/test_dataset.py::test_add_illegal_long_ontology PASSED [  5%]
tests/test_datasets/test_dataset.py::test_add_illegal_url_ontology PASSED [  5%]
tests/test_datasets/test_dataset.py::OpenMLDatasetTestSparse::test_get_sparse_categorical_data_id_395 PASSED [  5%]
tests/test_datasets/test_dataset.py::OpenMLDatasetTestSparse::test_get_sparse_dataset_dataframe PASSED [  5%]
tests/test_datasets/test_dataset.py::OpenMLDatasetTestSparse::test_get_sparse_dataset_dataframe_with_target PASSED [  6%]
tests/test_datasets/test_dataset.py::OpenMLDatasetTestSparse::test_get_sparse_dataset_rowid_and_ignore_and_target PASSED [  6%]
tests/test_datasets/test_dataset.py::test__read_features PASSED          [  6%]
tests/test_datasets/test_dataset.py::test__read_qualities PASSED         [  6%]
tests/test_datasets/test_dataset.py::test__check_qualities PASSED        [  7%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test__download_minio_file_object_does_not_exist PASSED [  7%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test__download_minio_file_raises_FileExists_if_destination_in_use PASSED [  7%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test__download_minio_file_to_directory PASSED [  8%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test__download_minio_file_to_path PASSED [  8%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test__download_minio_file_works_with_bucket_subdirectory PASSED [  8%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test__get_dataset_description PASSED [  8%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test__get_dataset_features FAILED [  9%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test__get_dataset_parquet_file_does_not_exist PASSED [  9%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test__get_dataset_parquet_is_cached PASSED [  9%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test__get_dataset_qualities FAILED [ 10%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test__getarff_md5_issue PASSED [ 10%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test__getarff_path_dataset_arff FAILED [ 10%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test__name_to_id_name_does_not_exist PASSED [ 10%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test__name_to_id_version_does_not_exist PASSED [ 11%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test__name_to_id_with_deactivated PASSED [ 11%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test__name_to_id_with_multiple_active PASSED [ 11%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test__name_to_id_with_multiple_active_error PASSED [ 12%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test__name_to_id_with_version PASSED [ 12%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test__retrieve_class_labels PASSED [ 12%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_attributes_arff_from_df PASSED [ 12%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_attributes_arff_from_df_mixed_dtype_categories PASSED [ 13%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_attributes_arff_from_df_numeric_column PASSED [ 13%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_attributes_arff_from_df_unknown_dtype PASSED [ 13%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_check_datasets_active PASSED [ 13%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_create_dataset_attributes_auto_without_df PASSED [ 14%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_create_dataset_list PASSED [ 14%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_create_dataset_numpy PASSED [ 14%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_create_dataset_pandas PASSED [ 15%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_create_dataset_row_id_attribute_error PASSED [ 15%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_create_dataset_row_id_attribute_inference PASSED [ 15%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_create_dataset_sparse PASSED [ 15%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_create_invalid_dataset PASSED [ 16%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_data_edit_cannot_edit_critical_field_if_dataset_has_task FAILED [ 16%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_data_edit_critical_field FAILED [ 16%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_data_edit_non_critical_field PASSED [ 17%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_data_edit_requires_field PASSED [ 17%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_data_edit_requires_valid_dataset PASSED [ 17%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_data_fork PASSED [ 17%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_data_status PASSED [ 18%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_dataset_by_name_cannot_access_private_data SKIPPED [ 18%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_deletion_of_cache_dir PASSED [ 18%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_deletion_of_cache_dir_faulty_download PASSED [ 18%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_download_rowid PASSED [ 19%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_edit_data_user_cannot_edit_critical_field_of_other_users_dataset PASSED [ 19%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_get_dataset_by_name FAILED [ 19%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_get_dataset_cache_format_feather FAILED [ 20%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_get_dataset_cache_format_pickle FAILED [ 20%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_get_dataset_cannot_access_private_data PASSED [ 20%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_get_dataset_download_all_files SKIPPED [ 20%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_get_dataset_force_refresh_cache PASSED [ 21%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_get_dataset_force_refresh_cache_clean_start PASSED [ 21%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_get_dataset_lazy_all_functions FAILED [ 21%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_get_dataset_sparse FAILED [ 22%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_get_dataset_uint8_dtype FAILED [ 22%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_get_datasets PASSED [ 22%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_get_datasets_by_mixed PASSED [ 22%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_get_datasets_by_name PASSED [ 23%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_get_online_dataset_arff FAILED [ 23%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_get_online_dataset_format PASSED [ 23%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_ignore_attributes_dataset PASSED [ 24%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_illegal_character_tag PASSED [ 24%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_illegal_length_tag PASSED [ 24%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_list_datasets_empty PASSED [ 24%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_list_datasets_length PASSED [ 25%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_list_datasets_paginate PASSED [ 25%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_list_datasets_with_high_size_parameter PASSED [ 25%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_list_qualities PASSED [ 25%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_publish_dataset FAILED [ 26%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_publish_fetch_ignore_attribute PASSED [ 26%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_tag_untag_dataset PASSED [ 26%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_topic_api_error PASSED [ 27%]
tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_upload_dataset_with_url PASSED [ 27%]
tests/test_datasets/test_dataset_functions.py::test_invalid_attribute_validations[wrong-None-None] PASSED [ 27%]
tests/test_datasets/test_dataset_functions.py::test_invalid_attribute_validations[None-wrong-None] PASSED [ 27%]
tests/test_datasets/test_dataset_functions.py::test_invalid_attribute_validations[None-None-wrong] PASSED [ 28%]
tests/test_datasets/test_dataset_functions.py::test_invalid_attribute_validations[wrong,sunny-None-None] PASSED [ 28%]
tests/test_datasets/test_dataset_functions.py::test_invalid_attribute_validations[None-None-wrong,sunny] PASSED [ 28%]
tests/test_datasets/test_dataset_functions.py::test_invalid_attribute_validations[default_target_attribute5-None-None] PASSED [ 29%]
tests/test_datasets/test_dataset_functions.py::test_invalid_attribute_validations[None-None-ignore_attribute6] PASSED [ 29%]
tests/test_datasets/test_dataset_functions.py::test_valid_attribute_validations[outlook-None-None] PASSED [ 29%]
tests/test_datasets/test_dataset_functions.py::test_valid_attribute_validations[None-outlook-None] PASSED [ 29%]
tests/test_datasets/test_dataset_functions.py::test_valid_attribute_validations[None-None-outlook] PASSED [ 30%]
tests/test_datasets/test_dataset_functions.py::test_valid_attribute_validations[outlook,windy-None-None] PASSED [ 30%]
tests/test_datasets/test_dataset_functions.py::test_valid_attribute_validations[None-None-outlook,windy] PASSED [ 30%]
tests/test_datasets/test_dataset_functions.py::test_valid_attribute_validations[default_target_attribute5-None-None] PASSED [ 31%]
tests/test_datasets/test_dataset_functions.py::test_valid_attribute_validations[None-None-ignore_attribute6] PASSED [ 31%]
tests/test_datasets/test_dataset_functions.py::test_delete_dataset_not_owned PASSED [ 31%]
tests/test_datasets/test_dataset_functions.py::test_delete_dataset_with_run PASSED [ 31%]
tests/test_datasets/test_dataset_functions.py::test_delete_dataset_success PASSED [ 32%]
tests/test_datasets/test_dataset_functions.py::test_delete_unknown_dataset PASSED [ 32%]
tests/test_datasets/test_dataset_functions.py::test_list_datasets PASSED [ 32%]
tests/test_datasets/test_dataset_functions.py::test_list_datasets_by_tag PASSED [ 32%]
tests/test_datasets/test_dataset_functions.py::test_list_datasets_by_size PASSED [ 33%]
tests/test_datasets/test_dataset_functions.py::test_list_datasets_by_number_instances PASSED [ 33%]
tests/test_datasets/test_dataset_functions.py::test_list_datasets_by_number_features FAILED [ 33%]
tests/test_datasets/test_dataset_functions.py::test_list_datasets_by_number_classes PASSED [ 34%]
tests/test_datasets/test_dataset_functions.py::test_list_datasets_by_number_missing_values FAILED [ 34%]
tests/test_datasets/test_dataset_functions.py::test_list_datasets_combined_filters FAILED [ 34%]
tests/test_datasets/test_dataset_functions.py::test_get_dataset_lazy_behavior[True-True-True] FAILED [ 34%]
tests/test_datasets/test_dataset_functions.py::test_get_dataset_lazy_behavior[True-True-False] FAILED [ 35%]
tests/test_datasets/test_dataset_functions.py::test_get_dataset_lazy_behavior[True-False-True] FAILED [ 35%]
tests/test_datasets/test_dataset_functions.py::test_get_dataset_lazy_behavior[True-False-False] FAILED [ 35%]
tests/test_datasets/test_dataset_functions.py::test_get_dataset_lazy_behavior[False-True-True] FAILED [ 36%]
tests/test_datasets/test_dataset_functions.py::test_get_dataset_lazy_behavior[False-True-False] FAILED [ 36%]
tests/test_datasets/test_dataset_functions.py::test_get_dataset_lazy_behavior[False-False-True] FAILED [ 36%]
tests/test_datasets/test_dataset_functions.py::test_get_dataset_lazy_behavior[False-False-False] FAILED [ 36%]
tests/test_datasets/test_dataset_functions.py::test_get_dataset_with_invalid_id PASSED [ 37%]
tests/test_datasets/test_dataset_functions.py::test__get_dataset_parquet_not_cached PASSED [ 37%]
tests/test_datasets/test_dataset_functions.py::test_read_features_from_xml_with_whitespace PASSED [ 37%]
tests/test_datasets/test_dataset_functions.py::test_get_dataset_parquet PASSED [ 37%]
tests/test_evaluations/test_evaluation_functions.py::TestEvaluationFunctions::test_evaluation_list_filter_flow PASSED [ 38%]
tests/test_evaluations/test_evaluation_functions.py::TestEvaluationFunctions::test_evaluation_list_filter_run PASSED [ 38%]
tests/test_evaluations/test_evaluation_functions.py::TestEvaluationFunctions::test_evaluation_list_filter_task PASSED [ 38%]
tests/test_evaluations/test_evaluation_functions.py::TestEvaluationFunctions::test_evaluation_list_filter_uploader_ID_10 PASSED [ 39%]
tests/test_evaluations/test_evaluation_functions.py::TestEvaluationFunctions::test_evaluation_list_filter_uploader_ID_16 PASSED [ 39%]
tests/test_evaluations/test_evaluation_functions.py::TestEvaluationFunctions::test_evaluation_list_limit PASSED [ 39%]
tests/test_evaluations/test_evaluation_functions.py::TestEvaluationFunctions::test_evaluation_list_per_fold PASSED [ 39%]
tests/test_evaluations/test_evaluation_functions.py::TestEvaluationFunctions::test_evaluation_list_sort PASSED [ 40%]
tests/test_evaluations/test_evaluation_functions.py::TestEvaluationFunctions::test_list_evaluation_measures PASSED [ 40%]
tests/test_evaluations/test_evaluation_functions.py::TestEvaluationFunctions::test_list_evaluations_empty PASSED [ 40%]
tests/test_evaluations/test_evaluation_functions.py::TestEvaluationFunctions::test_list_evaluations_setups_filter_flow PASSED [ 41%]
tests/test_evaluations/test_evaluation_functions.py::TestEvaluationFunctions::test_list_evaluations_setups_filter_task PASSED [ 41%]
tests/test_evaluations/test_evaluations_example.py::TestEvaluationsExample::test_example_python_paper PASSED [ 41%]
tests/test_extensions/test_functions.py::TestInit::test_get_extension_by_flow PASSED [ 41%]
tests/test_extensions/test_functions.py::TestInit::test_get_extension_by_model PASSED [ 42%]
tests/test_flows/test_flow.py::TestFlow::test_download_non_scikit_learn_flows PASSED [ 42%]
tests/test_flows/test_flow.py::TestFlow::test_existing_flow_exists PASSED [ 42%]
tests/test_flows/test_flow.py::TestFlow::test_extract_tags PASSED        [ 43%]
tests/test_flows/test_flow.py::TestFlow::test_from_xml_to_xml PASSED     [ 43%]
tests/test_flows/test_flow.py::TestFlow::test_get_flow PASSED            [ 43%]
tests/test_flows/test_flow.py::TestFlow::test_get_structure PASSED       [ 43%]
tests/test_flows/test_flow.py::TestFlow::test_illegal_flow PASSED        [ 44%]
tests/test_flows/test_flow.py::TestFlow::test_nonexisting_flow_exists PASSED [ 44%]
tests/test_flows/test_flow.py::TestFlow::test_publish_error PASSED       [ 44%]
tests/test_flows/test_flow.py::TestFlow::test_publish_existing_flow PASSED [ 44%]
tests/test_flows/test_flow.py::TestFlow::test_publish_flow PASSED        [ 45%]
tests/test_flows/test_flow.py::TestFlow::test_publish_flow_with_similar_components PASSED [ 45%]
tests/test_flows/test_flow.py::TestFlow::test_semi_legal_flow PASSED     [ 45%]
tests/test_flows/test_flow.py::TestFlow::test_sklearn_to_upload_to_flow PASSED [ 46%]
tests/test_flows/test_flow.py::TestFlow::test_tagging PASSED             [ 46%]
tests/test_flows/test_flow.py::TestFlow::test_to_xml_from_xml PASSED     [ 46%]
tests/test_flows/test_flow_functions.py::TestFlowFunctions::test_are_flows_equal PASSED [ 46%]
tests/test_flows/test_flow_functions.py::TestFlowFunctions::test_are_flows_equal_ignore_if_older PASSED [ 47%]
tests/test_flows/test_flow_functions.py::TestFlowFunctions::test_are_flows_equal_ignore_parameter_values PASSED [ 47%]
tests/test_flows/test_flow_functions.py::TestFlowFunctions::test_delete_flow PASSED [ 47%]
tests/test_flows/test_flow_functions.py::TestFlowFunctions::test_get_flow1 PASSED [ 48%]
tests/test_flows/test_flow_functions.py::TestFlowFunctions::test_get_flow_id SKIPPED [ 48%]
tests/test_flows/test_flow_functions.py::TestFlowFunctions::test_get_flow_reinstantiate_flow_not_strict_023_and_024 SKIPPED [ 48%]
tests/test_flows/test_flow_functions.py::TestFlowFunctions::test_get_flow_reinstantiate_flow_not_strict_post_1 SKIPPED [ 48%]
tests/test_flows/test_flow_functions.py::TestFlowFunctions::test_get_flow_reinstantiate_flow_not_strict_pre_023 SKIPPED [ 49%]
tests/test_flows/test_flow_functions.py::TestFlowFunctions::test_get_flow_reinstantiate_model PASSED [ 49%]
tests/test_flows/test_flow_functions.py::TestFlowFunctions::test_get_flow_reinstantiate_model_no_extension PASSED [ 49%]
tests/test_flows/test_flow_functions.py::TestFlowFunctions::test_get_flow_with_reinstantiate_strict_with_wrong_version_raises_exception PASSED [ 50%]
tests/test_flows/test_flow_functions.py::TestFlowFunctions::test_list_flows PASSED [ 50%]
tests/test_flows/test_flow_functions.py::TestFlowFunctions::test_list_flows_by_tag PASSED [ 50%]
tests/test_flows/test_flow_functions.py::TestFlowFunctions::test_list_flows_empty PASSED [ 50%]
tests/test_flows/test_flow_functions.py::TestFlowFunctions::test_list_flows_output_format PASSED [ 51%]
tests/test_flows/test_flow_functions.py::TestFlowFunctions::test_list_flows_paginate PASSED [ 51%]
tests/test_flows/test_flow_functions.py::TestFlowFunctions::test_sklearn_to_flow_list_of_lists PASSED [ 51%]
tests/test_flows/test_flow_functions.py::test_delete_flow_not_owned PASSED [ 51%]
tests/test_flows/test_flow_functions.py::test_delete_flow_with_run PASSED [ 52%]
tests/test_flows/test_flow_functions.py::test_delete_subflow PASSED      [ 52%]
tests/test_flows/test_flow_functions.py::test_delete_flow_success PASSED [ 52%]
tests/test_flows/test_flow_functions.py::test_delete_unknown_flow PASSED [ 53%]
tests/test_openml/test_api_calls.py::TestConfig::test_retry_on_database_error PASSED [ 53%]
tests/test_openml/test_api_calls.py::TestConfig::test_too_long_uri PASSED [ 53%]
tests/test_openml/test_api_calls.py::test_download_all_files_observes_cache FAILED [ 53%]
tests/test_openml/test_api_calls.py::test_download_minio_failure PASSED  [ 54%]
tests/test_openml/test_api_calls.py::test_authentication_endpoints_requiring_api_key_show_relevant_help_link[flow/exists-post] PASSED [ 54%]
tests/test_openml/test_api_calls.py::test_authentication_endpoints_requiring_api_key_show_relevant_help_link[dataset-post] PASSED [ 54%]
tests/test_openml/test_api_calls.py::test_authentication_endpoints_requiring_api_key_show_relevant_help_link[dataset/42-delete] PASSED [ 55%]
tests/test_openml/test_api_calls.py::test_authentication_endpoints_requiring_api_key_show_relevant_help_link[flow/42-delete] PASSED [ 55%]
tests/test_openml/test_api_calls.py::test_authentication_endpoints_requiring_api_key_show_relevant_help_link[run/42-delete] PASSED [ 55%]
tests/test_openml/test_api_calls.py::test_authentication_endpoints_requiring_api_key_show_relevant_help_link[task/42-delete] PASSED [ 55%]
tests/test_openml/test_config.py::TestConfig::test_XDG_directories_do_not_exist SKIPPED [ 56%]
tests/test_openml/test_config.py::TestConfig::test_get_config_as_dict PASSED [ 56%]
tests/test_openml/test_config.py::TestConfig::test_non_writable_home SKIPPED [ 56%]
tests/test_openml/test_config.py::TestConfig::test_setup_with_config PASSED [ 56%]
tests/test_openml/test_config.py::TestConfigurationForExamples::test_example_configuration_start_twice PASSED [ 57%]
tests/test_openml/test_config.py::TestConfigurationForExamples::test_example_configuration_stop_before_start PASSED [ 57%]
tests/test_openml/test_config.py::TestConfigurationForExamples::test_switch_from_example_configuration PASSED [ 57%]
tests/test_openml/test_config.py::TestConfigurationForExamples::test_switch_to_example_configuration PASSED [ 58%]
tests/test_openml/test_config.py::test_configuration_file_not_overwritten_on_load PASSED [ 58%]
tests/test_openml/test_config.py::test_configuration_loads_booleans PASSED [ 58%]
tests/test_openml/test_config.py::test_openml_cache_dir_env_var PASSED   [ 58%]
tests/test_openml/test_openml.py::TestInit::test_populate_cache PASSED   [ 59%]
tests/test_runs/test_run.py::TestRun::test_offline_and_online_run_identical FAILED [ 59%]
tests/test_runs/test_run.py::TestRun::test_publish_with_local_loaded_flow FAILED [ 59%]
tests/test_runs/test_run.py::TestRun::test_run_setup_string_included_in_xml PASSED [ 60%]
tests/test_runs/test_run.py::TestRun::test_tagging FAILED                [ 60%]
tests/test_runs/test_run.py::TestRun::test_to_from_filesystem_no_model FAILED [ 60%]
tests/test_runs/test_run.py::TestRun::test_to_from_filesystem_search RERUN [ 60%]
tests/test_runs/test_run.py::TestRun::test_to_from_filesystem_search FAILED [ 60%]
tests/test_runs/test_run.py::TestRun::test_to_from_filesystem_vanilla FAILED [ 61%]
tests/test_runs/test_run_functions.py::TestRun::test__create_trace_from_arff PASSED [ 61%]
tests/test_runs/test_run_functions.py::TestRun::test__run_exists FAILED  [ 61%]
tests/test_runs/test_run_functions.py::TestRun::test__run_task_get_arffcontent FAILED [ 62%]
tests/test_runs/test_run_functions.py::TestRun::test_check_erronous_sklearn_flow_fails FAILED [ 62%]
tests/test_runs/test_run_functions.py::TestRun::test_delete_run FAILED   [ 62%]
tests/test_runs/test_run_functions.py::TestRun::test_format_prediction_classification_incomplete_probabilities FAILED [ 62%]
tests/test_runs/test_run_functions.py::TestRun::test_format_prediction_classification_no_probabilities FAILED [ 63%]
tests/test_runs/test_run_functions.py::TestRun::test_format_prediction_non_supervised PASSED [ 63%]
tests/test_runs/test_run_functions.py::TestRun::test_format_prediction_task_learning_curve_sample_not_set FAILED [ 63%]
tests/test_runs/test_run_functions.py::TestRun::test_format_prediction_task_regression PASSED [ 63%]
tests/test_runs/test_run_functions.py::TestRun::test_format_prediction_task_without_classlabels_set FAILED [ 64%]
tests/test_runs/test_run_functions.py::TestRun::test_get_cached_run PASSED [ 64%]
tests/test_runs/test_run_functions.py::TestRun::test_get_run PASSED      [ 64%]
tests/test_runs/test_run_functions.py::TestRun::test_get_runs_list PASSED [ 65%]
tests/test_runs/test_run_functions.py::TestRun::test_get_runs_list_by_filters PASSED [ 65%]
tests/test_runs/test_run_functions.py::TestRun::test_get_runs_list_by_flow PASSED [ 65%]
tests/test_runs/test_run_functions.py::TestRun::test_get_runs_list_by_tag PASSED [ 65%]
tests/test_runs/test_run_functions.py::TestRun::test_get_runs_list_by_task PASSED [ 66%]
tests/test_runs/test_run_functions.py::TestRun::test_get_runs_list_by_uploader PASSED [ 66%]
tests/test_runs/test_run_functions.py::TestRun::test_get_runs_pagination PASSED [ 66%]
tests/test_runs/test_run_functions.py::TestRun::test_get_uncached_run PASSED [ 67%]
tests/test_runs/test_run_functions.py::TestRun::test_initialize_cv_from_run FAILED [ 67%]
tests/test_runs/test_run_functions.py::TestRun::test_initialize_model_from_run FAILED [ 67%]
tests/test_runs/test_run_functions.py::TestRun::test_initialize_model_from_run_nonstrict SKIPPED [ 67%]
tests/test_runs/test_run_functions.py::TestRun::test_learning_curve_task_1 FAILED [ 68%]
tests/test_runs/test_run_functions.py::TestRun::test_learning_curve_task_2 FAILED [ 68%]
tests/test_runs/test_run_functions.py::TestRun::test_list_runs_empty PASSED [ 68%]
tests/test_runs/test_run_functions.py::TestRun::test_local_run_metric_score FAILED [ 68%]
tests/test_runs/test_run_functions.py::TestRun::test_local_run_swapped_parameter_order_flow FAILED [ 69%]
tests/test_runs/test_run_functions.py::TestRun::test_local_run_swapped_parameter_order_model FAILED [ 69%]
tests/test_runs/test_run_functions.py::TestRun::test_online_run_metric_score PASSED [ 69%]
tests/test_runs/test_run_functions.py::TestRun::test_run_and_upload_column_transformer_pipeline SKIPPED [ 70%]
tests/test_runs/test_run_functions.py::TestRun::test_run_and_upload_gridsearch SKIPPED [ 70%]
tests/test_runs/test_run_functions.py::TestRun::test_run_and_upload_knn_pipeline SKIPPED [ 70%]
tests/test_runs/test_run_functions.py::TestRun::test_run_and_upload_linear_regression SKIPPED [ 70%]
tests/test_runs/test_run_functions.py::TestRun::test_run_and_upload_logistic_regression SKIPPED [ 71%]
tests/test_runs/test_run_functions.py::TestRun::test_run_and_upload_maskedarrays SKIPPED [ 71%]
tests/test_runs/test_run_functions.py::TestRun::test_run_and_upload_pipeline_dummy_pipeline SKIPPED [ 71%]
tests/test_runs/test_run_functions.py::TestRun::test_run_and_upload_randomsearch SKIPPED [ 72%]
tests/test_runs/test_run_functions.py::TestRun::test_run_flow_on_task_downloaded_flow FAILED [ 72%]
tests/test_runs/test_run_functions.py::TestRun::test_run_on_dataset_with_missing_labels_array FAILED [ 72%]
tests/test_runs/test_run_functions.py::TestRun::test_run_on_dataset_with_missing_labels_dataframe FAILED [ 72%]
tests/test_runs/test_run_functions.py::TestRun::test_run_regression_on_classif_task FAILED [ 73%]
tests/test_runs/test_run_functions.py::TestRun::test_run_with_illegal_flow_id FAILED [ 73%]
tests/test_runs/test_run_functions.py::TestRun::test_run_with_illegal_flow_id_1 FAILED [ 73%]
tests/test_runs/test_run_functions.py::TestRun::test_run_with_illegal_flow_id_1_after_load FAILED [ 74%]
tests/test_runs/test_run_functions.py::TestRun::test_run_with_illegal_flow_id_after_load FAILED [ 74%]
tests/test_runs/test_run_functions.py::test_delete_run_not_owned PASSED  [ 74%]
tests/test_runs/test_run_functions.py::test_delete_run_success PASSED    [ 74%]
tests/test_runs/test_run_functions.py::test_delete_unknown_run PASSED    [ 75%]
tests/test_runs/test_run_functions.py::test__run_task_get_arffcontent_2 FAILED [ 75%]
tests/test_runs/test_run_functions.py::test_joblib_backends[2-None-0] FAILED [ 75%]
tests/test_runs/test_run_functions.py::test_joblib_backends[-1-None-0] FAILED [ 75%]
tests/test_runs/test_run_functions.py::test_joblib_backends[1-None-10] FAILED [ 76%]
tests/test_runs/test_run_functions.py::test_joblib_backends[1-sequential-10] FAILED [ 76%]
tests/test_runs/test_run_functions.py::test_joblib_backends[1-threading-10] FAILED [ 76%]
tests/test_runs/test_run_functions.py::test_joblib_backends[-1-threading-10] FAILED [ 77%]
tests/test_runs/test_trace.py::TestTrace::test_duplicate_name PASSED     [ 77%]
tests/test_runs/test_trace.py::TestTrace::test_get_selected_iteration PASSED [ 77%]
tests/test_runs/test_trace.py::TestTrace::test_initialization PASSED     [ 77%]
tests/test_setups/test_setup_functions.py::TestSetupFunctions::test_exisiting_setup_exists_2 FAILED [ 78%]
tests/test_setups/test_setup_functions.py::TestSetupFunctions::test_existing_setup_exists_1 FAILED [ 78%]
tests/test_setups/test_setup_functions.py::TestSetupFunctions::test_existing_setup_exists_3 FAILED [ 78%]
tests/test_setups/test_setup_functions.py::TestSetupFunctions::test_get_cached_setup PASSED [ 79%]
tests/test_setups/test_setup_functions.py::TestSetupFunctions::test_get_setup PASSED [ 79%]
tests/test_setups/test_setup_functions.py::TestSetupFunctions::test_get_uncached_setup PASSED [ 79%]
tests/test_setups/test_setup_functions.py::TestSetupFunctions::test_list_setups_empty PASSED [ 79%]
tests/test_setups/test_setup_functions.py::TestSetupFunctions::test_list_setups_output_format PASSED [ 80%]
tests/test_setups/test_setup_functions.py::TestSetupFunctions::test_nonexisting_setup_exists PASSED [ 80%]
tests/test_setups/test_setup_functions.py::TestSetupFunctions::test_setup_list_filter_flow PASSED [ 80%]
tests/test_setups/test_setup_functions.py::TestSetupFunctions::test_setuplist_offset FAILED [ 81%]
tests/test_study/test_study_functions.py::TestStudyFunctions::test_get_openml100 PASSED [ 81%]
tests/test_study/test_study_functions.py::TestStudyFunctions::test_get_study_error PASSED [ 81%]
tests/test_study/test_study_functions.py::TestStudyFunctions::test_get_study_new PASSED [ 81%]
tests/test_study/test_study_functions.py::TestStudyFunctions::test_get_study_old PASSED [ 82%]
tests/test_study/test_study_functions.py::TestStudyFunctions::test_get_suite PASSED [ 82%]
tests/test_study/test_study_functions.py::TestStudyFunctions::test_get_suite_error PASSED [ 82%]
tests/test_study/test_study_functions.py::TestStudyFunctions::test_publish_benchmark_suite PASSED [ 82%]
tests/test_study/test_study_functions.py::TestStudyFunctions::test_publish_empty_study_explicit PASSED [ 83%]
tests/test_study/test_study_functions.py::TestStudyFunctions::test_publish_empty_study_implicit PASSED [ 83%]
tests/test_study/test_study_functions.py::TestStudyFunctions::test_publish_study RERUN [ 83%]
tests/test_study/test_study_functions.py::TestStudyFunctions::test_publish_study FAILED [ 83%]
tests/test_study/test_study_functions.py::TestStudyFunctions::test_study_attach_illegal FAILED [ 84%]
tests/test_study/test_study_functions.py::TestStudyFunctions::test_study_list SKIPPED [ 84%]
tests/test_tasks/test_classification_task.py::OpenMLClassificationTaskTest::test_class_labels FAILED [ 84%]
tests/test_tasks/test_classification_task.py::OpenMLClassificationTaskTest::test_download_task FAILED [ 84%]
tests/test_tasks/test_classification_task.py::OpenMLClassificationTaskTest::test_get_X_and_Y FAILED [ 85%]
tests/test_tasks/test_classification_task.py::OpenMLClassificationTaskTest::test_upload_task PASSED [ 85%]
tests/test_tasks/test_classification_task.py::test_get_X_and_Y FAILED    [ 85%]
tests/test_tasks/test_clustering_task.py::OpenMLClusteringTaskTest::test_download_task PASSED [ 86%]
tests/test_tasks/test_clustering_task.py::OpenMLClusteringTaskTest::test_get_dataset PASSED [ 86%]
tests/test_tasks/test_clustering_task.py::OpenMLClusteringTaskTest::test_upload_task PASSED [ 86%]
tests/test_tasks/test_learning_curve_task.py::OpenMLLearningCurveTaskTest::test_class_labels FAILED [ 86%]
tests/test_tasks/test_learning_curve_task.py::OpenMLLearningCurveTaskTest::test_download_task FAILED [ 87%]
tests/test_tasks/test_learning_curve_task.py::OpenMLLearningCurveTaskTest::test_get_X_and_Y FAILED [ 87%]
tests/test_tasks/test_learning_curve_task.py::OpenMLLearningCurveTaskTest::test_upload_task PASSED [ 87%]
tests/test_tasks/test_regression_task.py::OpenMLRegressionTaskTest::test_download_task PASSED [ 87%]
tests/test_tasks/test_regression_task.py::OpenMLRegressionTaskTest::test_get_X_and_Y FAILED [ 88%]
tests/test_tasks/test_regression_task.py::OpenMLRegressionTaskTest::test_upload_task PASSED [ 88%]
tests/test_tasks/test_split.py::OpenMLSplitTest::test_eq PASSED          [ 88%]
tests/test_tasks/test_split.py::OpenMLSplitTest::test_from_arff_file PASSED [ 89%]
tests/test_tasks/test_split.py::OpenMLSplitTest::test_get_split PASSED   [ 89%]
tests/test_tasks/test_task_functions.py::TestTask::test__get_cached_task PASSED [ 89%]
tests/test_tasks/test_task_functions.py::TestTask::test__get_cached_task_not_cached PASSED [ 89%]
tests/test_tasks/test_task_functions.py::TestTask::test__get_cached_tasks PASSED [ 90%]
tests/test_tasks/test_task_functions.py::TestTask::test__get_estimation_procedure_list PASSED [ 90%]
tests/test_tasks/test_task_functions.py::TestTask::test__get_task PASSED [ 90%]
tests/test_tasks/test_task_functions.py::TestTask::test__get_task_live SKIPPED [ 91%]
tests/test_tasks/test_task_functions.py::TestTask::test_deletion_of_cache_dir PASSED [ 91%]
tests/test_tasks/test_task_functions.py::TestTask::test_download_split FAILED [ 91%]
tests/test_tasks/test_task_functions.py::TestTask::test_get_task FAILED  [ 91%]
tests/test_tasks/test_task_functions.py::TestTask::test_get_task_different_types PASSED [ 92%]
tests/test_tasks/test_task_functions.py::TestTask::test_get_task_lazy FAILED [ 92%]
tests/test_tasks/test_task_functions.py::TestTask::test_get_task_with_cache FAILED [ 92%]
tests/test_tasks/test_task_functions.py::TestTask::test_list_clustering_task PASSED [ 93%]
tests/test_tasks/test_task_functions.py::TestTask::test_list_tasks PASSED [ 93%]
tests/test_tasks/test_task_functions.py::TestTask::test_list_tasks_by_tag PASSED [ 93%]
tests/test_tasks/test_task_functions.py::TestTask::test_list_tasks_by_type PASSED [ 93%]
tests/test_tasks/test_task_functions.py::TestTask::test_list_tasks_empty PASSED [ 94%]
tests/test_tasks/test_task_functions.py::TestTask::test_list_tasks_length PASSED [ 94%]
tests/test_tasks/test_task_functions.py::TestTask::test_list_tasks_paginate PASSED [ 94%]
tests/test_tasks/test_task_functions.py::TestTask::test_list_tasks_per_type_paginate PASSED [ 94%]
tests/test_tasks/test_task_functions.py::TestTask::test_removal_upon_download_failure XFAIL [ 95%]
tests/test_tasks/test_task_functions.py::test_delete_task_not_owned PASSED [ 95%]
tests/test_tasks/test_task_functions.py::test_delete_task_with_run PASSED [ 95%]
tests/test_tasks/test_task_functions.py::test_delete_success PASSED      [ 96%]
tests/test_tasks/test_task_functions.py::test_delete_unknown_task PASSED [ 96%]
tests/test_tasks/test_task_methods.py::OpenMLTaskMethodsTest::test_get_train_and_test_split_indices PASSED [ 96%]
tests/test_tasks/test_task_methods.py::OpenMLTaskMethodsTest::test_tagging FAILED [ 96%]
tests/test_utils/test_utils.py::test_list_all PASSED                     [ 97%]
tests/test_utils/test_utils.py::test_list_all_for_tasks PASSED           [ 97%]
tests/test_utils/test_utils.py::test_list_all_with_multiple_batches PASSED [ 97%]
tests/test_utils/test_utils.py::test_list_all_for_datasets PASSED        [ 98%]
tests/test_utils/test_utils.py::test_list_all_for_flows PASSED           [ 98%]
tests/test_utils/test_utils.py::test_list_all_for_setups RERUN           [ 98%]
tests/test_utils/test_utils.py::test_list_all_for_setups FAILED          [ 98%]
tests/test_utils/test_utils.py::test_list_all_for_runs RERUN             [ 98%]
tests/test_utils/test_utils.py::test_list_all_for_runs FAILED            [ 98%]
tests/test_utils/test_utils.py::test_list_all_for_evaluations RERUN      [ 99%]
tests/test_utils/test_utils.py::test_list_all_for_evaluations FAILED     [ 99%]
tests/test_utils/test_utils.py::test_list_all_few_results_available PASSED [ 99%]
tests/test_utils/test_utils.py::test__create_cache_directory SKIPPED     [ 99%]
tests/test_utils/test_utils.py::test_correct_test_server_download_state FAILED [100%]

================================== FAILURES ===================================
__________________ test_get_feature_with_ontology_data_id_11 __________________
[XPASS(strict)] failures_issue_1544
_____________________ test_add_remove_ontology_to_dataset _____________________

    def test_add_remove_ontology_to_dataset():
        did = 1
        feature_index = 1
        ontology = "https://www.openml.org/unittest/" + str(time())
>       openml.datasets.functions.data_feature_add_ontology(did, feature_index, ontology)

tests\test_datasets\test_dataset.py:310: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\functions.py:992: in data_feature_add_ontology
    openml._api_calls._perform_api_call("data/feature/ontology/add", "post", data=upload_data)
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [500]>
url = 'https://test.openml.org/api/v1/xml/data/feature/ontology/add'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/feature/ontology/add returned code 1102: Failure to write to the database - id=1; description=https://www.openml.org/unittest/1768424626.9149947

openml\_api_calls.py:452: OpenMLServerException
__________________ test_add_same_ontology_multiple_features ___________________

    def test_add_same_ontology_multiple_features():
        did = 1
        ontology = "https://www.openml.org/unittest/" + str(time())
    
        for i in range(3):
>           openml.datasets.functions.data_feature_add_ontology(did, i, ontology)

tests\test_datasets\test_dataset.py:318: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\functions.py:992: in data_feature_add_ontology
    openml._api_calls._perform_api_call("data/feature/ontology/add", "post", data=upload_data)
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [500]>
url = 'https://test.openml.org/api/v1/xml/data/feature/ontology/add'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/feature/ontology/add returned code 1102: Failure to write to the database - id=1; description=https://www.openml.org/unittest/1768424628.1604645

openml\_api_calls.py:452: OpenMLServerException
________________ TestOpenMLDataset.test__get_dataset_features _________________

self = <tests.test_datasets.test_dataset_functions.TestOpenMLDataset testMethod=test__get_dataset_features>

    def test__get_dataset_features(self):
>       features_file = _get_dataset_features_file(self.workdir, 2)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_datasets\test_dataset_functions.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/2', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/2 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException
________________ TestOpenMLDataset.test__get_dataset_qualities ________________

did_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_datasets.test_dataset_functions.TestOpenMLDataset.test__get_dataset_qualities')
dataset_id = 2

    def _get_dataset_qualities_file(
        did_cache_dir: str | Path | None,
        dataset_id: int,
    ) -> Path | None:
        """Get the path for the dataset qualities file, or None if no qualities exist.
    
        Loads from cache or downloads them.
        Features are metafeatures (number of features, number of classes, ...)
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        did_cache_dir : str or None
            Cache subdirectory for this dataset
    
        dataset_id : int
            Dataset ID
    
        Returns
        -------
        str
            Path of the cached qualities file
        """
        save_did_cache_dir = (
            _create_cache_directory_for_id(DATASETS_CACHE_DIR_NAME, dataset_id)
            if did_cache_dir is None
            else Path(did_cache_dir)
        )
    
        # Dataset qualities are subject to change and must be fetched every time
        qualities_file = save_did_cache_dir / "qualities.xml"
        try:
>           with qualities_file.open(encoding="utf8") as fh:
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\datasets\functions.py:1326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_datasets.test_dataset_functions.TestOpenMLDataset.test__get_dataset_qualities/qualities.xml')
mode = 'r', buffering = -1, encoding = 'utf8', errors = None, newline = None

    def open(self, mode='r', buffering=-1, encoding=None,
             errors=None, newline=None):
        """
        Open the file pointed to by this path and return a file object, as
        the built-in open() function does.
        """
        if "b" not in mode:
            encoding = io.text_encoding(encoding)
>       return io.open(self, mode, buffering, encoding, errors, newline)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       FileNotFoundError: [Errno 2] No such file or directory: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_datasets.test_dataset_functions.TestOpenMLDataset.test__get_dataset_qualities\\qualities.xml'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\pathlib\__init__.py:776: FileNotFoundError

During handling of the above exception, another exception occurred:

self = <tests.test_datasets.test_dataset_functions.TestOpenMLDataset testMethod=test__get_dataset_qualities>

    def test__get_dataset_qualities(self):
>       qualities = _get_dataset_qualities_file(self.workdir, 2)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_datasets\test_dataset_functions.py:440: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\functions.py:1339: in _get_dataset_qualities_file
    raise e
openml\datasets\functions.py:1330: in _get_dataset_qualities_file
    qualities_xml = _get_qualities_xml(dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1290: in _get_qualities_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/qualities/2'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/qualities/2 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0002/kr-vs-kp.arff

openml\_api_calls.py:452: OpenMLServerException
______________ TestOpenMLDataset.test__getarff_path_dataset_arff ______________

self = <tests.test_datasets.test_dataset_functions.TestOpenMLDataset testMethod=test__getarff_path_dataset_arff>

    def test__getarff_path_dataset_arff(self):
        openml.config.set_root_cache_directory(self.static_cache_dir)
        description = _get_dataset_description(self.workdir, 2)
>       arff_path = _get_dataset_arff(description, cache_directory=self.workdir)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_datasets\test_dataset_functions.py:333: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\functions.py:1234: in _get_dataset_arff
    openml._api_calls._download_text_file(
openml\_api_calls.py:275: in _download_text_file
    response = __read_url(source, request_method="get", md5_checksum=md5_checksum)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
openml\_api_calls.py:452: in __check_response
    raise __parse_server_exception(response, url, file_elements=file_elements)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [404]>
url = 'https://test.openml.org/data/v1/download/2/kr-vs-kp.arff'
file_elements = None

    def __parse_server_exception(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> OpenMLServerError:
        if response.status_code == requests.codes.URI_TOO_LONG:
            raise OpenMLServerError(f"URI too long! ({url})")
    
        # OpenML has a sophisticated error system where information about failures is provided,
        # in the response body itself.
        # First, we need to parse it out.
        try:
            server_exception = xmltodict.parse(response.text)
        except xml.parsers.expat.ExpatError as e:
            raise e
        except Exception as e:
            # If we failed to parse it out, then something has gone wrong in the body we have sent back
            # from the server and there is little extra information we can capture.
            raise OpenMLServerError(
                f"Unexpected server error when calling {url}. Please contact the developers!\n"
                f"Status code: {response.status_code}\n{response.text}",
            ) from e
    
        # Now we can parse out the specific error codes that we return. These
        # are in addition to the typical HTTP error codes, but encode more
        # specific informtion. You can find these codes here:
        # https://github.com/openml/OpenML/blob/develop/openml_OS/views/pages/api_new/v1/xml/pre.php
>       server_error = server_exception["oml:error"]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       KeyError: 'oml:error'

openml\_api_calls.py:484: KeyError
_ TestOpenMLDataset.test_data_edit_cannot_edit_critical_field_if_dataset_has_task _

self = <tests.test_datasets.test_dataset_functions.TestOpenMLDataset testMethod=test_data_edit_cannot_edit_critical_field_if_dataset_has_task>

    def test_data_edit_cannot_edit_critical_field_if_dataset_has_task(self):
        # Need to own a dataset to be able to edit meta-data
        # Will be creating a forked version of an existing dataset to allow the unit test user
        #  to edit meta-data of a dataset
        did = fork_dataset(1)
>       self._wait_for_dataset_being_processed(did)

tests\test_datasets\test_dataset_functions.py:1456: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <tests.test_datasets.test_dataset_functions.TestOpenMLDataset testMethod=test_data_edit_cannot_edit_critical_field_if_dataset_has_task>
dataset_id = 1483, poll_delay = 10, max_waiting_time_seconds = 600

    def _wait_for_dataset_being_processed(
        self, dataset_id, poll_delay: int = 10, max_waiting_time_seconds: int = 600
    ):
        start_time = time.time()
        while (time.time() - start_time) < max_waiting_time_seconds:
            try:
                # being able to download qualities is a sign that the dataset is processed
                return openml.datasets.get_dataset(dataset_id, download_qualities=True)
            except OpenMLServerException as e:
                TestBase.logger.error(
                    f"Failed to fetch dataset:{dataset_id} with '{e!s}'.",
                )
                time.sleep(poll_delay)
>       raise ValueError(f"TIMEOUT: Failed to fetch uploaded dataset - {dataset_id}")
E       ValueError: TIMEOUT: Failed to fetch uploaded dataset - 1483

tests\test_datasets\test_dataset_functions.py:1200: ValueError
------------------------------ Captured log call ------------------------------
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 363: Dataset not processed yet - None'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1483 with 'https://test.openml.org/api/v1/xml/data/qualities/1483 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
_______________ TestOpenMLDataset.test_data_edit_critical_field _______________

self = <tests.test_datasets.test_dataset_functions.TestOpenMLDataset testMethod=test_data_edit_critical_field>

    def test_data_edit_critical_field(self):
        # Case 2
        # only owners (or admin) can edit all critical fields of datasets
        # for this, we need to first clone a dataset to do changes
        did = fork_dataset(1)
>       self._wait_for_dataset_being_processed(did)

tests\test_datasets\test_dataset_functions.py:1408: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <tests.test_datasets.test_dataset_functions.TestOpenMLDataset testMethod=test_data_edit_critical_field>
dataset_id = 1484, poll_delay = 10, max_waiting_time_seconds = 600

    def _wait_for_dataset_being_processed(
        self, dataset_id, poll_delay: int = 10, max_waiting_time_seconds: int = 600
    ):
        start_time = time.time()
        while (time.time() - start_time) < max_waiting_time_seconds:
            try:
                # being able to download qualities is a sign that the dataset is processed
                return openml.datasets.get_dataset(dataset_id, download_qualities=True)
            except OpenMLServerException as e:
                TestBase.logger.error(
                    f"Failed to fetch dataset:{dataset_id} with '{e!s}'.",
                )
                time.sleep(poll_delay)
>       raise ValueError(f"TIMEOUT: Failed to fetch uploaded dataset - {dataset_id}")
E       ValueError: TIMEOUT: Failed to fetch uploaded dataset - 1484

tests\test_datasets\test_dataset_functions.py:1200: ValueError
------------------------------ Captured log call ------------------------------
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 363: Dataset not processed yet - None'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
ERROR    unit_tests_published_entities:test_dataset_functions.py:1196 Failed to fetch dataset:1484 with 'https://test.openml.org/api/v1/xml/data/qualities/1484 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff'.
_________________ TestOpenMLDataset.test_get_dataset_by_name __________________

self = <tests.test_datasets.test_dataset_functions.TestOpenMLDataset testMethod=test_get_dataset_by_name>

    def test_get_dataset_by_name(self):
        dataset = openml.datasets.get_dataset("anneal")
        assert type(dataset) == OpenMLDataset
        assert dataset.dataset_id == 1
        _assert_datasets_retrieved_successfully([1])
    
>       assert len(dataset.features) > 1
                   ^^^^^^^^^^^^^^^^

tests\test_datasets\test_dataset_functions.py:253: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/1', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/1 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException
___________ TestOpenMLDataset.test_get_dataset_cache_format_feather ___________

self = <tests.test_datasets.test_dataset_functions.TestOpenMLDataset testMethod=test_get_dataset_cache_format_feather>

    def test_get_dataset_cache_format_feather(self):
        # This test crashed due to using the parquet file by default, which is downloaded
        # from minio. However, there is a mismatch between OpenML test server and minio IDs.
        # The parquet file on minio with ID 128 is not the iris dataset from the test server.
        dataset = openml.datasets.get_dataset(128, cache_format="feather")
        # Workaround
        dataset._parquet_url = None
        dataset.parquet_file = None
>       dataset.get_data()

tests\test_datasets\test_dataset_functions.py:1358: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:750: in get_data
    data, categorical_mask, attribute_names = self._load_data()
                                              ^^^^^^^^^^^^^^^^^
openml\datasets\dataset.py:626: in _load_data
    self._download_data()
openml\datasets\dataset.py:383: in _download_data
    self.data_file = str(_get_dataset_arff(self))
                         ^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1234: in _get_dataset_arff
    openml._api_calls._download_text_file(
openml\_api_calls.py:275: in _download_text_file
    response = __read_url(source, request_method="get", md5_checksum=md5_checksum)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
openml\_api_calls.py:452: in __check_response
    raise __parse_server_exception(response, url, file_elements=file_elements)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [404]>
url = 'https://test.openml.org/data/v1/download/128/iris.arff'
file_elements = None

    def __parse_server_exception(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> OpenMLServerError:
        if response.status_code == requests.codes.URI_TOO_LONG:
            raise OpenMLServerError(f"URI too long! ({url})")
    
        # OpenML has a sophisticated error system where information about failures is provided,
        # in the response body itself.
        # First, we need to parse it out.
        try:
            server_exception = xmltodict.parse(response.text)
        except xml.parsers.expat.ExpatError as e:
            raise e
        except Exception as e:
            # If we failed to parse it out, then something has gone wrong in the body we have sent back
            # from the server and there is little extra information we can capture.
            raise OpenMLServerError(
                f"Unexpected server error when calling {url}. Please contact the developers!\n"
                f"Status code: {response.status_code}\n{response.text}",
            ) from e
    
        # Now we can parse out the specific error codes that we return. These
        # are in addition to the typical HTTP error codes, but encode more
        # specific informtion. You can find these codes here:
        # https://github.com/openml/OpenML/blob/develop/openml_OS/views/pages/api_new/v1/xml/pre.php
>       server_error = server_exception["oml:error"]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       KeyError: 'oml:error'

openml\_api_calls.py:484: KeyError
___________ TestOpenMLDataset.test_get_dataset_cache_format_pickle ____________

self = <tests.test_datasets.test_dataset_functions.TestOpenMLDataset testMethod=test_get_dataset_cache_format_pickle>

    def test_get_dataset_cache_format_pickle(self):
        dataset = openml.datasets.get_dataset(1)
>       dataset.get_data()

tests\test_datasets\test_dataset_functions.py:1337: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:750: in get_data
    data, categorical_mask, attribute_names = self._load_data()
                                              ^^^^^^^^^^^^^^^^^
openml\datasets\dataset.py:626: in _load_data
    self._download_data()
openml\datasets\dataset.py:383: in _download_data
    self.data_file = str(_get_dataset_arff(self))
                         ^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1234: in _get_dataset_arff
    openml._api_calls._download_text_file(
openml\_api_calls.py:275: in _download_text_file
    response = __read_url(source, request_method="get", md5_checksum=md5_checksum)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
openml\_api_calls.py:452: in __check_response
    raise __parse_server_exception(response, url, file_elements=file_elements)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [404]>
url = 'https://test.openml.org/data/v1/download/1/anneal.arff'
file_elements = None

    def __parse_server_exception(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> OpenMLServerError:
        if response.status_code == requests.codes.URI_TOO_LONG:
            raise OpenMLServerError(f"URI too long! ({url})")
    
        # OpenML has a sophisticated error system where information about failures is provided,
        # in the response body itself.
        # First, we need to parse it out.
        try:
            server_exception = xmltodict.parse(response.text)
        except xml.parsers.expat.ExpatError as e:
            raise e
        except Exception as e:
            # If we failed to parse it out, then something has gone wrong in the body we have sent back
            # from the server and there is little extra information we can capture.
            raise OpenMLServerError(
                f"Unexpected server error when calling {url}. Please contact the developers!\n"
                f"Status code: {response.status_code}\n{response.text}",
            ) from e
    
        # Now we can parse out the specific error codes that we return. These
        # are in addition to the typical HTTP error codes, but encode more
        # specific informtion. You can find these codes here:
        # https://github.com/openml/OpenML/blob/develop/openml_OS/views/pages/api_new/v1/xml/pre.php
>       server_error = server_exception["oml:error"]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       KeyError: 'oml:error'

openml\_api_calls.py:484: KeyError
____________ TestOpenMLDataset.test_get_dataset_lazy_all_functions ____________

self = <tests.test_datasets.test_dataset_functions.TestOpenMLDataset testMethod=test_get_dataset_lazy_all_functions>

    def test_get_dataset_lazy_all_functions(self):
        """Test that all expected functionality is available without downloading the dataset."""
        dataset = openml.datasets.get_dataset(1)
        # We only tests functions as general integrity is tested by test_get_dataset_lazy
    
        def ensure_absence_of_real_data():
            assert not os.path.exists(
                os.path.join(openml.config.get_cache_directory(), "datasets", "1", "dataset.arff")
            )
    
        tag = "test_lazy_tag_%d" % random.randint(1, 1000000)
        dataset.push_tag(tag)
        ensure_absence_of_real_data()
    
        dataset.remove_tag(tag)
        ensure_absence_of_real_data()
    
>       nominal_indices = dataset.get_features_by_type("nominal")
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_datasets\test_dataset_functions.py:300: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:913: in get_features_by_type
    for idx in self.features:
               ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/1', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/1 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException
__________________ TestOpenMLDataset.test_get_dataset_sparse __________________

self = <tests.test_datasets.test_dataset_functions.TestOpenMLDataset testMethod=test_get_dataset_sparse>

    def test_get_dataset_sparse(self):
        dataset = openml.datasets.get_dataset(102)
>       X, *_ = dataset.get_data()
                ^^^^^^^^^^^^^^^^^^

tests\test_datasets\test_dataset_functions.py:314: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:750: in get_data
    data, categorical_mask, attribute_names = self._load_data()
                                              ^^^^^^^^^^^^^^^^^
openml\datasets\dataset.py:626: in _load_data
    self._download_data()
openml\datasets\dataset.py:383: in _download_data
    self.data_file = str(_get_dataset_arff(self))
                         ^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1234: in _get_dataset_arff
    openml._api_calls._download_text_file(
openml\_api_calls.py:275: in _download_text_file
    response = __read_url(source, request_method="get", md5_checksum=md5_checksum)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
openml\_api_calls.py:452: in __check_response
    raise __parse_server_exception(response, url, file_elements=file_elements)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [404]>
url = 'https://test.openml.org/data/v1/download/102/fourclass_scale.sparse_arff'
file_elements = None

    def __parse_server_exception(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> OpenMLServerError:
        if response.status_code == requests.codes.URI_TOO_LONG:
            raise OpenMLServerError(f"URI too long! ({url})")
    
        # OpenML has a sophisticated error system where information about failures is provided,
        # in the response body itself.
        # First, we need to parse it out.
        try:
            server_exception = xmltodict.parse(response.text)
        except xml.parsers.expat.ExpatError as e:
            raise e
        except Exception as e:
            # If we failed to parse it out, then something has gone wrong in the body we have sent back
            # from the server and there is little extra information we can capture.
            raise OpenMLServerError(
                f"Unexpected server error when calling {url}. Please contact the developers!\n"
                f"Status code: {response.status_code}\n{response.text}",
            ) from e
    
        # Now we can parse out the specific error codes that we return. These
        # are in addition to the typical HTTP error codes, but encode more
        # specific informtion. You can find these codes here:
        # https://github.com/openml/OpenML/blob/develop/openml_OS/views/pages/api_new/v1/xml/pre.php
>       server_error = server_exception["oml:error"]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       KeyError: 'oml:error'

openml\_api_calls.py:484: KeyError
_______________ TestOpenMLDataset.test_get_dataset_uint8_dtype ________________

self = <tests.test_datasets.test_dataset_functions.TestOpenMLDataset testMethod=test_get_dataset_uint8_dtype>

    def test_get_dataset_uint8_dtype(self):
        dataset = openml.datasets.get_dataset(1)
        assert type(dataset) == OpenMLDataset
        assert dataset.name == "anneal"
>       df, _, _, _ = dataset.get_data()
                      ^^^^^^^^^^^^^^^^^^

tests\test_datasets\test_dataset_functions.py:269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:750: in get_data
    data, categorical_mask, attribute_names = self._load_data()
                                              ^^^^^^^^^^^^^^^^^
openml\datasets\dataset.py:626: in _load_data
    self._download_data()
openml\datasets\dataset.py:383: in _download_data
    self.data_file = str(_get_dataset_arff(self))
                         ^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1234: in _get_dataset_arff
    openml._api_calls._download_text_file(
openml\_api_calls.py:275: in _download_text_file
    response = __read_url(source, request_method="get", md5_checksum=md5_checksum)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
openml\_api_calls.py:452: in __check_response
    raise __parse_server_exception(response, url, file_elements=file_elements)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [404]>
url = 'https://test.openml.org/data/v1/download/1/anneal.arff'
file_elements = None

    def __parse_server_exception(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> OpenMLServerError:
        if response.status_code == requests.codes.URI_TOO_LONG:
            raise OpenMLServerError(f"URI too long! ({url})")
    
        # OpenML has a sophisticated error system where information about failures is provided,
        # in the response body itself.
        # First, we need to parse it out.
        try:
            server_exception = xmltodict.parse(response.text)
        except xml.parsers.expat.ExpatError as e:
            raise e
        except Exception as e:
            # If we failed to parse it out, then something has gone wrong in the body we have sent back
            # from the server and there is little extra information we can capture.
            raise OpenMLServerError(
                f"Unexpected server error when calling {url}. Please contact the developers!\n"
                f"Status code: {response.status_code}\n{response.text}",
            ) from e
    
        # Now we can parse out the specific error codes that we return. These
        # are in addition to the typical HTTP error codes, but encode more
        # specific informtion. You can find these codes here:
        # https://github.com/openml/OpenML/blob/develop/openml_OS/views/pages/api_new/v1/xml/pre.php
>       server_error = server_exception["oml:error"]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       KeyError: 'oml:error'

openml\_api_calls.py:484: KeyError
_______________ TestOpenMLDataset.test_get_online_dataset_arff ________________

self = <tests.test_datasets.test_dataset_functions.TestOpenMLDataset testMethod=test_get_online_dataset_arff>

    def test_get_online_dataset_arff(self):
        dataset_id = 100  # Australian
        # lazy loading not used as arff file is checked.
>       dataset = openml.datasets.get_dataset(dataset_id, download_data=True)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_datasets\test_dataset_functions.py:859: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:511: in get_dataset
    arff_file = _get_dataset_arff(description)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1234: in _get_dataset_arff
    openml._api_calls._download_text_file(
openml\_api_calls.py:275: in _download_text_file
    response = __read_url(source, request_method="get", md5_checksum=md5_checksum)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
openml\_api_calls.py:452: in __check_response
    raise __parse_server_exception(response, url, file_elements=file_elements)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [404]>
url = 'https://test.openml.org/data/v1/download/100/Australian.arff'
file_elements = None

    def __parse_server_exception(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> OpenMLServerError:
        if response.status_code == requests.codes.URI_TOO_LONG:
            raise OpenMLServerError(f"URI too long! ({url})")
    
        # OpenML has a sophisticated error system where information about failures is provided,
        # in the response body itself.
        # First, we need to parse it out.
        try:
            server_exception = xmltodict.parse(response.text)
        except xml.parsers.expat.ExpatError as e:
            raise e
        except Exception as e:
            # If we failed to parse it out, then something has gone wrong in the body we have sent back
            # from the server and there is little extra information we can capture.
            raise OpenMLServerError(
                f"Unexpected server error when calling {url}. Please contact the developers!\n"
                f"Status code: {response.status_code}\n{response.text}",
            ) from e
    
        # Now we can parse out the specific error codes that we return. These
        # are in addition to the typical HTTP error codes, but encode more
        # specific informtion. You can find these codes here:
        # https://github.com/openml/OpenML/blob/develop/openml_OS/views/pages/api_new/v1/xml/pre.php
>       server_error = server_exception["oml:error"]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       KeyError: 'oml:error'

openml\_api_calls.py:484: KeyError
___________________ TestOpenMLDataset.test_publish_dataset ____________________

self = <tests.test_datasets.test_dataset_functions.TestOpenMLDataset testMethod=test_publish_dataset>

    def test_publish_dataset(self):
        # lazy loading not possible as we need the arff-file.
>       openml.datasets.get_dataset(3, download_data=True)

tests\test_datasets\test_dataset_functions.py:511: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:511: in get_dataset
    arff_file = _get_dataset_arff(description)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1234: in _get_dataset_arff
    openml._api_calls._download_text_file(
openml\_api_calls.py:275: in _download_text_file
    response = __read_url(source, request_method="get", md5_checksum=md5_checksum)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
openml\_api_calls.py:452: in __check_response
    raise __parse_server_exception(response, url, file_elements=file_elements)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [404]>
url = 'https://test.openml.org/data/v1/download/3/letter.arff'
file_elements = None

    def __parse_server_exception(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> OpenMLServerError:
        if response.status_code == requests.codes.URI_TOO_LONG:
            raise OpenMLServerError(f"URI too long! ({url})")
    
        # OpenML has a sophisticated error system where information about failures is provided,
        # in the response body itself.
        # First, we need to parse it out.
        try:
            server_exception = xmltodict.parse(response.text)
        except xml.parsers.expat.ExpatError as e:
            raise e
        except Exception as e:
            # If we failed to parse it out, then something has gone wrong in the body we have sent back
            # from the server and there is little extra information we can capture.
            raise OpenMLServerError(
                f"Unexpected server error when calling {url}. Please contact the developers!\n"
                f"Status code: {response.status_code}\n{response.text}",
            ) from e
    
        # Now we can parse out the specific error codes that we return. These
        # are in addition to the typical HTTP error codes, but encode more
        # specific informtion. You can find these codes here:
        # https://github.com/openml/OpenML/blob/develop/openml_OS/views/pages/api_new/v1/xml/pre.php
>       server_error = server_exception["oml:error"]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       KeyError: 'oml:error'

openml\_api_calls.py:484: KeyError
____________________ test_list_datasets_by_number_features ____________________

all_datasets =        did  ... NumberOfSymbolicFeatures
1        1  ...                      NaN
2        2  ...                     ...         0.0
1486  1486  ...                      NaN
1487  1487  ...                      1.0

[222 rows x 15 columns]

    def test_list_datasets_by_number_features(all_datasets: pd.DataFrame):
        wide_datasets = openml.datasets.list_datasets(number_features="50..100")
>       assert 8 <= len(wide_datasets) < len(all_datasets)
E       assert 8 <= 0
E        +  where 0 = len(Empty DataFrame\nColumns: []\nIndex: [])

tests\test_datasets\test_dataset_functions.py:1807: AssertionError
_________________ test_list_datasets_by_number_missing_values _________________

all_datasets =        did  ... NumberOfSymbolicFeatures
1        1  ...                      NaN
2        2  ...                     ...         0.0
1486  1486  ...                      NaN
1487  1487  ...                      1.0

[222 rows x 15 columns]

    def test_list_datasets_by_number_missing_values(all_datasets: pd.DataFrame):
        na_datasets = openml.datasets.list_datasets(number_missing_values="5..100")
>       assert 5 <= len(na_datasets) < len(all_datasets)
E       assert 5 <= 1
E        +  where 1 = len(     did            name  ...  NumberOfNumericFeatures NumberOfSymbolicFeatures\n129  129  iris-challenge  ...                      4.0                      1.0\n\n[1 rows x 15 columns])

tests\test_datasets\test_dataset_functions.py:1819: AssertionError
_____________________ test_list_datasets_combined_filters _____________________

all_datasets =        did  ... NumberOfSymbolicFeatures
1        1  ...                      NaN
2        2  ...                     ...         0.0
1486  1486  ...                      NaN
1487  1487  ...                      1.0

[222 rows x 15 columns]

    def test_list_datasets_combined_filters(all_datasets: pd.DataFrame):
        combined_filter_datasets = openml.datasets.list_datasets(
            tag="study_14",
            number_instances="100..1000",
            number_missing_values="800..1000",
        )
>       assert 1 <= len(combined_filter_datasets) < len(all_datasets)
E       assert 1 <= 0
E        +  where 0 = len(Empty DataFrame\nColumns: []\nIndex: [])

tests\test_datasets\test_dataset_functions.py:1829: AssertionError
_______________ test_get_dataset_lazy_behavior[True-True-True] ________________

isolate_for_test = None, with_data = True, with_qualities = True
with_features = True

    @pytest.mark.parametrize(
        ("with_data", "with_qualities", "with_features"),
        itertools.product([True, False], repeat=3),
    )
    def test_get_dataset_lazy_behavior(
        isolate_for_test, with_data: bool, with_qualities: bool, with_features: bool
    ):
>       dataset = openml.datasets.get_dataset(
            1,
            download_data=with_data,
            download_qualities=with_qualities,
            download_features_meta_data=with_features,
        )

C:\Users\ASUS\Documents\work\opensource\openml-python\tests\test_datasets\test_dataset_functions.py:1898: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:520: in get_dataset
    raise e
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:491: in get_dataset
    features_file = _get_dataset_features_file(did_cache_dir, dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:342: in __read_url
    return _send_request(
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:413: in _send_request
    raise e
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/1', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/1 returned code 274: No features found. Additionally, dataset processed with error - None

C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:452: OpenMLServerException
_______________ test_get_dataset_lazy_behavior[True-True-False] _______________

did_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_datasets.test_dataset_functions.TestOpenMLDataset.runTest060c916604874d278d41b653ae15822e/org/openml/test/datasets/1')
dataset_id = 1

    def _get_dataset_qualities_file(
        did_cache_dir: str | Path | None,
        dataset_id: int,
    ) -> Path | None:
        """Get the path for the dataset qualities file, or None if no qualities exist.
    
        Loads from cache or downloads them.
        Features are metafeatures (number of features, number of classes, ...)
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        did_cache_dir : str or None
            Cache subdirectory for this dataset
    
        dataset_id : int
            Dataset ID
    
        Returns
        -------
        str
            Path of the cached qualities file
        """
        save_did_cache_dir = (
            _create_cache_directory_for_id(DATASETS_CACHE_DIR_NAME, dataset_id)
            if did_cache_dir is None
            else Path(did_cache_dir)
        )
    
        # Dataset qualities are subject to change and must be fetched every time
        qualities_file = save_did_cache_dir / "qualities.xml"
        try:
>           with qualities_file.open(encoding="utf8") as fh:
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:1326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_datasets.test_dataset_functions.TestOpenMLDataset.runTest060c916604874d278d41b653ae15822e/org/openml/test/datasets/1/qualities.xml')
mode = 'r', buffering = -1, encoding = 'utf8', errors = None, newline = None

    def open(self, mode='r', buffering=-1, encoding=None,
             errors=None, newline=None):
        """
        Open the file pointed to by this path and return a file object, as
        the built-in open() function does.
        """
        if "b" not in mode:
            encoding = io.text_encoding(encoding)
>       return io.open(self, mode, buffering, encoding, errors, newline)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       FileNotFoundError: [Errno 2] No such file or directory: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_datasets.test_dataset_functions.TestOpenMLDataset.runTest060c916604874d278d41b653ae15822e\\org\\openml\\test\\datasets\\1\\qualities.xml'

C:\Users\ASUS\AppData\Local\Python\pythoncore-3.14-64\Lib\pathlib\__init__.py:776: FileNotFoundError

During handling of the above exception, another exception occurred:

isolate_for_test = None, with_data = True, with_qualities = True
with_features = False

    @pytest.mark.parametrize(
        ("with_data", "with_qualities", "with_features"),
        itertools.product([True, False], repeat=3),
    )
    def test_get_dataset_lazy_behavior(
        isolate_for_test, with_data: bool, with_qualities: bool, with_features: bool
    ):
>       dataset = openml.datasets.get_dataset(
            1,
            download_data=with_data,
            download_qualities=with_qualities,
            download_features_meta_data=with_features,
        )

C:\Users\ASUS\Documents\work\opensource\openml-python\tests\test_datasets\test_dataset_functions.py:1898: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:520: in get_dataset
    raise e
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:493: in get_dataset
    qualities_file = _get_dataset_qualities_file(did_cache_dir, dataset_id)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:1339: in _get_dataset_qualities_file
    raise e
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:1330: in _get_dataset_qualities_file
    qualities_xml = _get_qualities_xml(dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:1290: in _get_qualities_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:342: in __read_url
    return _send_request(
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:413: in _send_request
    raise e
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/qualities/1'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/qualities/1 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff

C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:452: OpenMLServerException
_______________ test_get_dataset_lazy_behavior[True-False-True] _______________

isolate_for_test = None, with_data = True, with_qualities = False
with_features = True

    @pytest.mark.parametrize(
        ("with_data", "with_qualities", "with_features"),
        itertools.product([True, False], repeat=3),
    )
    def test_get_dataset_lazy_behavior(
        isolate_for_test, with_data: bool, with_qualities: bool, with_features: bool
    ):
>       dataset = openml.datasets.get_dataset(
            1,
            download_data=with_data,
            download_qualities=with_qualities,
            download_features_meta_data=with_features,
        )

C:\Users\ASUS\Documents\work\opensource\openml-python\tests\test_datasets\test_dataset_functions.py:1898: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:520: in get_dataset
    raise e
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:491: in get_dataset
    features_file = _get_dataset_features_file(did_cache_dir, dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:342: in __read_url
    return _send_request(
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:413: in _send_request
    raise e
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/1', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/1 returned code 274: No features found. Additionally, dataset processed with error - None

C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:452: OpenMLServerException
______________ test_get_dataset_lazy_behavior[True-False-False] _______________

isolate_for_test = None, with_data = True, with_qualities = False
with_features = False

    @pytest.mark.parametrize(
        ("with_data", "with_qualities", "with_features"),
        itertools.product([True, False], repeat=3),
    )
    def test_get_dataset_lazy_behavior(
        isolate_for_test, with_data: bool, with_qualities: bool, with_features: bool
    ):
>       dataset = openml.datasets.get_dataset(
            1,
            download_data=with_data,
            download_qualities=with_qualities,
            download_features_meta_data=with_features,
        )

C:\Users\ASUS\Documents\work\opensource\openml-python\tests\test_datasets\test_dataset_functions.py:1898: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:511: in get_dataset
    arff_file = _get_dataset_arff(description)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:1234: in _get_dataset_arff
    openml._api_calls._download_text_file(
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:275: in _download_text_file
    response = __read_url(source, request_method="get", md5_checksum=md5_checksum)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:342: in __read_url
    return _send_request(
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:452: in __check_response
    raise __parse_server_exception(response, url, file_elements=file_elements)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [404]>
url = 'https://test.openml.org/data/v1/download/1/anneal.arff'
file_elements = None

    def __parse_server_exception(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> OpenMLServerError:
        if response.status_code == requests.codes.URI_TOO_LONG:
            raise OpenMLServerError(f"URI too long! ({url})")
    
        # OpenML has a sophisticated error system where information about failures is provided,
        # in the response body itself.
        # First, we need to parse it out.
        try:
            server_exception = xmltodict.parse(response.text)
        except xml.parsers.expat.ExpatError as e:
            raise e
        except Exception as e:
            # If we failed to parse it out, then something has gone wrong in the body we have sent back
            # from the server and there is little extra information we can capture.
            raise OpenMLServerError(
                f"Unexpected server error when calling {url}. Please contact the developers!\n"
                f"Status code: {response.status_code}\n{response.text}",
            ) from e
    
        # Now we can parse out the specific error codes that we return. These
        # are in addition to the typical HTTP error codes, but encode more
        # specific informtion. You can find these codes here:
        # https://github.com/openml/OpenML/blob/develop/openml_OS/views/pages/api_new/v1/xml/pre.php
>       server_error = server_exception["oml:error"]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       KeyError: 'oml:error'

C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:484: KeyError
_______________ test_get_dataset_lazy_behavior[False-True-True] _______________

isolate_for_test = None, with_data = False, with_qualities = True
with_features = True

    @pytest.mark.parametrize(
        ("with_data", "with_qualities", "with_features"),
        itertools.product([True, False], repeat=3),
    )
    def test_get_dataset_lazy_behavior(
        isolate_for_test, with_data: bool, with_qualities: bool, with_features: bool
    ):
>       dataset = openml.datasets.get_dataset(
            1,
            download_data=with_data,
            download_qualities=with_qualities,
            download_features_meta_data=with_features,
        )

C:\Users\ASUS\Documents\work\opensource\openml-python\tests\test_datasets\test_dataset_functions.py:1898: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:520: in get_dataset
    raise e
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:491: in get_dataset
    features_file = _get_dataset_features_file(did_cache_dir, dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:342: in __read_url
    return _send_request(
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:413: in _send_request
    raise e
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/1', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/1 returned code 274: No features found. Additionally, dataset processed with error - None

C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:452: OpenMLServerException
______________ test_get_dataset_lazy_behavior[False-True-False] _______________

did_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_datasets.test_dataset_functions.TestOpenMLDataset.runTest312b1c80a5544603abd75c6623958e58/org/openml/test/datasets/1')
dataset_id = 1

    def _get_dataset_qualities_file(
        did_cache_dir: str | Path | None,
        dataset_id: int,
    ) -> Path | None:
        """Get the path for the dataset qualities file, or None if no qualities exist.
    
        Loads from cache or downloads them.
        Features are metafeatures (number of features, number of classes, ...)
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        did_cache_dir : str or None
            Cache subdirectory for this dataset
    
        dataset_id : int
            Dataset ID
    
        Returns
        -------
        str
            Path of the cached qualities file
        """
        save_did_cache_dir = (
            _create_cache_directory_for_id(DATASETS_CACHE_DIR_NAME, dataset_id)
            if did_cache_dir is None
            else Path(did_cache_dir)
        )
    
        # Dataset qualities are subject to change and must be fetched every time
        qualities_file = save_did_cache_dir / "qualities.xml"
        try:
>           with qualities_file.open(encoding="utf8") as fh:
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:1326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_datasets.test_dataset_functions.TestOpenMLDataset.runTest312b1c80a5544603abd75c6623958e58/org/openml/test/datasets/1/qualities.xml')
mode = 'r', buffering = -1, encoding = 'utf8', errors = None, newline = None

    def open(self, mode='r', buffering=-1, encoding=None,
             errors=None, newline=None):
        """
        Open the file pointed to by this path and return a file object, as
        the built-in open() function does.
        """
        if "b" not in mode:
            encoding = io.text_encoding(encoding)
>       return io.open(self, mode, buffering, encoding, errors, newline)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       FileNotFoundError: [Errno 2] No such file or directory: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_datasets.test_dataset_functions.TestOpenMLDataset.runTest312b1c80a5544603abd75c6623958e58\\org\\openml\\test\\datasets\\1\\qualities.xml'

C:\Users\ASUS\AppData\Local\Python\pythoncore-3.14-64\Lib\pathlib\__init__.py:776: FileNotFoundError

During handling of the above exception, another exception occurred:

isolate_for_test = None, with_data = False, with_qualities = True
with_features = False

    @pytest.mark.parametrize(
        ("with_data", "with_qualities", "with_features"),
        itertools.product([True, False], repeat=3),
    )
    def test_get_dataset_lazy_behavior(
        isolate_for_test, with_data: bool, with_qualities: bool, with_features: bool
    ):
>       dataset = openml.datasets.get_dataset(
            1,
            download_data=with_data,
            download_qualities=with_qualities,
            download_features_meta_data=with_features,
        )

C:\Users\ASUS\Documents\work\opensource\openml-python\tests\test_datasets\test_dataset_functions.py:1898: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:520: in get_dataset
    raise e
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:493: in get_dataset
    qualities_file = _get_dataset_qualities_file(did_cache_dir, dataset_id)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:1339: in _get_dataset_qualities_file
    raise e
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:1330: in _get_dataset_qualities_file
    qualities_xml = _get_qualities_xml(dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:1290: in _get_qualities_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:342: in __read_url
    return _send_request(
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:413: in _send_request
    raise e
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/qualities/1'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/qualities/1 returned code 364: Dataset processed with error - https://www.openml.org/minio/datasets/0000/0001/anneal.arff

C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:452: OpenMLServerException
______________ test_get_dataset_lazy_behavior[False-False-True] _______________

isolate_for_test = None, with_data = False, with_qualities = False
with_features = True

    @pytest.mark.parametrize(
        ("with_data", "with_qualities", "with_features"),
        itertools.product([True, False], repeat=3),
    )
    def test_get_dataset_lazy_behavior(
        isolate_for_test, with_data: bool, with_qualities: bool, with_features: bool
    ):
>       dataset = openml.datasets.get_dataset(
            1,
            download_data=with_data,
            download_qualities=with_qualities,
            download_features_meta_data=with_features,
        )

C:\Users\ASUS\Documents\work\opensource\openml-python\tests\test_datasets\test_dataset_functions.py:1898: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:520: in get_dataset
    raise e
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:491: in get_dataset
    features_file = _get_dataset_features_file(did_cache_dir, dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:342: in __read_url
    return _send_request(
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:413: in _send_request
    raise e
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/1', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/1 returned code 274: No features found. Additionally, dataset processed with error - None

C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:452: OpenMLServerException
______________ test_get_dataset_lazy_behavior[False-False-False] ______________

isolate_for_test = None, with_data = False, with_qualities = False
with_features = False

    @pytest.mark.parametrize(
        ("with_data", "with_qualities", "with_features"),
        itertools.product([True, False], repeat=3),
    )
    def test_get_dataset_lazy_behavior(
        isolate_for_test, with_data: bool, with_qualities: bool, with_features: bool
    ):
        dataset = openml.datasets.get_dataset(
            1,
            download_data=with_data,
            download_qualities=with_qualities,
            download_features_meta_data=with_features,
        )
        assert type(dataset) == OpenMLDataset
        assert dataset.name == "anneal"
    
        _assert_datasets_retrieved_successfully(
            [1],
            with_qualities=with_qualities,
            with_features=with_features,
            with_data=with_data,
        )
>       assert dataset.features, "Features should be downloaded on-demand if not during get_dataset"
               ^^^^^^^^^^^^^^^^

C:\Users\ASUS\Documents\work\opensource\openml-python\tests\test_datasets\test_dataset_functions.py:1913: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\dataset.py:275: in features
    self._load_features()
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:342: in __read_url
    return _send_request(
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:413: in _send_request
    raise e
C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/1', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/1 returned code 274: No features found. Additionally, dataset processed with error - None

C:\Users\ASUS\Documents\work\opensource\openml-python\openml\_api_calls.py:452: OpenMLServerException
___________________ test_download_all_files_observes_cache ____________________

mock_minio = <MagicMock name='Minio' id='2629730029920'>
tmp_path = WindowsPath('C:/Users/ASUS/AppData/Local/Temp/pytest-of-ASUS/pytest-21/test_download_all_files_observ0')

    @mock.patch.object(minio, "Minio")
    def test_download_all_files_observes_cache(mock_minio, tmp_path: Path) -> None:
        some_prefix, some_filename = "some/prefix", "dataset.arff"
        some_object_path = f"{some_prefix}/{some_filename}"
        some_url = f"https://not.real.com/bucket/{some_object_path}"
        mock_minio.return_value = FakeMinio(
            objects=[
                FakeObject(object_name=some_object_path, etag=str(hash(some_object_path))),
            ],
        )
    
        _download_minio_bucket(source=some_url, destination=tmp_path)
        time_created = (tmp_path / "dataset.arff").stat().st_ctime
    
        _download_minio_bucket(source=some_url, destination=tmp_path)
        time_modified = (tmp_path / some_filename).stat().st_mtime
    
>       assert time_created == time_modified
E       assert 1768426478.7007978 == 1768426478.705117

tests\test_openml\test_api_calls.py:78: AssertionError
________________ TestRun.test_offline_and_online_run_identical ________________

task_id = 119, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run.TestRun.test_offline_and_online_run_identical/org/openml/test/tasks/119')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run.TestRun.test_offline_and_online_run_identical/org/openml/test/tasks/119/119')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...ps://test.openml.org/t/119
Estimation Procedure.: holdout
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run.TestRun.test_offline_and_online_run_identical/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run.TestRun.test_offline_and_online_run_identical/org/openml/test/tasks/119/119')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026453095DD0>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run.TestRun.test_offline_and_online_run_identical\\org\\openml\\test\\tasks\\119\\119'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run.TestRun testMethod=test_offline_and_online_run_identical>

    @pytest.mark.sklearn()
    def test_offline_and_online_run_identical(self):
        extension = SklearnExtension()
    
>       for model, task in self._get_models_tasks_for_tests():
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run.py:341: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\test_runs\test_run.py:247: in _get_models_tasks_for_tests
    task_clf = openml.tasks.get_task(119)  # diabetes; hold out validation
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run.TestRun.test_offline_and_online_run_identical/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run.TestRun.test_offline_and_online_run_identical\org\openml\test\tasks\119\119. Please do this manually!

openml\utils.py:395: ValueError
_________________ TestRun.test_publish_with_local_loaded_flow _________________

task_id = 119, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run.TestRun.test_publish_with_local_loaded_flow/org/openml/test/tasks/119')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run.TestRun.test_publish_with_local_loaded_flow/org/openml/test/tasks/119/119')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...ps://test.openml.org/t/119
Estimation Procedure.: holdout
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run.TestRun.test_publish_with_local_loaded_flow/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run.TestRun.test_publish_with_local_loaded_flow/org/openml/test/tasks/119/119')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026453096770>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run.TestRun.test_publish_with_local_loaded_flow\\org\\openml\\test\\tasks\\119\\119'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run.TestRun testMethod=test_publish_with_local_loaded_flow>

    @pytest.mark.sklearn()
    def test_publish_with_local_loaded_flow(self):
        """
        Publish a run tied to a local flow after it has first been saved to
         and loaded from disk.
        """
        extension = SklearnExtension()
    
>       for model, task in self._get_models_tasks_for_tests():
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run.py:302: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\test_runs\test_run.py:247: in _get_models_tasks_for_tests
    task_clf = openml.tasks.get_task(119)  # diabetes; hold out validation
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run.TestRun.test_publish_with_local_loaded_flow/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run.TestRun.test_publish_with_local_loaded_flow\org\openml\test\tasks\119\119. Please do this manually!

openml\utils.py:395: ValueError
____________________________ TestRun.test_tagging _____________________________

self = <tests.test_runs.test_run.TestRun testMethod=test_tagging>

    def test_tagging(self):
        runs = openml.runs.list_runs(size=1)
>       assert not runs.empty, "Test server state is incorrect"
E       AssertionError: Test server state is incorrect
E       assert not True
E        +  where True = Empty DataFrame\nColumns: []\nIndex: [].empty

tests\test_runs\test_run.py:30: AssertionError
__________________ TestRun.test_to_from_filesystem_no_model ___________________

task_id = 119, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run.TestRun.test_to_from_filesystem_no_model/org/openml/test/tasks/119')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run.TestRun.test_to_from_filesystem_no_model/org/openml/test/tasks/119/119')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...ps://test.openml.org/t/119
Estimation Procedure.: holdout
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run.TestRun.test_to_from_filesystem_no_model/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run.TestRun.test_to_from_filesystem_no_model/org/openml/test/tasks/119/119')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x00000264530975E0>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run.TestRun.test_to_from_filesystem_no_model\\org\\openml\\test\\tasks\\119\\119'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run.TestRun testMethod=test_to_from_filesystem_no_model>

    @pytest.mark.sklearn()
    def test_to_from_filesystem_no_model(self):
        model = Pipeline(
            [("imputer", SimpleImputer(strategy="mean")), ("classifier", DummyClassifier())],
        )
>       task = openml.tasks.get_task(119)  # diabetes; crossvalidation
               ^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run.py:194: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run.TestRun.test_to_from_filesystem_no_model/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run.TestRun.test_to_from_filesystem_no_model\org\openml\test\tasks\119\119. Please do this manually!

openml\utils.py:395: ValueError
___________________ TestRun.test_to_from_filesystem_search ____________________

task_id = 119, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run.TestRun.test_to_from_filesystem_search/org/openml/test/tasks/119')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run.TestRun.test_to_from_filesystem_search/org/openml/test/tasks/119/119')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...ps://test.openml.org/t/119
Estimation Procedure.: holdout
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run.TestRun.test_to_from_filesystem_search/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run.TestRun.test_to_from_filesystem_search/org/openml/test/tasks/119/119')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026452FAC250>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run.TestRun.test_to_from_filesystem_search\\org\\openml\\test\\tasks\\119\\119'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run.TestRun testMethod=test_to_from_filesystem_search>

    @pytest.mark.sklearn()
    @pytest.mark.flaky()
    def test_to_from_filesystem_search(self):
        model = Pipeline(
            [
                ("imputer", SimpleImputer(strategy="mean")),
                ("classifier", DecisionTreeClassifier(max_depth=1)),
            ],
        )
        model = GridSearchCV(
            estimator=model,
            param_grid={
                "classifier__max_depth": [1, 2, 3, 4, 5],
                "imputer__strategy": ["mean", "median"],
            },
        )
    
>       task = openml.tasks.get_task(119)  # diabetes; crossvalidation
               ^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run.TestRun.test_to_from_filesystem_search/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run.TestRun.test_to_from_filesystem_search\org\openml\test\tasks\119\119. Please do this manually!

openml\utils.py:395: ValueError
___________________ TestRun.test_to_from_filesystem_vanilla ___________________

task_id = 119, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run.TestRun.test_to_from_filesystem_vanilla/org/openml/test/tasks/119')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run.TestRun.test_to_from_filesystem_vanilla/org/openml/test/tasks/119/119')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...ps://test.openml.org/t/119
Estimation Procedure.: holdout
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run.TestRun.test_to_from_filesystem_vanilla/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run.TestRun.test_to_from_filesystem_vanilla/org/openml/test/tasks/119/119')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026452FAC9E0>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run.TestRun.test_to_from_filesystem_vanilla\\org\\openml\\test\\tasks\\119\\119'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run.TestRun testMethod=test_to_from_filesystem_vanilla>

    @pytest.mark.sklearn()
    def test_to_from_filesystem_vanilla(self):
        model = Pipeline(
            [
                ("imputer", SimpleImputer(strategy="mean")),
                ("classifier", DecisionTreeClassifier(max_depth=1)),
            ],
        )
>       task = openml.tasks.get_task(119)  # diabetes; crossvalidation
               ^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run.py:128: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run.TestRun.test_to_from_filesystem_vanilla/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run.TestRun.test_to_from_filesystem_vanilla\org\openml\test\tasks\119\119. Please do this manually!

openml\utils.py:395: ValueError
__________________________ TestRun.test__run_exists ___________________________

task_id = 115, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test__run_exists/org/openml/test/tasks/115')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test__run_exists/org/openml/test/tasks/115/115')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...t.openml.org/t/115
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test__run_exists/org/openml/test/tasks/115/115')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test__run_exists/org/openml/test/tasks/115/115')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026452FAC720>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run_functions.TestRun.test__run_exists\\org\\openml\\test\\tasks\\115\\115'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run_functions.TestRun testMethod=test__run_exists>

    @pytest.mark.sklearn()
    @unittest.skipIf(
        Version(sklearn.__version__) < Version("0.20"),
        reason="SimpleImputer doesn't handle mixed type DataFrame as input",
    )
    def test__run_exists(self):
        # would be better to not sentinel these clfs,
        # so we do not have to perform the actual runs
        # and can just check their status on line
        rs = 1
        clfs = [
            sklearn.pipeline.Pipeline(
                steps=[
                    ("Imputer", SimpleImputer(strategy="mean")),
                    ("VarianceThreshold", VarianceThreshold(threshold=0.05)),
                    ("Estimator", DecisionTreeClassifier(max_depth=4)),
                ],
            ),
            sklearn.pipeline.Pipeline(
                steps=[
                    ("Imputer", SimpleImputer(strategy="most_frequent")),
                    ("VarianceThreshold", VarianceThreshold(threshold=0.1)),
                    ("Estimator", DecisionTreeClassifier(max_depth=4)),
                ],
            ),
        ]
    
>       task = openml.tasks.get_task(115)  # diabetes; crossvalidation
               ^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run_functions.py:1190: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test__run_exists/org/openml/test/tasks/115/115')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run_functions.TestRun.test__run_exists\org\openml\test\tasks\115\115. Please do this manually!

openml\utils.py:395: ValueError
___________________ TestRun.test__run_task_get_arffcontent ____________________

task_id = 7, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test__run_task_get_arffcontent/org/openml/test/tasks/7')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test__run_task_get_arffcontent/org/openml/test/tasks/7/7')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...est.openml.org/t/7
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: kr-vs-kp
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...https://test.openml.org/data/v1/download/2/kr-vs-kp.arff
OpenML URL...: https://test.openml.org/d/2
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/2', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/2 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test__run_task_get_arffcontent/org/openml/test/tasks/7/7')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test__run_task_get_arffcontent/org/openml/test/tasks/7/7')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026452FADBC0>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run_functions.TestRun.test__run_task_get_arffcontent\\org\\openml\\test\\tasks\\7\\7'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run_functions.TestRun testMethod=test__run_task_get_arffcontent>

    @pytest.mark.sklearn()
    @unittest.skipIf(
        Version(sklearn.__version__) < Version("0.20"),
        reason="OneHotEncoder cannot handle mixed type DataFrame as input",
    )
    def test__run_task_get_arffcontent(self):
>       task = openml.tasks.get_task(7)  # kr-vs-kp; crossvalidation
               ^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run_functions.py:1341: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test__run_task_get_arffcontent/org/openml/test/tasks/7/7')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run_functions.TestRun.test__run_task_get_arffcontent\org\openml\test\tasks\7\7. Please do this manually!

openml\utils.py:395: ValueError
_______________ TestRun.test_check_erronous_sklearn_flow_fails ________________

task_id = 115, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_check_erronous_sklearn_flow_fails/org/openml/test/tasks/115')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_check_erronous_sklearn_flow_fails/org/openml/test/tasks/115/115')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...t.openml.org/t/115
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_check_erronous_sklearn_flow_fails/org/openml/test/tasks/115/115')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_check_erronous_sklearn_flow_fails/org/openml/test/tasks/115/115')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026452FAE090>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run_functions.TestRun.test_check_erronous_sklearn_flow_fails\\org\\openml\\test\\tasks\\115\\115'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run_functions.TestRun testMethod=test_check_erronous_sklearn_flow_fails>

    @pytest.mark.sklearn()
    def test_check_erronous_sklearn_flow_fails(self):
        task_id = 115  # diabetes; crossvalidation
>       task = openml.tasks.get_task(task_id)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run_functions.py:419: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_check_erronous_sklearn_flow_fails/org/openml/test/tasks/115/115')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run_functions.TestRun.test_check_erronous_sklearn_flow_fails\org\openml\test\tasks\115\115. Please do this manually!

openml\utils.py:395: ValueError
___________________________ TestRun.test_delete_run ___________________________

task_id = 32, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_delete_run/org/openml/test/tasks/32')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_delete_run/org/openml/test/tasks/32/32')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...st.openml.org/t/32
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: mfeat-fourier
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04...://test.openml.org/data/v1/download/6/mfeat-fourier.arff
OpenML URL...: https://test.openml.org/d/6
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/6', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/6 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_delete_run/org/openml/test/tasks/32/32')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_delete_run/org/openml/test/tasks/32/32')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026452FADE80>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run_functions.TestRun.test_delete_run\\org\\openml\\test\\tasks\\32\\32'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run_functions.TestRun testMethod=test_delete_run>

    @unittest.skipIf(
        Version(sklearn.__version__) < Version("0.20"),
        reason="SimpleImputer doesn't handle mixed type DataFrame as input",
    )
    @pytest.mark.sklearn()
    def test_delete_run(self):
        rs = np.random.randint(1, 2**31 - 1)
        clf = sklearn.pipeline.Pipeline(
            steps=[
                (f"test_server_imputer_{rs}", SimpleImputer()),
                ("estimator", DecisionTreeClassifier()),
            ],
        )
>       task = openml.tasks.get_task(32)  # diabetes; crossvalidation
               ^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run_functions.py:1759: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_delete_run/org/openml/test/tasks/32/32')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run_functions.TestRun.test_delete_run\org\openml\test\tasks\32\32. Please do this manually!

openml\utils.py:395: ValueError
___ TestRun.test_format_prediction_classification_incomplete_probabilities ____

task_id = 119, download_splits = False
get_dataset_kwargs = {'download_data': False}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_format_prediction_classification_incomplete_probabilities/org/openml/test/tasks/119')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_format_prediction_classification_incomplete_probabilities/org/openml/test/tasks/119/119')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...ps://test.openml.org/t/119
Estimation Procedure.: holdout
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_format_prediction_classification_incomplete_probabilities/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_format_prediction_classification_incomplete_probabilities/org/openml/test/tasks/119/119')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026452FAEB90>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run_functions.TestRun.test_format_prediction_classification_incomplete_probabilities\\org\\openml\\test\\tasks\\119\\119'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run_functions.TestRun testMethod=test_format_prediction_classification_incomplete_probabilities>

    def test_format_prediction_classification_incomplete_probabilities(self):
>       classification = openml.tasks.get_task(
            self.TEST_SERVER_TASK_SIMPLE["task_id"],
            download_data=False,
        )

tests\test_runs\test_run_functions.py:1691: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_format_prediction_classification_incomplete_probabilities/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run_functions.TestRun.test_format_prediction_classification_incomplete_probabilities\org\openml\test\tasks\119\119. Please do this manually!

openml\utils.py:395: ValueError
_______ TestRun.test_format_prediction_classification_no_probabilities ________

task_id = 119, download_splits = False
get_dataset_kwargs = {'download_data': False}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_format_prediction_classification_no_probabilities/org/openml/test/tasks/119')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_format_prediction_classification_no_probabilities/org/openml/test/tasks/119/119')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...ps://test.openml.org/t/119
Estimation Procedure.: holdout
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_format_prediction_classification_no_probabilities/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_format_prediction_classification_no_probabilities/org/openml/test/tasks/119/119')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026452FAF110>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run_functions.TestRun.test_format_prediction_classification_no_probabilities\\org\\openml\\test\\tasks\\119\\119'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run_functions.TestRun testMethod=test_format_prediction_classification_no_probabilities>

    def test_format_prediction_classification_no_probabilities(self):
>       classification = openml.tasks.get_task(
            self.TEST_SERVER_TASK_SIMPLE["task_id"],
            download_data=False,
        )

tests\test_runs\test_run_functions.py:1682: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_format_prediction_classification_no_probabilities/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run_functions.TestRun.test_format_prediction_classification_no_probabilities\org\openml\test\tasks\119\119. Please do this manually!

openml\utils.py:395: ValueError
______ TestRun.test_format_prediction_task_learning_curve_sample_not_set ______

task_id = 801, download_splits = False
get_dataset_kwargs = {'download_data': False}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_format_prediction_task_learning_curve_sample_not_set/org/openml/test/tasks/801')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_format_prediction_task_learning_curve_sample_not_set/org/openml/test/tasks/801/801')
tid_cache_dir_existed = False
task = OpenML Learning Curve Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.LEARN...t.openml.org/t/801
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_format_prediction_task_learning_curve_sample_not_set/org/openml/test/tasks/801/801')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_format_prediction_task_learning_curve_sample_not_set/org/openml/test/tasks/801/801')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026452FAFC10>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run_functions.TestRun.test_format_prediction_task_learning_curve_sample_not_set\\org\\openml\\test\\tasks\\801\\801'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run_functions.TestRun testMethod=test_format_prediction_task_learning_curve_sample_not_set>

    def test_format_prediction_task_learning_curve_sample_not_set(self):
>       learning_curve = openml.tasks.get_task(801, download_data=False)  # diabetes;crossvalidation
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run_functions.py:1711: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_format_prediction_task_learning_curve_sample_not_set/org/openml/test/tasks/801/801')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run_functions.TestRun.test_format_prediction_task_learning_curve_sample_not_set\org\openml\test\tasks\801\801. Please do this manually!

openml\utils.py:395: ValueError
_________ TestRun.test_format_prediction_task_without_classlabels_set _________

task_id = 119, download_splits = False
get_dataset_kwargs = {'download_data': False}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_format_prediction_task_without_classlabels_set/org/openml/test/tasks/119')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_format_prediction_task_without_classlabels_set/org/openml/test/tasks/119/119')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...ps://test.openml.org/t/119
Estimation Procedure.: holdout
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_format_prediction_task_without_classlabels_set/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_format_prediction_task_without_classlabels_set/org/openml/test/tasks/119/119')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026452FAEE50>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run_functions.TestRun.test_format_prediction_task_without_classlabels_set\\org\\openml\\test\\tasks\\119\\119'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run_functions.TestRun testMethod=test_format_prediction_task_without_classlabels_set>

    def test_format_prediction_task_without_classlabels_set(self):
>       classification = openml.tasks.get_task(
            self.TEST_SERVER_TASK_SIMPLE["task_id"],
            download_data=False,
        )

tests\test_runs\test_run_functions.py:1701: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_format_prediction_task_without_classlabels_set/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run_functions.TestRun.test_format_prediction_task_without_classlabels_set\org\openml\test\tasks\119\119. Please do this manually!

openml\utils.py:395: ValueError
_____________________ TestRun.test_initialize_cv_from_run _____________________

task_id = 11, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_initialize_cv_from_run/org/openml/test/tasks/11')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_initialize_cv_from_run/org/openml/test/tasks/11/11')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...tps://test.openml.org/t/11
Estimation Procedure.: holdout
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: kr-vs-kp
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...https://test.openml.org/data/v1/download/2/kr-vs-kp.arff
OpenML URL...: https://test.openml.org/d/2
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/2', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/2 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_initialize_cv_from_run/org/openml/test/tasks/11/11')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_initialize_cv_from_run/org/openml/test/tasks/11/11')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x00000264492BD380>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run_functions.TestRun.test_initialize_cv_from_run\\org\\openml\\test\\tasks\\11\\11'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run_functions.TestRun testMethod=test_initialize_cv_from_run>

    @pytest.mark.sklearn()
    @unittest.skipIf(
        Version(sklearn.__version__) < Version("0.21"),
        reason="Pipelines don't support indexing (used for the assert check)",
    )
    def test_initialize_cv_from_run(self):
        randomsearch = Pipeline(
            [
                ("enc", OneHotEncoder(handle_unknown="ignore")),
                (
                    "rs",
                    RandomizedSearchCV(
                        RandomForestClassifier(n_estimators=5),
                        {
                            "max_depth": [3, None],
                            "max_features": [1, 2, 3, 4],
                            "min_samples_split": [2, 3, 4, 5, 6, 7, 8, 9, 10],
                            "min_samples_leaf": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
                            "bootstrap": [True, False],
                            "criterion": ["gini", "entropy"],
                        },
                        cv=StratifiedKFold(n_splits=2, shuffle=True),
                        n_iter=2,
                    ),
                ),
            ],
        )
    
>       task = openml.tasks.get_task(11)  # kr-vs-kp; holdout
               ^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run_functions.py:972: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_initialize_cv_from_run/org/openml/test/tasks/11/11')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run_functions.TestRun.test_initialize_cv_from_run\org\openml\test\tasks\11\11. Please do this manually!

openml\utils.py:395: ValueError
___________________ TestRun.test_initialize_model_from_run ____________________

task_id = 1196, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_initialize_model_from_run/org/openml/test/tasks/1196')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_initialize_model_from_run/org/openml/test/tasks/1196/1196')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER....openml.org/t/1196
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: iris
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 23:23...https://test.openml.org/data/v1/download/128/iris.arff
OpenML URL...: https://test.openml.org/d/128
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/128'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/128 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_initialize_model_from_run/org/openml/test/tasks/1196/1196')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_initialize_model_from_run/org/openml/test/tasks/1196/1196')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x00000264492BDA60>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run_functions.TestRun.test_initialize_model_from_run\\org\\openml\\test\\tasks\\1196\\1196'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run_functions.TestRun testMethod=test_initialize_model_from_run>

    @pytest.mark.sklearn()
    @unittest.skipIf(
        Version(sklearn.__version__) < Version("0.20"),
        reason="SimpleImputer doesn't handle mixed type DataFrame as input",
    )
    def test_initialize_model_from_run(self):
        clf = sklearn.pipeline.Pipeline(
            steps=[
                ("Imputer", SimpleImputer(strategy="most_frequent")),
                ("VarianceThreshold", VarianceThreshold(threshold=0.05)),
                ("Estimator", GaussianNB()),
            ],
        )
        task_meta_data = {
            "task_type": TaskType.SUPERVISED_CLASSIFICATION,
            "dataset_id": 128,  # iris
            "estimation_procedure_id": 1,
            "target_name": "class",
        }
>       _task_id = check_task_existence(**task_meta_data)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run_functions.py:1121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\testing.py:307: in check_task_existence
    task = openml.tasks.get_task(task_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_initialize_model_from_run/org/openml/test/tasks/1196/1196')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run_functions.TestRun.test_initialize_model_from_run\org\openml\test\tasks\1196\1196. Please do this manually!

openml\utils.py:395: ValueError
_____________________ TestRun.test_learning_curve_task_1 ______________________

task_id = 801, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_learning_curve_task_1/org/openml/test/tasks/801')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_learning_curve_task_1/org/openml/test/tasks/801/801')
tid_cache_dir_existed = False
task = OpenML Learning Curve Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.LEARN...t.openml.org/t/801
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_learning_curve_task_1/org/openml/test/tasks/801/801')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_learning_curve_task_1/org/openml/test/tasks/801/801')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x00000264492BE770>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run_functions.TestRun.test_learning_curve_task_1\\org\\openml\\test\\tasks\\801\\801'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run_functions.TestRun testMethod=test_learning_curve_task_1>

    @pytest.mark.sklearn()
    def test_learning_curve_task_1(self):
        task_id = 801  # diabates dataset
        num_test_instances = 6144  # for learning curve
        num_missing_vals = 0
        num_repeats = 1
        num_folds = 10
        num_samples = 8
    
        pipeline1 = Pipeline(
            steps=[
                ("scaler", StandardScaler(with_mean=False)),
                ("dummy", DummyClassifier(strategy="prior")),
            ],
        )
>       run = self._perform_run(
            task_id,
            num_test_instances,
            num_missing_vals,
            pipeline1,
            flow_expected_rsv="62501",
        )

tests\test_runs\test_run_functions.py:899: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\test_runs\test_run_functions.py:271: in _perform_run
    task = openml.tasks.get_task(task_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_learning_curve_task_1/org/openml/test/tasks/801/801')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run_functions.TestRun.test_learning_curve_task_1\org\openml\test\tasks\801\801. Please do this manually!

openml\utils.py:395: ValueError
------------------------------ Captured log call ------------------------------
INFO     unit_tests_published_entities:test_run_functions.py:269 collected from test_run_functions: 20801
_____________________ TestRun.test_learning_curve_task_2 ______________________

task_id = 801, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_learning_curve_task_2/org/openml/test/tasks/801')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_learning_curve_task_2/org/openml/test/tasks/801/801')
tid_cache_dir_existed = False
task = OpenML Learning Curve Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.LEARN...t.openml.org/t/801
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_learning_curve_task_2/org/openml/test/tasks/801/801')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_learning_curve_task_2/org/openml/test/tasks/801/801')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x00000264492BF110>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run_functions.TestRun.test_learning_curve_task_2\\org\\openml\\test\\tasks\\801\\801'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run_functions.TestRun testMethod=test_learning_curve_task_2>

    @pytest.mark.sklearn()
    def test_learning_curve_task_2(self):
        task_id = 801  # diabates dataset
        num_test_instances = 6144  # for learning curve
        num_missing_vals = 0
        num_repeats = 1
        num_folds = 10
        num_samples = 8
    
        pipeline2 = Pipeline(
            steps=[
                ("Imputer", SimpleImputer(strategy="median")),
                ("VarianceThreshold", VarianceThreshold()),
                (
                    "Estimator",
                    RandomizedSearchCV(
                        DecisionTreeClassifier(),
                        {
                            "min_samples_split": [2**x for x in range(1, 8)],
                            "min_samples_leaf": [2**x for x in range(7)],
                        },
                        cv=3,
                        n_iter=10,
                    ),
                ),
            ],
        )
>       run = self._perform_run(
            task_id,
            num_test_instances,
            num_missing_vals,
            pipeline2,
            flow_expected_rsv="62501",
        )

tests\test_runs\test_run_functions.py:935: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\test_runs\test_run_functions.py:271: in _perform_run
    task = openml.tasks.get_task(task_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_learning_curve_task_2/org/openml/test/tasks/801/801')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run_functions.TestRun.test_learning_curve_task_2\org\openml\test\tasks\801\801. Please do this manually!

openml\utils.py:395: ValueError
------------------------------ Captured log call ------------------------------
INFO     unit_tests_published_entities:test_run_functions.py:269 collected from test_run_functions: 20804
_____________________ TestRun.test_local_run_metric_score _____________________

task_id = 7, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_local_run_metric_score/org/openml/test/tasks/7')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_local_run_metric_score/org/openml/test/tasks/7/7')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...est.openml.org/t/7
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: kr-vs-kp
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...https://test.openml.org/data/v1/download/2/kr-vs-kp.arff
OpenML URL...: https://test.openml.org/d/2
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/2', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/2 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_local_run_metric_score/org/openml/test/tasks/7/7')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_local_run_metric_score/org/openml/test/tasks/7/7')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x00000264492BF690>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run_functions.TestRun.test_local_run_metric_score\\org\\openml\\test\\tasks\\7\\7'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run_functions.TestRun testMethod=test_local_run_metric_score>

    @pytest.mark.sklearn()
    @unittest.skipIf(
        Version(sklearn.__version__) < Version("0.20"),
        reason="SimpleImputer doesn't handle mixed type DataFrame as input",
    )
    def test_local_run_metric_score(self):
        # construct sci-kit learn classifier
        clf = Pipeline(
            steps=[
                ("imputer", SimpleImputer(strategy="most_frequent")),
                ("encoder", OneHotEncoder(handle_unknown="ignore")),
                ("estimator", RandomForestClassifier(n_estimators=10)),
            ],
        )
    
        # download task
>       task = openml.tasks.get_task(7)  # kr-vs-kp; crossvalidation
               ^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run_functions.py:1081: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_local_run_metric_score/org/openml/test/tasks/7/7')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run_functions.TestRun.test_local_run_metric_score\org\openml\test\tasks\7\7. Please do this manually!

openml\utils.py:395: ValueError
_____________ TestRun.test_local_run_swapped_parameter_order_flow _____________

task_id = 7, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_local_run_swapped_parameter_order_flow/org/openml/test/tasks/7')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_local_run_swapped_parameter_order_flow/org/openml/test/tasks/7/7')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...est.openml.org/t/7
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: kr-vs-kp
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...https://test.openml.org/data/v1/download/2/kr-vs-kp.arff
OpenML URL...: https://test.openml.org/d/2
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/2', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/2 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_local_run_swapped_parameter_order_flow/org/openml/test/tasks/7/7')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_local_run_swapped_parameter_order_flow/org/openml/test/tasks/7/7')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x00000264492BFE20>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run_functions.TestRun.test_local_run_swapped_parameter_order_flow\\org\\openml\\test\\tasks\\7\\7'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run_functions.TestRun testMethod=test_local_run_swapped_parameter_order_flow>

    @pytest.mark.sklearn()
    @unittest.skipIf(
        Version(sklearn.__version__) < Version("0.20"),
        reason="SimpleImputer doesn't handle mixed type DataFrame as input",
    )
    def test_local_run_swapped_parameter_order_flow(self):
        # construct sci-kit learn classifier
        clf = Pipeline(
            steps=[
                ("imputer", SimpleImputer(strategy="most_frequent")),
                ("encoder", OneHotEncoder(handle_unknown="ignore")),
                ("estimator", RandomForestClassifier(n_estimators=10)),
            ],
        )
    
        flow = self.extension.model_to_flow(clf)
        # download task
>       task = openml.tasks.get_task(7)  # kr-vs-kp; crossvalidation
               ^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run_functions.py:1054: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_local_run_swapped_parameter_order_flow/org/openml/test/tasks/7/7')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run_functions.TestRun.test_local_run_swapped_parameter_order_flow\org\openml\test\tasks\7\7. Please do this manually!

openml\utils.py:395: ValueError
____________ TestRun.test_local_run_swapped_parameter_order_model _____________

task_id = 595, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_local_run_swapped_parameter_order_model/org/openml/test/tasks/595')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_local_run_swapped_parameter_order_model/org/openml/test/tasks/595/595')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER.../test.openml.org/t/595
Estimation Procedure.: crossvalidation
Target Feature.......: Y
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: Australian
Version......: 3
Format.......: ARFF
Upload Date..: 2016-09-21...//test.openml.org/data/v1/download/100/Australian.arff
OpenML URL...: https://test.openml.org/d/100
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/100'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/100 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_local_run_swapped_parameter_order_model/org/openml/test/tasks/595/595')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_local_run_swapped_parameter_order_model/org/openml/test/tasks/595/595')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x00000264554A4250>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run_functions.TestRun.test_local_run_swapped_parameter_order_model\\org\\openml\\test\\tasks\\595\\595'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run_functions.TestRun testMethod=test_local_run_swapped_parameter_order_model>

    @pytest.mark.sklearn()
    def test_local_run_swapped_parameter_order_model(self):
        clf = DecisionTreeClassifier()
        australian_task = 595  # Australian; crossvalidation
>       task = openml.tasks.get_task(australian_task)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run_functions.py:1026: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_local_run_swapped_parameter_order_model/org/openml/test/tasks/595/595')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run_functions.TestRun.test_local_run_swapped_parameter_order_model\org\openml\test\tasks\595\595. Please do this manually!

openml\utils.py:395: ValueError
________________ TestRun.test_run_flow_on_task_downloaded_flow ________________

task_id = 119, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_flow_on_task_downloaded_flow/org/openml/test/tasks/119')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_flow_on_task_downloaded_flow/org/openml/test/tasks/119/119')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...ps://test.openml.org/t/119
Estimation Procedure.: holdout
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_flow_on_task_downloaded_flow/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_flow_on_task_downloaded_flow/org/openml/test/tasks/119/119')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x00000264554A6A30>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run_functions.TestRun.test_run_flow_on_task_downloaded_flow\\org\\openml\\test\\tasks\\119\\119'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run_functions.TestRun testMethod=test_run_flow_on_task_downloaded_flow>

    @pytest.mark.sklearn()
    def test_run_flow_on_task_downloaded_flow(self):
        model = sklearn.ensemble.RandomForestClassifier(n_estimators=33)
        flow = self.extension.model_to_flow(model)
        flow.publish(raise_error_if_exists=False)
        TestBase._mark_entity_for_removal("flow", flow.flow_id, flow.name)
        TestBase.logger.info(f"collected from test_run_functions: {flow.flow_id}")
    
        downloaded_flow = openml.flows.get_flow(flow.flow_id)
>       task = openml.tasks.get_task(self.TEST_SERVER_TASK_SIMPLE["task_id"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run_functions.py:1659: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_flow_on_task_downloaded_flow/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run_functions.TestRun.test_run_flow_on_task_downloaded_flow\org\openml\test\tasks\119\119. Please do this manually!

openml\utils.py:395: ValueError
------------------------------ Captured log call ------------------------------
INFO     unit_tests_published_entities:test_run_functions.py:1656 collected from test_run_functions: 2765
____________ TestRun.test_run_on_dataset_with_missing_labels_array ____________

task_id = 2, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_on_dataset_with_missing_labels_array/org/openml/test/tasks/2')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_on_dataset_with_missing_labels_array/org/openml/test/tasks/2/2')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...est.openml.org/t/2
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: anneal
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 23:...: https://test.openml.org/data/v1/download/1/anneal.arff
OpenML URL...: https://test.openml.org/d/1
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/1', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/1 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_on_dataset_with_missing_labels_array/org/openml/test/tasks/2/2')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_on_dataset_with_missing_labels_array/org/openml/test/tasks/2/2')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x00000264554A4BF0>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run_functions.TestRun.test_run_on_dataset_with_missing_labels_array\\org\\openml\\test\\tasks\\2\\2'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run_functions.TestRun testMethod=test_run_on_dataset_with_missing_labels_array>

    @pytest.mark.sklearn()
    @unittest.skipIf(
        Version(sklearn.__version__) < Version("0.20"),
        reason="columntransformer introduction in 0.20.0",
    )
    def test_run_on_dataset_with_missing_labels_array(self):
        # Check that _run_task_get_arffcontent works when one of the class
        # labels only declared in the arff file, but is not present in the
        # actual data
>       task = openml.tasks.get_task(2)  # anneal; crossvalidation
               ^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run_functions.py:1607: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_on_dataset_with_missing_labels_array/org/openml/test/tasks/2/2')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run_functions.TestRun.test_run_on_dataset_with_missing_labels_array\org\openml\test\tasks\2\2. Please do this manually!

openml\utils.py:395: ValueError
__________ TestRun.test_run_on_dataset_with_missing_labels_dataframe __________

task_id = 2, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_on_dataset_with_missing_labels_dataframe/org/openml/test/tasks/2')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_on_dataset_with_missing_labels_dataframe/org/openml/test/tasks/2/2')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...est.openml.org/t/2
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: anneal
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 23:...: https://test.openml.org/data/v1/download/1/anneal.arff
OpenML URL...: https://test.openml.org/d/1
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/1', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/1 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_on_dataset_with_missing_labels_dataframe/org/openml/test/tasks/2/2')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_on_dataset_with_missing_labels_dataframe/org/openml/test/tasks/2/2')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x00000264554A6DA0>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run_functions.TestRun.test_run_on_dataset_with_missing_labels_dataframe\\org\\openml\\test\\tasks\\2\\2'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run_functions.TestRun testMethod=test_run_on_dataset_with_missing_labels_dataframe>

    @pytest.mark.sklearn()
    @unittest.skipIf(
        Version(sklearn.__version__) < Version("0.20"),
        reason="columntransformer introduction in 0.20.0",
    )
    def test_run_on_dataset_with_missing_labels_dataframe(self):
        # Check that _run_task_get_arffcontent works when one of the class
        # labels only declared in the arff file, but is not present in the
        # actual data
>       task = openml.tasks.get_task(2)  # anneal; crossvalidation
               ^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run_functions.py:1571: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_on_dataset_with_missing_labels_dataframe/org/openml/test/tasks/2/2')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run_functions.TestRun.test_run_on_dataset_with_missing_labels_dataframe\org\openml\test\tasks\2\2. Please do this manually!

openml\utils.py:395: ValueError
_________________ TestRun.test_run_regression_on_classif_task _________________

task_id = 259, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_regression_on_classif_task/org/openml/test/tasks/259')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_regression_on_classif_task/org/openml/test/tasks/259/259')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...nml.org/t/259
Estimation Procedure.: crossvalidation
Target Feature.......: Corp.Genre
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: collins
Version......: 1
Format.......: ARFF
Upload Date..: 2014-09-28 23...ttps://test.openml.org/data/v1/download/44/collins.arff
OpenML URL...: https://test.openml.org/d/44
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/44'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/44 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_regression_on_classif_task/org/openml/test/tasks/259/259')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_regression_on_classif_task/org/openml/test/tasks/259/259')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x00000264554A7480>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run_functions.TestRun.test_run_regression_on_classif_task\\org\\openml\\test\\tasks\\259\\259'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run_functions.TestRun testMethod=test_run_regression_on_classif_task>

    @pytest.mark.sklearn()
    def test_run_regression_on_classif_task(self):
        task_id = 259  # collins; crossvalidation; has numeric targets
    
        clf = LinearRegression()
>       task = openml.tasks.get_task(task_id)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run_functions.py:405: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_regression_on_classif_task/org/openml/test/tasks/259/259')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run_functions.TestRun.test_run_regression_on_classif_task\org\openml\test\tasks\259\259. Please do this manually!

openml\utils.py:395: ValueError
____________________ TestRun.test_run_with_illegal_flow_id ____________________

task_id = 115, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id/org/openml/test/tasks/115')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id/org/openml/test/tasks/115/115')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...t.openml.org/t/115
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id/org/openml/test/tasks/115/115')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id/org/openml/test/tasks/115/115')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x00000264554A7CC0>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id\\org\\openml\\test\\tasks\\115\\115'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run_functions.TestRun testMethod=test_run_with_illegal_flow_id>

    @pytest.mark.sklearn()
    def test_run_with_illegal_flow_id(self):
        # check the case where the user adds an illegal flow id to a
        # non-existing flo
>       task = openml.tasks.get_task(115)  # diabetes; crossvalidation
               ^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run_functions.py:1226: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id/org/openml/test/tasks/115/115')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id\org\openml\test\tasks\115\115. Please do this manually!

openml\utils.py:395: ValueError
___________________ TestRun.test_run_with_illegal_flow_id_1 ___________________

task_id = 115, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id_1/org/openml/test/tasks/115')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id_1/org/openml/test/tasks/115/115')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...t.openml.org/t/115
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id_1/org/openml/test/tasks/115/115')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id_1/org/openml/test/tasks/115/115')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026452F34510>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id_1\\org\\openml\\test\\tasks\\115\\115'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run_functions.TestRun testMethod=test_run_with_illegal_flow_id_1>

    @pytest.mark.sklearn()
    def test_run_with_illegal_flow_id_1(self):
        # Check the case where the user adds an illegal flow id to an existing
        # flow. Comes to a different value error than the previous test
>       task = openml.tasks.get_task(115)  # diabetes; crossvalidation
               ^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run_functions.py:1276: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id_1/org/openml/test/tasks/115/115')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id_1\org\openml\test\tasks\115\115. Please do this manually!

openml\utils.py:395: ValueError
_____________ TestRun.test_run_with_illegal_flow_id_1_after_load ______________

task_id = 115, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id_1_after_load/org/openml/test/tasks/115')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id_1_after_load/org/openml/test/tasks/115/115')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...t.openml.org/t/115
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id_1_after_load/org/openml/test/tasks/115/115')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id_1_after_load/org/openml/test/tasks/115/115')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026452F34A90>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id_1_after_load\\org\\openml\\test\\tasks\\115\\115'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run_functions.TestRun testMethod=test_run_with_illegal_flow_id_1_after_load>

    @pytest.mark.sklearn()
    def test_run_with_illegal_flow_id_1_after_load(self):
        # Same as `test_run_with_illegal_flow_id_1`, but test this error is
        # also caught if the run is stored to and loaded from disk first.
>       task = openml.tasks.get_task(115)  # diabetes; crossvalidation
               ^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run_functions.py:1301: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id_1_after_load/org/openml/test/tasks/115/115')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id_1_after_load\org\openml\test\tasks\115\115. Please do this manually!

openml\utils.py:395: ValueError
______________ TestRun.test_run_with_illegal_flow_id_after_load _______________

task_id = 115, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id_after_load/org/openml/test/tasks/115')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id_after_load/org/openml/test/tasks/115/115')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...t.openml.org/t/115
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id_after_load/org/openml/test/tasks/115/115')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id_after_load/org/openml/test/tasks/115/115')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026452F350C0>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id_after_load\\org\\openml\\test\\tasks\\115\\115'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_runs.test_run_functions.TestRun testMethod=test_run_with_illegal_flow_id_after_load>

    @pytest.mark.sklearn()
    def test_run_with_illegal_flow_id_after_load(self):
        # Same as `test_run_with_illegal_flow_id`, but test this error is also
        # caught if the run is stored to and loaded from disk first.
>       task = openml.tasks.get_task(115)  # diabetes; crossvalidation
               ^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run_functions.py:1245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id_after_load/org/openml/test/tasks/115/115')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_runs.test_run_functions.TestRun.test_run_with_illegal_flow_id_after_load\org\openml\test\tasks\115\115. Please do this manually!

openml\utils.py:395: ValueError
______________________ test__run_task_get_arffcontent_2 _______________________

task_id = 7, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test__run_task_get_arffcontent_2/org/openml/test/tasks/7')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test__run_task_get_arffcontent_2/org/openml/test/tasks/7/7')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...est.openml.org/t/7
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: kr-vs-kp
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...https://test.openml.org/data/v1/download/2/kr-vs-kp.arff
OpenML URL...: https://test.openml.org/d/2
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/2', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/2 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test__run_task_get_arffcontent_2/org/openml/test/tasks/7/7')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test__run_task_get_arffcontent_2/org/openml/test/tasks/7/7')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026452F35F30>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\tests\\files\\test__run_task_get_arffcontent_2\\org\\openml\\test\\tasks\\7\\7'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

parallel_mock = <MagicMock name='_prevent_optimize_n_jobs' id='2629922743232'>

    @pytest.mark.sklearn()
    @unittest.skipIf(
        Version(sklearn.__version__) < Version("0.21"),
        reason="couldn't perform local tests successfully w/o bloating RAM",
        )
    @mock.patch("openml_sklearn.SklearnExtension._prevent_optimize_n_jobs")
    def test__run_task_get_arffcontent_2(parallel_mock):
        """Tests if a run executed in parallel is collated correctly."""
>       task = openml.tasks.get_task(7)  # Supervised Classification on kr-vs-kp
               ^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run_functions.py:1853: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test__run_task_get_arffcontent_2/org/openml/test/tasks/7/7')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\tests\files\test__run_task_get_arffcontent_2\org\openml\test\tasks\7\7. Please do this manually!

openml\utils.py:395: ValueError
_______________________ test_joblib_backends[2-None-0] ________________________

task_id = 7, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[2-None-0]/org/openml/test/tasks/7')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[2-None-0]/org/openml/test/tasks/7/7')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...est.openml.org/t/7
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: kr-vs-kp
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...https://test.openml.org/data/v1/download/2/kr-vs-kp.arff
OpenML URL...: https://test.openml.org/d/2
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/2', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/2 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[2-None-0]/org/openml/test/tasks/7/7')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[2-None-0]/org/openml/test/tasks/7/7')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026452F366C0>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\tests\\files\\test_joblib_backends[2-None-0]\\org\\openml\\test\\tasks\\7\\7'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

parallel_mock = <MagicMock name='_prevent_optimize_n_jobs' id='2629922742560'>
n_jobs = 2, backend = 'loky', call_count = 0

    @pytest.mark.sklearn()
    @unittest.skipIf(
        Version(sklearn.__version__) < Version("0.21"),
        reason="couldn't perform local tests successfully w/o bloating RAM",
        )
    @mock.patch("openml_sklearn.SklearnExtension._prevent_optimize_n_jobs")
    @pytest.mark.parametrize(
        ("n_jobs", "backend", "call_count"),
        [
            # `None` picks the backend based on joblib version (loky or multiprocessing) and
            # spawns multiple processes if n_jobs != 1, which means the mock is not applied.
            (2, None, 0),
            (-1, None, 0),
            (1, None, 10),  # with n_jobs=1 the mock *is* applied, since there is no new subprocess
            (1, "sequential", 10),
            (1, "threading", 10),
            (-1, "threading", 10),  # the threading backend does preserve mocks even with parallelizing
        ]
    )
    def test_joblib_backends(parallel_mock, n_jobs, backend, call_count):
        """Tests evaluation of a run using various joblib backends and n_jobs."""
        if backend is None:
            backend = (
                "loky" if Version(joblib.__version__) > Version("0.11") else "multiprocessing"
            )
    
>       task = openml.tasks.get_task(7)  # Supervised Classification on kr-vs-kp
               ^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run_functions.py:1948: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[2-None-0]/org/openml/test/tasks/7/7')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\tests\files\test_joblib_backends[2-None-0]\org\openml\test\tasks\7\7. Please do this manually!

openml\utils.py:395: ValueError
_______________________ test_joblib_backends[-1-None-0] _______________________

task_id = 7, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[-1-None-0]/org/openml/test/tasks/7')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[-1-None-0]/org/openml/test/tasks/7/7')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...est.openml.org/t/7
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: kr-vs-kp
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...https://test.openml.org/data/v1/download/2/kr-vs-kp.arff
OpenML URL...: https://test.openml.org/d/2
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/2', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/2 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[-1-None-0]/org/openml/test/tasks/7/7')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[-1-None-0]/org/openml/test/tasks/7/7')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026452F36820>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\tests\\files\\test_joblib_backends[-1-None-0]\\org\\openml\\test\\tasks\\7\\7'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

parallel_mock = <MagicMock name='_prevent_optimize_n_jobs' id='2629922744912'>
n_jobs = -1, backend = 'loky', call_count = 0

    @pytest.mark.sklearn()
    @unittest.skipIf(
        Version(sklearn.__version__) < Version("0.21"),
        reason="couldn't perform local tests successfully w/o bloating RAM",
        )
    @mock.patch("openml_sklearn.SklearnExtension._prevent_optimize_n_jobs")
    @pytest.mark.parametrize(
        ("n_jobs", "backend", "call_count"),
        [
            # `None` picks the backend based on joblib version (loky or multiprocessing) and
            # spawns multiple processes if n_jobs != 1, which means the mock is not applied.
            (2, None, 0),
            (-1, None, 0),
            (1, None, 10),  # with n_jobs=1 the mock *is* applied, since there is no new subprocess
            (1, "sequential", 10),
            (1, "threading", 10),
            (-1, "threading", 10),  # the threading backend does preserve mocks even with parallelizing
        ]
    )
    def test_joblib_backends(parallel_mock, n_jobs, backend, call_count):
        """Tests evaluation of a run using various joblib backends and n_jobs."""
        if backend is None:
            backend = (
                "loky" if Version(joblib.__version__) > Version("0.11") else "multiprocessing"
            )
    
>       task = openml.tasks.get_task(7)  # Supervised Classification on kr-vs-kp
               ^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run_functions.py:1948: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[-1-None-0]/org/openml/test/tasks/7/7')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\tests\files\test_joblib_backends[-1-None-0]\org\openml\test\tasks\7\7. Please do this manually!

openml\utils.py:395: ValueError
_______________________ test_joblib_backends[1-None-10] _______________________

task_id = 7, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[1-None-10]/org/openml/test/tasks/7')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[1-None-10]/org/openml/test/tasks/7/7')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...est.openml.org/t/7
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: kr-vs-kp
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...https://test.openml.org/data/v1/download/2/kr-vs-kp.arff
OpenML URL...: https://test.openml.org/d/2
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/2', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/2 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[1-None-10]/org/openml/test/tasks/7/7')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[1-None-10]/org/openml/test/tasks/7/7')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026453D481A0>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\tests\\files\\test_joblib_backends[1-None-10]\\org\\openml\\test\\tasks\\7\\7'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

parallel_mock = <MagicMock name='_prevent_optimize_n_jobs' id='2629922746256'>
n_jobs = 1, backend = 'loky', call_count = 10

    @pytest.mark.sklearn()
    @unittest.skipIf(
        Version(sklearn.__version__) < Version("0.21"),
        reason="couldn't perform local tests successfully w/o bloating RAM",
        )
    @mock.patch("openml_sklearn.SklearnExtension._prevent_optimize_n_jobs")
    @pytest.mark.parametrize(
        ("n_jobs", "backend", "call_count"),
        [
            # `None` picks the backend based on joblib version (loky or multiprocessing) and
            # spawns multiple processes if n_jobs != 1, which means the mock is not applied.
            (2, None, 0),
            (-1, None, 0),
            (1, None, 10),  # with n_jobs=1 the mock *is* applied, since there is no new subprocess
            (1, "sequential", 10),
            (1, "threading", 10),
            (-1, "threading", 10),  # the threading backend does preserve mocks even with parallelizing
        ]
    )
    def test_joblib_backends(parallel_mock, n_jobs, backend, call_count):
        """Tests evaluation of a run using various joblib backends and n_jobs."""
        if backend is None:
            backend = (
                "loky" if Version(joblib.__version__) > Version("0.11") else "multiprocessing"
            )
    
>       task = openml.tasks.get_task(7)  # Supervised Classification on kr-vs-kp
               ^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run_functions.py:1948: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[1-None-10]/org/openml/test/tasks/7/7')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\tests\files\test_joblib_backends[1-None-10]\org\openml\test\tasks\7\7. Please do this manually!

openml\utils.py:395: ValueError
____________________ test_joblib_backends[1-sequential-10] ____________________

task_id = 7, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[1-sequential-10]/org/openml/test/tasks/7')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[1-sequential-10]/org/openml/test/tasks/7/7')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...est.openml.org/t/7
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: kr-vs-kp
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...https://test.openml.org/data/v1/download/2/kr-vs-kp.arff
OpenML URL...: https://test.openml.org/d/2
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/2', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/2 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[1-sequential-10]/org/openml/test/tasks/7/7')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[1-sequential-10]/org/openml/test/tasks/7/7')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026453D48BF0>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\tests\\files\\test_joblib_backends[1-sequential-10]\\org\\openml\\test\\tasks\\7\\7'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

parallel_mock = <MagicMock name='_prevent_optimize_n_jobs' id='2629922747600'>
n_jobs = 1, backend = 'sequential', call_count = 10

    @pytest.mark.sklearn()
    @unittest.skipIf(
        Version(sklearn.__version__) < Version("0.21"),
        reason="couldn't perform local tests successfully w/o bloating RAM",
        )
    @mock.patch("openml_sklearn.SklearnExtension._prevent_optimize_n_jobs")
    @pytest.mark.parametrize(
        ("n_jobs", "backend", "call_count"),
        [
            # `None` picks the backend based on joblib version (loky or multiprocessing) and
            # spawns multiple processes if n_jobs != 1, which means the mock is not applied.
            (2, None, 0),
            (-1, None, 0),
            (1, None, 10),  # with n_jobs=1 the mock *is* applied, since there is no new subprocess
            (1, "sequential", 10),
            (1, "threading", 10),
            (-1, "threading", 10),  # the threading backend does preserve mocks even with parallelizing
        ]
    )
    def test_joblib_backends(parallel_mock, n_jobs, backend, call_count):
        """Tests evaluation of a run using various joblib backends and n_jobs."""
        if backend is None:
            backend = (
                "loky" if Version(joblib.__version__) > Version("0.11") else "multiprocessing"
            )
    
>       task = openml.tasks.get_task(7)  # Supervised Classification on kr-vs-kp
               ^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run_functions.py:1948: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[1-sequential-10]/org/openml/test/tasks/7/7')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\tests\files\test_joblib_backends[1-sequential-10]\org\openml\test\tasks\7\7. Please do this manually!

openml\utils.py:395: ValueError
____________________ test_joblib_backends[1-threading-10] _____________________

task_id = 7, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[1-threading-10]/org/openml/test/tasks/7')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[1-threading-10]/org/openml/test/tasks/7/7')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...est.openml.org/t/7
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: kr-vs-kp
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...https://test.openml.org/data/v1/download/2/kr-vs-kp.arff
OpenML URL...: https://test.openml.org/d/2
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/2', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/2 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[1-threading-10]/org/openml/test/tasks/7/7')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[1-threading-10]/org/openml/test/tasks/7/7')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026453D48EB0>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\tests\\files\\test_joblib_backends[1-threading-10]\\org\\openml\\test\\tasks\\7\\7'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

parallel_mock = <MagicMock name='_prevent_optimize_n_jobs' id='2629922748944'>
n_jobs = 1, backend = 'threading', call_count = 10

    @pytest.mark.sklearn()
    @unittest.skipIf(
        Version(sklearn.__version__) < Version("0.21"),
        reason="couldn't perform local tests successfully w/o bloating RAM",
        )
    @mock.patch("openml_sklearn.SklearnExtension._prevent_optimize_n_jobs")
    @pytest.mark.parametrize(
        ("n_jobs", "backend", "call_count"),
        [
            # `None` picks the backend based on joblib version (loky or multiprocessing) and
            # spawns multiple processes if n_jobs != 1, which means the mock is not applied.
            (2, None, 0),
            (-1, None, 0),
            (1, None, 10),  # with n_jobs=1 the mock *is* applied, since there is no new subprocess
            (1, "sequential", 10),
            (1, "threading", 10),
            (-1, "threading", 10),  # the threading backend does preserve mocks even with parallelizing
        ]
    )
    def test_joblib_backends(parallel_mock, n_jobs, backend, call_count):
        """Tests evaluation of a run using various joblib backends and n_jobs."""
        if backend is None:
            backend = (
                "loky" if Version(joblib.__version__) > Version("0.11") else "multiprocessing"
            )
    
>       task = openml.tasks.get_task(7)  # Supervised Classification on kr-vs-kp
               ^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run_functions.py:1948: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[1-threading-10]/org/openml/test/tasks/7/7')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\tests\files\test_joblib_backends[1-threading-10]\org\openml\test\tasks\7\7. Please do this manually!

openml\utils.py:395: ValueError
____________________ test_joblib_backends[-1-threading-10] ____________________

task_id = 7, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[-1-threading-10]/org/openml/test/tasks/7')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[-1-threading-10]/org/openml/test/tasks/7/7')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...est.openml.org/t/7
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: kr-vs-kp
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...https://test.openml.org/data/v1/download/2/kr-vs-kp.arff
OpenML URL...: https://test.openml.org/d/2
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/2', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/2 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[-1-threading-10]/org/openml/test/tasks/7/7')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[-1-threading-10]/org/openml/test/tasks/7/7')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026453D4A090>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\tests\\files\\test_joblib_backends[-1-threading-10]\\org\\openml\\test\\tasks\\7\\7'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

parallel_mock = <MagicMock name='_prevent_optimize_n_jobs' id='2629926305872'>
n_jobs = -1, backend = 'threading', call_count = 10

    @pytest.mark.sklearn()
    @unittest.skipIf(
        Version(sklearn.__version__) < Version("0.21"),
        reason="couldn't perform local tests successfully w/o bloating RAM",
        )
    @mock.patch("openml_sklearn.SklearnExtension._prevent_optimize_n_jobs")
    @pytest.mark.parametrize(
        ("n_jobs", "backend", "call_count"),
        [
            # `None` picks the backend based on joblib version (loky or multiprocessing) and
            # spawns multiple processes if n_jobs != 1, which means the mock is not applied.
            (2, None, 0),
            (-1, None, 0),
            (1, None, 10),  # with n_jobs=1 the mock *is* applied, since there is no new subprocess
            (1, "sequential", 10),
            (1, "threading", 10),
            (-1, "threading", 10),  # the threading backend does preserve mocks even with parallelizing
        ]
    )
    def test_joblib_backends(parallel_mock, n_jobs, backend, call_count):
        """Tests evaluation of a run using various joblib backends and n_jobs."""
        if backend is None:
            backend = (
                "loky" if Version(joblib.__version__) > Version("0.11") else "multiprocessing"
            )
    
>       task = openml.tasks.get_task(7)  # Supervised Classification on kr-vs-kp
               ^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_runs\test_run_functions.py:1948: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_joblib_backends[-1-threading-10]/org/openml/test/tasks/7/7')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\tests\files\test_joblib_backends[-1-threading-10]\org\openml\test\tasks\7\7. Please do this manually!

openml\utils.py:395: ValueError
______________ TestSetupFunctions.test_exisiting_setup_exists_2 _______________

task_id = 115, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_setups.test_setup_functions.TestSetupFunctions.test_exisiting_setup_exists_2/org/openml/test/tasks/115')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_setups.test_setup_functions.TestSetupFunctions.test_exisiting_setup_exists_2/org/openml/test/tasks/115/115')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...t.openml.org/t/115
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_setups.test_setup_functions.TestSetupFunctions.test_exisiting_setup_exists_2/org/openml/test/tasks/115/115')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_setups.test_setup_functions.TestSetupFunctions.test_exisiting_setup_exists_2/org/openml/test/tasks/115/115')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026453D4B110>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_setups.test_setup_functions.TestSetupFunctions.test_exisiting_setup_exists_2\\org\\openml\\test\\tasks\\115\\115'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_setups.test_setup_functions.TestSetupFunctions testMethod=test_exisiting_setup_exists_2>

    @pytest.mark.sklearn()
    def test_exisiting_setup_exists_2(self):
        # Check a flow with one hyperparameter
>       self._existing_setup_exists(sklearn.naive_bayes.GaussianNB())

tests\test_setups\test_setup_functions.py:102: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\test_setups\test_setup_functions.py:70: in _existing_setup_exists
    task = openml.tasks.get_task(115)  # diabetes; crossvalidation
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_setups.test_setup_functions.TestSetupFunctions.test_exisiting_setup_exists_2/org/openml/test/tasks/115/115')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_setups.test_setup_functions.TestSetupFunctions.test_exisiting_setup_exists_2\org\openml\test\tasks\115\115. Please do this manually!

openml\utils.py:395: ValueError
------------------------------ Captured log call ------------------------------
INFO     unit_tests_published_entities:test_setup_functions.py:60 collected from C:\Users\ASUS\Documents\work\opensource\openml-python\tests\test_setups\test_setup_functions.py: 20809
_______________ TestSetupFunctions.test_existing_setup_exists_1 _______________

task_id = 115, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_setups.test_setup_functions.TestSetupFunctions.test_existing_setup_exists_1/org/openml/test/tasks/115')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_setups.test_setup_functions.TestSetupFunctions.test_existing_setup_exists_1/org/openml/test/tasks/115/115')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...t.openml.org/t/115
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_setups.test_setup_functions.TestSetupFunctions.test_existing_setup_exists_1/org/openml/test/tasks/115/115')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_setups.test_setup_functions.TestSetupFunctions.test_existing_setup_exists_1/org/openml/test/tasks/115/115')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026453D4B7F0>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_setups.test_setup_functions.TestSetupFunctions.test_existing_setup_exists_1\\org\\openml\\test\\tasks\\115\\115'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_setups.test_setup_functions.TestSetupFunctions testMethod=test_existing_setup_exists_1>

    @pytest.mark.sklearn()
    def test_existing_setup_exists_1(self):
        def side_effect(self):
            self.var_smoothing = 1e-9
            self.priors = None
    
        with unittest.mock.patch.object(
            sklearn.naive_bayes.GaussianNB,
            "__init__",
            side_effect,
        ):
            # Check a flow with zero hyperparameters
            nb = sklearn.naive_bayes.GaussianNB()
>           self._existing_setup_exists(nb)

tests\test_setups\test_setup_functions.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\test_setups\test_setup_functions.py:70: in _existing_setup_exists
    task = openml.tasks.get_task(115)  # diabetes; crossvalidation
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_setups.test_setup_functions.TestSetupFunctions.test_existing_setup_exists_1/org/openml/test/tasks/115/115')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_setups.test_setup_functions.TestSetupFunctions.test_existing_setup_exists_1\org\openml\test\tasks\115\115. Please do this manually!

openml\utils.py:395: ValueError
------------------------------ Captured log call ------------------------------
INFO     unit_tests_published_entities:test_setup_functions.py:60 collected from C:\Users\ASUS\Documents\work\opensource\openml-python\tests\test_setups\test_setup_functions.py: 20810
_______________ TestSetupFunctions.test_existing_setup_exists_3 _______________

task_id = 115, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_setups.test_setup_functions.TestSetupFunctions.test_existing_setup_exists_3/org/openml/test/tasks/115')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_setups.test_setup_functions.TestSetupFunctions.test_existing_setup_exists_3/org/openml/test/tasks/115/115')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...t.openml.org/t/115
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_setups.test_setup_functions.TestSetupFunctions.test_existing_setup_exists_3/org/openml/test/tasks/115/115')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_setups.test_setup_functions.TestSetupFunctions.test_existing_setup_exists_3/org/openml/test/tasks/115/115')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026453D4BE20>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_setups.test_setup_functions.TestSetupFunctions.test_existing_setup_exists_3\\org\\openml\\test\\tasks\\115\\115'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_setups.test_setup_functions.TestSetupFunctions testMethod=test_existing_setup_exists_3>

    @pytest.mark.sklearn()
    def test_existing_setup_exists_3(self):
        # Check a flow with many hyperparameters
>       self._existing_setup_exists(
            sklearn.tree.DecisionTreeClassifier(
                max_depth=5,
                min_samples_split=3,
                # Not setting the random state will make this flow fail as running it
                # will add a random random_state.
                random_state=1,
            ),
        )

tests\test_setups\test_setup_functions.py:107: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\test_setups\test_setup_functions.py:70: in _existing_setup_exists
    task = openml.tasks.get_task(115)  # diabetes; crossvalidation
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_setups.test_setup_functions.TestSetupFunctions.test_existing_setup_exists_3/org/openml/test/tasks/115/115')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_setups.test_setup_functions.TestSetupFunctions.test_existing_setup_exists_3\org\openml\test\tasks\115\115. Please do this manually!

openml\utils.py:395: ValueError
------------------------------ Captured log call ------------------------------
INFO     unit_tests_published_entities:test_setup_functions.py:60 collected from C:\Users\ASUS\Documents\work\opensource\openml-python\tests\test_setups\test_setup_functions.py: 20811
__________________ TestSetupFunctions.test_setuplist_offset ___________________

self = <tests.test_setups.test_setup_functions.TestSetupFunctions testMethod=test_setuplist_offset>

    def test_setuplist_offset(self):
        size = 10
        setups = openml.setups.list_setups(offset=0, size=size)
>       assert len(setups) == size
E       assert 0 == 10
E        +  where 0 = len({})

tests\test_setups\test_setup_functions.py:169: AssertionError
____________________ TestStudyFunctions.test_publish_study ____________________

self = <tests.test_study.test_study_functions.TestStudyFunctions testMethod=test_publish_study>

    @pytest.mark.flaky()
    def test_publish_study(self):
        # get some random runs to attach
        run_list = openml.evaluations.list_evaluations("predictive_accuracy", size=10)
>       assert len(run_list) == 10
E       assert 0 == 10
E        +  where 0 = len({})

tests\test_study\test_study_functions.py:154: AssertionError
________________ TestStudyFunctions.test_study_attach_illegal _________________

self = <tests.test_study.test_study_functions.TestStudyFunctions testMethod=test_study_attach_illegal>

    def test_study_attach_illegal(self):
        run_list = openml.runs.list_runs(size=10)
>       assert len(run_list) == 10
E       assert 0 == 10
E        +  where 0 = len(Empty DataFrame\nColumns: []\nIndex: [])

tests\test_study\test_study_functions.py:222: AssertionError
_______________ OpenMLClassificationTaskTest.test_class_labels ________________

task_id = 119, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_classification_task.OpenMLClassificationTaskTest.test_class_labels/org/openml/test/tasks/119')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_classification_task.OpenMLClassificationTaskTest.test_class_labels/org/openml/test/tasks/119/119')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...ps://test.openml.org/t/119
Estimation Procedure.: holdout
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_classification_task.OpenMLClassificationTaskTest.test_class_labels/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_classification_task.OpenMLClassificationTaskTest.test_class_labels/org/openml/test/tasks/119/119')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026453D4F480>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_tasks.test_classification_task.OpenMLClassificationTaskTest.test_class_labels\\org\\openml\\test\\tasks\\119\\119'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_tasks.test_classification_task.OpenMLClassificationTaskTest testMethod=test_class_labels>

    def test_class_labels(self):
>       task = get_task(self.task_id)
               ^^^^^^^^^^^^^^^^^^^^^^

tests\test_tasks\test_classification_task.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_classification_task.OpenMLClassificationTaskTest.test_class_labels/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_tasks.test_classification_task.OpenMLClassificationTaskTest.test_class_labels\org\openml\test\tasks\119\119. Please do this manually!

openml\utils.py:395: ValueError
_______________ OpenMLClassificationTaskTest.test_download_task _______________

task_id = 119, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_classification_task.OpenMLClassificationTaskTest.test_download_task/org/openml/test/tasks/119')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_classification_task.OpenMLClassificationTaskTest.test_download_task/org/openml/test/tasks/119/119')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...ps://test.openml.org/t/119
Estimation Procedure.: holdout
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_classification_task.OpenMLClassificationTaskTest.test_download_task/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_classification_task.OpenMLClassificationTaskTest.test_download_task/org/openml/test/tasks/119/119')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026453D4F950>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_tasks.test_classification_task.OpenMLClassificationTaskTest.test_download_task\\org\\openml\\test\\tasks\\119\\119'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_tasks.test_classification_task.OpenMLClassificationTaskTest testMethod=test_download_task>

    def test_download_task(self):
>       task = super().test_download_task()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_tasks\test_classification_task.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\test_tasks\test_task.py:34: in test_download_task
    return get_task(self.task_id)
           ^^^^^^^^^^^^^^^^^^^^^^
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_classification_task.OpenMLClassificationTaskTest.test_download_task/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_tasks.test_classification_task.OpenMLClassificationTaskTest.test_download_task\org\openml\test\tasks\119\119. Please do this manually!

openml\utils.py:395: ValueError
________________ OpenMLClassificationTaskTest.test_get_X_and_Y ________________

task_id = 119, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_classification_task.OpenMLClassificationTaskTest.test_get_X_and_Y/org/openml/test/tasks/119')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_classification_task.OpenMLClassificationTaskTest.test_get_X_and_Y/org/openml/test/tasks/119/119')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...ps://test.openml.org/t/119
Estimation Procedure.: holdout
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_classification_task.OpenMLClassificationTaskTest.test_get_X_and_Y/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_classification_task.OpenMLClassificationTaskTest.test_get_X_and_Y/org/openml/test/tasks/119/119')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026453D4FED0>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_tasks.test_classification_task.OpenMLClassificationTaskTest.test_get_X_and_Y\\org\\openml\\test\\tasks\\119\\119'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_tasks.test_classification_task.OpenMLClassificationTaskTest testMethod=test_get_X_and_Y>

    def test_get_X_and_Y(self) -> tuple[pd.DataFrame, pd.Series]:
>       task = get_task(self.task_id)
               ^^^^^^^^^^^^^^^^^^^^^^

tests\test_tasks\test_supervised_task.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_classification_task.OpenMLClassificationTaskTest.test_get_X_and_Y/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_tasks.test_classification_task.OpenMLClassificationTaskTest.test_get_X_and_Y\org\openml\test\tasks\119\119. Please do this manually!

openml\utils.py:395: ValueError
______________________________ test_get_X_and_Y _______________________________

task_id = 119, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_get_X_and_Y/org/openml/test/tasks/119')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_get_X_and_Y/org/openml/test/tasks/119/119')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...ps://test.openml.org/t/119
Estimation Procedure.: holdout
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_get_X_and_Y/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_get_X_and_Y/org/openml/test/tasks/119/119')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026452590880>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\tests\\files\\test_get_X_and_Y\\org\\openml\\test\\tasks\\119\\119'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

    @pytest.mark.server()
    def test_get_X_and_Y():
>       task = get_task(119)
               ^^^^^^^^^^^^^

tests\test_tasks\test_classification_task.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_get_X_and_Y/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\tests\files\test_get_X_and_Y\org\openml\test\tasks\119\119. Please do this manually!

openml\utils.py:395: ValueError
________________ OpenMLLearningCurveTaskTest.test_class_labels ________________

task_id = 801, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_learning_curve_task.OpenMLLearningCurveTaskTest.test_class_labels/org/openml/test/tasks/801')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_learning_curve_task.OpenMLLearningCurveTaskTest.test_class_labels/org/openml/test/tasks/801/801')
tid_cache_dir_existed = False
task = OpenML Learning Curve Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.LEARN...t.openml.org/t/801
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_learning_curve_task.OpenMLLearningCurveTaskTest.test_class_labels/org/openml/test/tasks/801/801')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_learning_curve_task.OpenMLLearningCurveTaskTest.test_class_labels/org/openml/test/tasks/801/801')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x00000264525919B0>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_tasks.test_learning_curve_task.OpenMLLearningCurveTaskTest.test_class_labels\\org\\openml\\test\\tasks\\801\\801'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_tasks.test_learning_curve_task.OpenMLLearningCurveTaskTest testMethod=test_class_labels>

    def test_class_labels(self):
>       task = get_task(self.task_id)
               ^^^^^^^^^^^^^^^^^^^^^^

tests\test_tasks\test_learning_curve_task.py:36: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_learning_curve_task.OpenMLLearningCurveTaskTest.test_class_labels/org/openml/test/tasks/801/801')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_tasks.test_learning_curve_task.OpenMLLearningCurveTaskTest.test_class_labels\org\openml\test\tasks\801\801. Please do this manually!

openml\utils.py:395: ValueError
_______________ OpenMLLearningCurveTaskTest.test_download_task ________________

task_id = 801, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_learning_curve_task.OpenMLLearningCurveTaskTest.test_download_task/org/openml/test/tasks/801')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_learning_curve_task.OpenMLLearningCurveTaskTest.test_download_task/org/openml/test/tasks/801/801')
tid_cache_dir_existed = False
task = OpenML Learning Curve Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.LEARN...t.openml.org/t/801
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_learning_curve_task.OpenMLLearningCurveTaskTest.test_download_task/org/openml/test/tasks/801/801')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_learning_curve_task.OpenMLLearningCurveTaskTest.test_download_task/org/openml/test/tasks/801/801')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026452591F30>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_tasks.test_learning_curve_task.OpenMLLearningCurveTaskTest.test_download_task\\org\\openml\\test\\tasks\\801\\801'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_tasks.test_learning_curve_task.OpenMLLearningCurveTaskTest testMethod=test_download_task>

    def test_download_task(self):
>       task = super().test_download_task()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_tasks\test_learning_curve_task.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\test_tasks\test_task.py:34: in test_download_task
    return get_task(self.task_id)
           ^^^^^^^^^^^^^^^^^^^^^^
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_learning_curve_task.OpenMLLearningCurveTaskTest.test_download_task/org/openml/test/tasks/801/801')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_tasks.test_learning_curve_task.OpenMLLearningCurveTaskTest.test_download_task\org\openml\test\tasks\801\801. Please do this manually!

openml\utils.py:395: ValueError
________________ OpenMLLearningCurveTaskTest.test_get_X_and_Y _________________

task_id = 801, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_learning_curve_task.OpenMLLearningCurveTaskTest.test_get_X_and_Y/org/openml/test/tasks/801')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_learning_curve_task.OpenMLLearningCurveTaskTest.test_get_X_and_Y/org/openml/test/tasks/801/801')
tid_cache_dir_existed = False
task = OpenML Learning Curve Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.LEARN...t.openml.org/t/801
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_learning_curve_task.OpenMLLearningCurveTaskTest.test_get_X_and_Y/org/openml/test/tasks/801/801')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_learning_curve_task.OpenMLLearningCurveTaskTest.test_get_X_and_Y/org/openml/test/tasks/801/801')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x00000264525924B0>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_tasks.test_learning_curve_task.OpenMLLearningCurveTaskTest.test_get_X_and_Y\\org\\openml\\test\\tasks\\801\\801'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_tasks.test_learning_curve_task.OpenMLLearningCurveTaskTest testMethod=test_get_X_and_Y>

    def test_get_X_and_Y(self):
>       X, Y = super().test_get_X_and_Y()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_tasks\test_learning_curve_task.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\test_tasks\test_supervised_task.py:32: in test_get_X_and_Y
    task = get_task(self.task_id)
           ^^^^^^^^^^^^^^^^^^^^^^
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_learning_curve_task.OpenMLLearningCurveTaskTest.test_get_X_and_Y/org/openml/test/tasks/801/801')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_tasks.test_learning_curve_task.OpenMLLearningCurveTaskTest.test_get_X_and_Y\org\openml\test\tasks\801\801. Please do this manually!

openml\utils.py:395: ValueError
__________________ OpenMLRegressionTaskTest.test_get_X_and_Y __________________

self = <tests.test_tasks.test_regression_task.OpenMLRegressionTaskTest testMethod=test_get_X_and_Y>

    def test_get_X_and_Y(self):
>       X, Y = super().test_get_X_and_Y()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_tasks\test_regression_task.py:53: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\test_tasks\test_supervised_task.py:33: in test_get_X_and_Y
    X, Y = task.get_X_and_y()
           ^^^^^^^^^^^^^^^^^^
openml\tasks\task.py:295: in get_X_and_y
    X, y, _, _ = dataset.get_data(target=self.target_name)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\dataset.py:750: in get_data
    data, categorical_mask, attribute_names = self._load_data()
                                              ^^^^^^^^^^^^^^^^^
openml\datasets\dataset.py:626: in _load_data
    self._download_data()
openml\datasets\dataset.py:383: in _download_data
    self.data_file = str(_get_dataset_arff(self))
                         ^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1234: in _get_dataset_arff
    openml._api_calls._download_text_file(
openml\_api_calls.py:275: in _download_text_file
    response = __read_url(source, request_method="get", md5_checksum=md5_checksum)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
openml\_api_calls.py:452: in __check_response
    raise __parse_server_exception(response, url, file_elements=file_elements)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [404]>
url = 'https://test.openml.org/data/v1/download/105/wisconsin.arff'
file_elements = None

    def __parse_server_exception(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> OpenMLServerError:
        if response.status_code == requests.codes.URI_TOO_LONG:
            raise OpenMLServerError(f"URI too long! ({url})")
    
        # OpenML has a sophisticated error system where information about failures is provided,
        # in the response body itself.
        # First, we need to parse it out.
        try:
            server_exception = xmltodict.parse(response.text)
        except xml.parsers.expat.ExpatError as e:
            raise e
        except Exception as e:
            # If we failed to parse it out, then something has gone wrong in the body we have sent back
            # from the server and there is little extra information we can capture.
            raise OpenMLServerError(
                f"Unexpected server error when calling {url}. Please contact the developers!\n"
                f"Status code: {response.status_code}\n{response.text}",
            ) from e
    
        # Now we can parse out the specific error codes that we return. These
        # are in addition to the typical HTTP error codes, but encode more
        # specific informtion. You can find these codes here:
        # https://github.com/openml/OpenML/blob/develop/openml_OS/views/pages/api_new/v1/xml/pre.php
>       server_error = server_exception["oml:error"]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       KeyError: 'oml:error'

openml\_api_calls.py:484: KeyError
________________________ TestTask.test_download_split _________________________

task_id = 1, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_task_functions.TestTask.test_download_split/org/openml/test/tasks/1')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_task_functions.TestTask.test_download_split/org/openml/test/tasks/1/1')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...est.openml.org/t/1
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: anneal
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 23:...: https://test.openml.org/data/v1/download/1/anneal.arff
OpenML URL...: https://test.openml.org/d/1
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/1', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/1 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_task_functions.TestTask.test_download_split/org/openml/test/tasks/1/1')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_task_functions.TestTask.test_download_split/org/openml/test/tasks/1/1')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026452369850>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_tasks.test_task_functions.TestTask.test_download_split\\org\\openml\\test\\tasks\\1\\1'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_tasks.test_task_functions.TestTask testMethod=test_download_split>

    def test_download_split(self):
>       task = openml.tasks.get_task(1)  # anneal; crossvalidation
               ^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_tasks\test_task_functions.py:211: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_task_functions.TestTask.test_download_split/org/openml/test/tasks/1/1')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_tasks.test_task_functions.TestTask.test_download_split\org\openml\test\tasks\1\1. Please do this manually!

openml\utils.py:395: ValueError
___________________________ TestTask.test_get_task ____________________________

task_id = 1, download_splits = False
get_dataset_kwargs = {'download_data': True}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_task_functions.TestTask.test_get_task/org/openml/test/tasks/1')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_task_functions.TestTask.test_get_task/org/openml/test/tasks/1/1')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...est.openml.org/t/1
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
>           dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:423: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:511: in get_dataset
    arff_file = _get_dataset_arff(description)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1234: in _get_dataset_arff
    openml._api_calls._download_text_file(
openml\_api_calls.py:275: in _download_text_file
    response = __read_url(source, request_method="get", md5_checksum=md5_checksum)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
openml\_api_calls.py:452: in __check_response
    raise __parse_server_exception(response, url, file_elements=file_elements)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [404]>
url = 'https://test.openml.org/data/v1/download/1/anneal.arff'
file_elements = None

    def __parse_server_exception(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> OpenMLServerError:
        if response.status_code == requests.codes.URI_TOO_LONG:
            raise OpenMLServerError(f"URI too long! ({url})")
    
        # OpenML has a sophisticated error system where information about failures is provided,
        # in the response body itself.
        # First, we need to parse it out.
        try:
            server_exception = xmltodict.parse(response.text)
        except xml.parsers.expat.ExpatError as e:
            raise e
        except Exception as e:
            # If we failed to parse it out, then something has gone wrong in the body we have sent back
            # from the server and there is little extra information we can capture.
            raise OpenMLServerError(
                f"Unexpected server error when calling {url}. Please contact the developers!\n"
                f"Status code: {response.status_code}\n{response.text}",
            ) from e
    
        # Now we can parse out the specific error codes that we return. These
        # are in addition to the typical HTTP error codes, but encode more
        # specific informtion. You can find these codes here:
        # https://github.com/openml/OpenML/blob/develop/openml_OS/views/pages/api_new/v1/xml/pre.php
>       server_error = server_exception["oml:error"]
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       KeyError: 'oml:error'

openml\_api_calls.py:484: KeyError

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_task_functions.TestTask.test_get_task/org/openml/test/tasks/1/1')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_task_functions.TestTask.test_get_task/org/openml/test/tasks/1/1')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026452369D20>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_tasks.test_task_functions.TestTask.test_get_task\\org\\openml\\test\\tasks\\1\\1'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_tasks.test_task_functions.TestTask testMethod=test_get_task>

    def test_get_task(self):
>       task = openml.tasks.get_task(1, download_data=True)  # anneal; crossvalidation
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_tasks\test_task_functions.py:143: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_task_functions.TestTask.test_get_task/org/openml/test/tasks/1/1')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_tasks.test_task_functions.TestTask.test_get_task\org\openml\test\tasks\1\1. Please do this manually!

openml\utils.py:395: ValueError
_________________________ TestTask.test_get_task_lazy _________________________

task_id = 2, download_splits = False
get_dataset_kwargs = {'download_data': False}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_task_functions.TestTask.test_get_task_lazy/org/openml/test/tasks/2')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_task_functions.TestTask.test_get_task_lazy/org/openml/test/tasks/2/2')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...est.openml.org/t/2
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: anneal
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 23:...: https://test.openml.org/data/v1/download/1/anneal.arff
OpenML URL...: https://test.openml.org/d/1
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/1', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/1 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_task_functions.TestTask.test_get_task_lazy/org/openml/test/tasks/2/2')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_task_functions.TestTask.test_get_task_lazy/org/openml/test/tasks/2/2')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x000002645236A820>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_tasks.test_task_functions.TestTask.test_get_task_lazy\\org\\openml\\test\\tasks\\2\\2'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_tasks.test_task_functions.TestTask testMethod=test_get_task_lazy>

    def test_get_task_lazy(self):
>       task = openml.tasks.get_task(2, download_data=False)  # anneal; crossvalidation
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_tasks\test_task_functions.py:156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_task_functions.TestTask.test_get_task_lazy/org/openml/test/tasks/2/2')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_tasks.test_task_functions.TestTask.test_get_task_lazy\org\openml\test\tasks\2\2. Please do this manually!

openml\utils.py:395: ValueError
______________________ TestTask.test_get_task_with_cache ______________________

task_id = 1, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/org/openml/test/tasks/1')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/org/openml/test/tasks/1/1')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...rossvalidation
Evaluation Measure...: predictive_accuracy
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: anneal
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 23:...: https://test.openml.org/data/v1/download/1/anneal.arff
OpenML URL...: https://test.openml.org/d/1
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/1', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/1 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/org/openml/test/tasks/1/1')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/org/openml/test/tasks/1/1')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x000002645236AF00>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\tests\\files\\org\\openml\\test\\tasks\\1\\1'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_tasks.test_task_functions.TestTask testMethod=test_get_task_with_cache>

    def test_get_task_with_cache(self):
        openml.config.set_root_cache_directory(self.static_cache_dir)
>       task = openml.tasks.get_task(1)
               ^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_tasks\test_task_functions.py:197: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/org/openml/test/tasks/1/1')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\tests\files\org\openml\test\tasks\1\1. Please do this manually!

openml\utils.py:395: ValueError
_____________________ OpenMLTaskMethodsTest.test_tagging ______________________

task_id = 1, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_task_methods.OpenMLTaskMethodsTest.test_tagging/org/openml/test/tasks/1')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_task_methods.OpenMLTaskMethodsTest.test_tagging/org/openml/test/tasks/1/1')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...est.openml.org/t/1
Estimation Procedure.: crossvalidation
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: anneal
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 23:...: https://test.openml.org/data/v1/download/1/anneal.arff
OpenML URL...: https://test.openml.org/d/1
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/1', file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/1 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_task_methods.OpenMLTaskMethodsTest.test_tagging/org/openml/test/tasks/1/1')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_task_methods.OpenMLTaskMethodsTest.test_tagging/org/openml/test/tasks/1/1')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026455245D20>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\openml\\tests.test_tasks.test_task_methods.OpenMLTaskMethodsTest.test_tagging\\org\\openml\\test\\tasks\\1\\1'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

self = <tests.test_tasks.test_task_methods.OpenMLTaskMethodsTest testMethod=test_tagging>

    def test_tagging(self):
>       task = openml.tasks.get_task(1)  # anneal; crossvalidation
               ^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_tasks\test_task_methods.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/openml/tests.test_tasks.test_task_methods.OpenMLTaskMethodsTest.test_tagging/org/openml/test/tasks/1/1')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tests.test_tasks.test_task_methods.OpenMLTaskMethodsTest.test_tagging\org\openml\test\tasks\1\1. Please do this manually!

openml\utils.py:395: ValueError
__________________________ test_list_all_for_setups ___________________________

min_number_setups_on_test_server = 50

    @pytest.mark.server()
    @pytest.mark.flaky()  # Other tests might need to upload runs first
    def test_list_all_for_setups(min_number_setups_on_test_server):
        # TODO apparently list_setups function does not support kwargs
        setups = openml.setups.list_setups(size=min_number_setups_on_test_server)
>       assert min_number_setups_on_test_server == len(setups)
E       assert 50 == 0
E        +  where 0 = len({})

tests\test_utils\test_utils.py:97: AssertionError
___________________________ test_list_all_for_runs ____________________________

min_number_runs_on_test_server = 21

    @pytest.mark.server()
    @pytest.mark.flaky()  # Other tests might need to upload runs first
    def test_list_all_for_runs(min_number_runs_on_test_server):
        runs = openml.runs.list_runs(size=min_number_runs_on_test_server)
>       assert min_number_runs_on_test_server == len(runs)
E       assert 21 == 0
E        +  where 0 = len(Empty DataFrame\nColumns: []\nIndex: [])

tests\test_utils\test_utils.py:104: AssertionError
________________________ test_list_all_for_evaluations ________________________

min_number_evaluations_on_test_server = 8

    @pytest.mark.server()
    @pytest.mark.flaky()  # Other tests might need to upload runs first
    def test_list_all_for_evaluations(min_number_evaluations_on_test_server):
        # TODO apparently list_evaluations function does not support kwargs
        evaluations = openml.evaluations.list_evaluations(
            function="predictive_accuracy",
            size=min_number_evaluations_on_test_server,
        )
>       assert min_number_evaluations_on_test_server == len(evaluations)
E       assert 8 == 0
E        +  where 0 = len({})

tests\test_utils\test_utils.py:115: AssertionError
___________________ test_correct_test_server_download_state ___________________

task_id = 119, download_splits = False, get_dataset_kwargs = {}
cache_key_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_correct_test_server_download_state/org/openml/test/tasks/119')
tid_cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_correct_test_server_download_state/org/openml/test/tasks/119/119')
tid_cache_dir_existed = False
task = OpenML Classification Task
==========================
Task Type Description: https://test.openml.org/tt/TaskType.SUPER...ps://test.openml.org/t/119
Estimation Procedure.: holdout
Target Feature.......: class
Cost Matrix..........: Available
dataset = OpenML Dataset
==============
Name.........: diabetes
Version......: 1
Format.......: ARFF
Upload Date..: 2014-04-06 2...tps://test.openml.org/data/v1/download/20/diabetes.arff
OpenML URL...: https://test.openml.org/d/20
# of features: None

    @openml.utils.thread_safe_if_oslo_installed
    def get_task(
        task_id: int,
        download_splits: bool = False,  # noqa: FBT001, FBT002
        **get_dataset_kwargs: Any,
    ) -> OpenMLTask:
        """Download OpenML task for a given task ID.
    
        Downloads the task representation.
    
        Use the `download_splits` parameter to control whether the splits are downloaded.
        Moreover, you may pass additional parameter (args or kwargs) that are passed to
        :meth:`openml.datasets.get_dataset`.
    
        Parameters
        ----------
        task_id : int
            The OpenML task id of the task to download.
        download_splits: bool (default=False)
            Whether to download the splits as well.
        get_dataset_kwargs :
            Args and kwargs can be used pass optional parameters to :meth:`openml.datasets.get_dataset`.
    
        Returns
        -------
        task: OpenMLTask
        """
        if not isinstance(task_id, int):
            raise TypeError(f"Task id should be integer, is {type(task_id)}")
    
        cache_key_dir = openml.utils._create_cache_directory_for_id(TASKS_CACHE_DIR_NAME, task_id)
        tid_cache_dir = cache_key_dir / str(task_id)
        tid_cache_dir_existed = tid_cache_dir.exists()
        try:
            task = _get_task_description(task_id)
            dataset = get_dataset(task.dataset_id, **get_dataset_kwargs)
            # List of class labels available in dataset description
            # Including class labels as part of task meta data handles
            #   the case where data download was initially disabled
            if isinstance(task, (OpenMLClassificationTask, OpenMLLearningCurveTask)):
>               task.class_labels = dataset.retrieve_class_labels(task.target_name)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

openml\tasks\functions.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\datasets\dataset.py:847: in retrieve_class_labels
    for feature in self.features.values():
                   ^^^^^^^^^^^^^
openml\datasets\dataset.py:275: in features
    self._load_features()
openml\datasets\dataset.py:809: in _load_features
    features_file = _get_dataset_features_file(None, self.dataset_id)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1281: in _get_dataset_features_file
    features_xml = _get_features_xml(dataset_id)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\datasets\functions.py:1249: in _get_features_xml
    return openml._api_calls._perform_api_call(url_extension, "get")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:120: in _perform_api_call
    response = __read_url(url, request_method, data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
openml\_api_calls.py:342: in __read_url
    return _send_request(
openml\_api_calls.py:413: in _send_request
    raise e
openml\_api_calls.py:387: in _send_request
    __check_response(response=response, url=url, file_elements=files)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

response = <Response [412]>
url = 'https://test.openml.org/api/v1/xml/data/features/20'
file_elements = None

    def __check_response(
        response: requests.Response,
        url: str,
        file_elements: FILE_ELEMENTS_TYPE | None,
    ) -> None:
        if response.status_code != 200:
>           raise __parse_server_exception(response, url, file_elements=file_elements)
E           openml.exceptions.OpenMLServerException: https://test.openml.org/api/v1/xml/data/features/20 returned code 274: No features found. Additionally, dataset processed with error - None

openml\_api_calls.py:452: OpenMLServerException

During handling of the above exception, another exception occurred:

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_correct_test_server_download_state/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
>           shutil.rmtree(cache_dir)

openml\utils.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:852: in rmtree
    _rmtree_impl(path, dir_fd, onexc)
..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:675: in _rmtree_unsafe
    onexc(os.lstat, path, err)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_correct_test_server_download_state/org/openml/test/tasks/119/119')
dir_fd = None, onexc = <function rmtree.<locals>.onexc at 0x0000026455200300>

    def _rmtree_unsafe(path, dir_fd, onexc):
        if dir_fd is not None:
            raise NotImplementedError("dir_fd unavailable on this platform")
        try:
>           st = os.lstat(path)
                 ^^^^^^^^^^^^^^
E           FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\Users\\ASUS\\Documents\\work\\opensource\\openml-python\\tests\\files\\test_correct_test_server_download_state\\org\\openml\\test\\tasks\\119\\119'

..\..\..\..\AppData\Local\Python\pythoncore-3.14-64\Lib\shutil.py:673: FileNotFoundError

The above exception was the direct cause of the following exception:

    @pytest.mark.server()
    def test_correct_test_server_download_state():
        """This test verifies that the test server downloads the data from the correct source.
    
        If this tests fails, it is highly likely that the test server is not configured correctly.
        Usually, this means that the test server is serving data from the task with the same ID from the production server.
        That is, it serves parquet files wrongly associated with the test server's task.
        """
>       task = openml.tasks.get_task(119)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_utils\test_utils.py:152: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
openml\utils.py:423: in safe_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
openml\tasks\functions.py:435: in get_task
    openml.utils._remove_cache_dir_for_id(TASKS_CACHE_DIR_NAME, tid_cache_dir)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'tasks'
cache_dir = WindowsPath('C:/Users/ASUS/Documents/work/opensource/openml-python/tests/files/test_correct_test_server_download_state/org/openml/test/tasks/119/119')

    def _remove_cache_dir_for_id(key: str, cache_dir: Path) -> None:
        """Remove the task cache directory
    
        This function is NOT thread/multiprocessing safe.
    
        Parameters
        ----------
        key : str
    
        cache_dir : str
        """
        try:
            shutil.rmtree(cache_dir)
        except OSError as e:
>           raise ValueError(
                f"Cannot remove faulty {key} cache directory {cache_dir}. Please do this manually!",
            ) from e
E           ValueError: Cannot remove faulty tasks cache directory C:\Users\ASUS\Documents\work\opensource\openml-python\tests\files\test_correct_test_server_download_state\org\openml\test\tasks\119\119. Please do this manually!

openml\utils.py:395: ValueError
============================== warnings summary ===============================
tests\test_flows\test_flow_functions.py:325
  C:\Users\ASUS\Documents\work\opensource\openml-python\tests\test_flows\test_flow_functions.py:325: SyntaxWarning: "\(" is an invalid escape sequence. Such sequences will not work in the future. Did you mean "\\("? A raw string is also an option.
    ".* flow: 10 \(weka.SMO\). ",

tests/test_datasets/test_dataset.py::OpenMLDatasetTestSparse::test_get_sparse_dataset_dataframe
tests/test_datasets/test_dataset.py::OpenMLDatasetTestSparse::test_get_sparse_dataset_dataframe_with_target
tests/test_datasets/test_dataset.py::OpenMLDatasetTestSparse::test_get_sparse_dataset_rowid_and_ignore_and_target
  C:\Users\ASUS\Documents\work\opensource\openml-python\openml\datasets\dataset.py:487: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.
    pd.factorize(type_)[0]

tests/test_datasets/test_dataset.py::OpenMLDatasetTestSparse::test_get_sparse_dataset_dataframe_with_target
  C:\Users\ASUS\Documents\work\opensource\openml-python\tests\test_datasets\test_dataset.py:355: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
    assert isinstance(X.dtypes[0], pd.SparseDtype)

tests/test_datasets/test_dataset_functions.py::test_delete_dataset_not_owned
  C:\Users\ASUS\Documents\work\opensource\openml-python\tests\test_datasets\test_dataset_functions.py:1686: UserWarning: Switching to the test server https://test.openml.org/api/v1/xml to not upload results to the live server. Using the test server may result in reduced performance of the API!
    openml.config.start_using_configuration_for_example()

tests/test_openml/test_config.py::TestConfigurationForExamples::test_example_configuration_start_twice
  C:\Users\ASUS\Documents\work\opensource\openml-python\tests\test_openml\test_config.py:152: UserWarning: Switching to the test server https://test.openml.org/api/v1/xml to not upload results to the live server. Using the test server may result in reduced performance of the API!
    openml.config.start_using_configuration_for_example()

tests/test_openml/test_config.py::TestConfigurationForExamples::test_switch_from_example_configuration
  C:\Users\ASUS\Documents\work\opensource\openml-python\tests\test_openml\test_config.py:128: UserWarning: Switching to the test server https://test.openml.org/api/v1/xml to not upload results to the live server. Using the test server may result in reduced performance of the API!
    openml.config.start_using_configuration_for_example()

tests/test_openml/test_config.py::TestConfigurationForExamples::test_switch_to_example_configuration
  C:\Users\ASUS\Documents\work\opensource\openml-python\tests\test_openml\test_config.py:116: UserWarning: Switching to the test server https://test.openml.org/api/v1/xml to not upload results to the live server. Using the test server may result in reduced performance of the API!
    openml.config.start_using_configuration_for_example()

tests/test_runs/test_run_functions.py: 2 warnings
tests/test_tasks/test_regression_task.py: 3 warnings
tests/test_tasks/test_task_functions.py: 23 warnings
tests/test_utils/test_utils.py: 4 warnings
  C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tasks\functions.py:283: RuntimeWarning: Could not create task type id for 10 due to error 10 is not a valid TaskType
    procs = _get_estimation_procedure_list()

tests/test_runs/test_run_functions.py: 2 warnings
tests/test_tasks/test_regression_task.py: 3 warnings
tests/test_tasks/test_task_functions.py: 23 warnings
tests/test_utils/test_utils.py: 4 warnings
  C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tasks\functions.py:283: RuntimeWarning: Could not create task type id for 11 due to error 11 is not a valid TaskType
    procs = _get_estimation_procedure_list()

tests/test_study/test_study_functions.py::TestStudyFunctions::test_get_openml100
  C:\Users\ASUS\Documents\work\opensource\openml-python\tests\test_study\test_study_functions.py:41: DeprecationWarning: It looks like you are running code from the OpenML100 paper. It still works, but lots of things have changed since then. Please use `get_suite('OpenML100')` instead.
    study = openml.study.get_study("OpenML100", "tasks")

tests/test_tasks/test_task_functions.py::TestTask::test__get_estimation_procedure_list
  C:\Users\ASUS\Documents\work\opensource\openml-python\tests\test_tasks\test_task_functions.py:51: RuntimeWarning: Could not create task type id for 10 due to error 10 is not a valid TaskType
    estimation_procedures = openml.tasks.functions._get_estimation_procedure_list()

tests/test_tasks/test_task_functions.py::TestTask::test__get_estimation_procedure_list
  C:\Users\ASUS\Documents\work\opensource\openml-python\tests\test_tasks\test_task_functions.py:51: RuntimeWarning: Could not create task type id for 11 due to error 11 is not a valid TaskType
    estimation_procedures = openml.tasks.functions._get_estimation_procedure_list()

tests/test_tasks/test_task_functions.py::TestTask::test_list_tasks
tests/test_utils/test_utils.py::test_list_all
tests/test_utils/test_utils.py::test_list_all_with_multiple_batches
  C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tasks\functions.py:239: RuntimeWarning: Could not create task type id for 11 due to error 11 is not a valid TaskType
    return __list_tasks(api_call=api_call)

tests/test_tasks/test_task_functions.py::TestTask::test_list_tasks
tests/test_utils/test_utils.py::test_list_all
tests/test_utils/test_utils.py::test_list_all_with_multiple_batches
  C:\Users\ASUS\Documents\work\opensource\openml-python\openml\tasks\functions.py:239: RuntimeWarning: Could not create task type id for 10 due to error 10 is not a valid TaskType
    return __list_tasks(api_call=api_call)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
FAILED tests/test_datasets/test_dataset.py::test_get_feature_with_ontology_data_id_11
FAILED tests/test_datasets/test_dataset.py::test_add_remove_ontology_to_dataset
FAILED tests/test_datasets/test_dataset.py::test_add_same_ontology_multiple_features
FAILED tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test__get_dataset_features
FAILED tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test__get_dataset_qualities
FAILED tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test__getarff_path_dataset_arff
FAILED tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_data_edit_cannot_edit_critical_field_if_dataset_has_task
FAILED tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_data_edit_critical_field
FAILED tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_get_dataset_by_name
FAILED tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_get_dataset_cache_format_feather
FAILED tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_get_dataset_cache_format_pickle
FAILED tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_get_dataset_lazy_all_functions
FAILED tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_get_dataset_sparse
FAILED tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_get_dataset_uint8_dtype
FAILED tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_get_online_dataset_arff
FAILED tests/test_datasets/test_dataset_functions.py::TestOpenMLDataset::test_publish_dataset
FAILED tests/test_datasets/test_dataset_functions.py::test_list_datasets_by_number_features
FAILED tests/test_datasets/test_dataset_functions.py::test_list_datasets_by_number_missing_values
FAILED tests/test_datasets/test_dataset_functions.py::test_list_datasets_combined_filters
FAILED tests/test_datasets/test_dataset_functions.py::test_get_dataset_lazy_behavior[True-True-True]
FAILED tests/test_datasets/test_dataset_functions.py::test_get_dataset_lazy_behavior[True-True-False]
FAILED tests/test_datasets/test_dataset_functions.py::test_get_dataset_lazy_behavior[True-False-True]
FAILED tests/test_datasets/test_dataset_functions.py::test_get_dataset_lazy_behavior[True-False-False]
FAILED tests/test_datasets/test_dataset_functions.py::test_get_dataset_lazy_behavior[False-True-True]
FAILED tests/test_datasets/test_dataset_functions.py::test_get_dataset_lazy_behavior[False-True-False]
FAILED tests/test_datasets/test_dataset_functions.py::test_get_dataset_lazy_behavior[False-False-True]
FAILED tests/test_datasets/test_dataset_functions.py::test_get_dataset_lazy_behavior[False-False-False]
FAILED tests/test_openml/test_api_calls.py::test_download_all_files_observes_cache
FAILED tests/test_runs/test_run.py::TestRun::test_offline_and_online_run_identical
FAILED tests/test_runs/test_run.py::TestRun::test_publish_with_local_loaded_flow
FAILED tests/test_runs/test_run.py::TestRun::test_tagging - AssertionError: T...
FAILED tests/test_runs/test_run.py::TestRun::test_to_from_filesystem_no_model
FAILED tests/test_runs/test_run.py::TestRun::test_to_from_filesystem_search
FAILED tests/test_runs/test_run.py::TestRun::test_to_from_filesystem_vanilla
FAILED tests/test_runs/test_run_functions.py::TestRun::test__run_exists - Val...
FAILED tests/test_runs/test_run_functions.py::TestRun::test__run_task_get_arffcontent
FAILED tests/test_runs/test_run_functions.py::TestRun::test_check_erronous_sklearn_flow_fails
FAILED tests/test_runs/test_run_functions.py::TestRun::test_delete_run - Valu...
FAILED tests/test_runs/test_run_functions.py::TestRun::test_format_prediction_classification_incomplete_probabilities
FAILED tests/test_runs/test_run_functions.py::TestRun::test_format_prediction_classification_no_probabilities
FAILED tests/test_runs/test_run_functions.py::TestRun::test_format_prediction_task_learning_curve_sample_not_set
FAILED tests/test_runs/test_run_functions.py::TestRun::test_format_prediction_task_without_classlabels_set
FAILED tests/test_runs/test_run_functions.py::TestRun::test_initialize_cv_from_run
FAILED tests/test_runs/test_run_functions.py::TestRun::test_initialize_model_from_run
FAILED tests/test_runs/test_run_functions.py::TestRun::test_learning_curve_task_1
FAILED tests/test_runs/test_run_functions.py::TestRun::test_learning_curve_task_2
FAILED tests/test_runs/test_run_functions.py::TestRun::test_local_run_metric_score
FAILED tests/test_runs/test_run_functions.py::TestRun::test_local_run_swapped_parameter_order_flow
FAILED tests/test_runs/test_run_functions.py::TestRun::test_local_run_swapped_parameter_order_model
FAILED tests/test_runs/test_run_functions.py::TestRun::test_run_flow_on_task_downloaded_flow
FAILED tests/test_runs/test_run_functions.py::TestRun::test_run_on_dataset_with_missing_labels_array
FAILED tests/test_runs/test_run_functions.py::TestRun::test_run_on_dataset_with_missing_labels_dataframe
FAILED tests/test_runs/test_run_functions.py::TestRun::test_run_regression_on_classif_task
FAILED tests/test_runs/test_run_functions.py::TestRun::test_run_with_illegal_flow_id
FAILED tests/test_runs/test_run_functions.py::TestRun::test_run_with_illegal_flow_id_1
FAILED tests/test_runs/test_run_functions.py::TestRun::test_run_with_illegal_flow_id_1_after_load
FAILED tests/test_runs/test_run_functions.py::TestRun::test_run_with_illegal_flow_id_after_load
FAILED tests/test_runs/test_run_functions.py::test__run_task_get_arffcontent_2
FAILED tests/test_runs/test_run_functions.py::test_joblib_backends[2-None-0]
FAILED tests/test_runs/test_run_functions.py::test_joblib_backends[-1-None-0]
FAILED tests/test_runs/test_run_functions.py::test_joblib_backends[1-None-10]
FAILED tests/test_runs/test_run_functions.py::test_joblib_backends[1-sequential-10]
FAILED tests/test_runs/test_run_functions.py::test_joblib_backends[1-threading-10]
FAILED tests/test_runs/test_run_functions.py::test_joblib_backends[-1-threading-10]
FAILED tests/test_setups/test_setup_functions.py::TestSetupFunctions::test_exisiting_setup_exists_2
FAILED tests/test_setups/test_setup_functions.py::TestSetupFunctions::test_existing_setup_exists_1
FAILED tests/test_setups/test_setup_functions.py::TestSetupFunctions::test_existing_setup_exists_3
FAILED tests/test_setups/test_setup_functions.py::TestSetupFunctions::test_setuplist_offset
FAILED tests/test_study/test_study_functions.py::TestStudyFunctions::test_publish_study
FAILED tests/test_study/test_study_functions.py::TestStudyFunctions::test_study_attach_illegal
FAILED tests/test_tasks/test_classification_task.py::OpenMLClassificationTaskTest::test_class_labels
FAILED tests/test_tasks/test_classification_task.py::OpenMLClassificationTaskTest::test_download_task
FAILED tests/test_tasks/test_classification_task.py::OpenMLClassificationTaskTest::test_get_X_and_Y
FAILED tests/test_tasks/test_classification_task.py::test_get_X_and_Y - Value...
FAILED tests/test_tasks/test_learning_curve_task.py::OpenMLLearningCurveTaskTest::test_class_labels
FAILED tests/test_tasks/test_learning_curve_task.py::OpenMLLearningCurveTaskTest::test_download_task
FAILED tests/test_tasks/test_learning_curve_task.py::OpenMLLearningCurveTaskTest::test_get_X_and_Y
FAILED tests/test_tasks/test_regression_task.py::OpenMLRegressionTaskTest::test_get_X_and_Y
FAILED tests/test_tasks/test_task_functions.py::TestTask::test_download_split
FAILED tests/test_tasks/test_task_functions.py::TestTask::test_get_task - Val...
FAILED tests/test_tasks/test_task_functions.py::TestTask::test_get_task_lazy
FAILED tests/test_tasks/test_task_functions.py::TestTask::test_get_task_with_cache
FAILED tests/test_tasks/test_task_methods.py::OpenMLTaskMethodsTest::test_tagging
FAILED tests/test_utils/test_utils.py::test_list_all_for_setups - assert 50 == 0
FAILED tests/test_utils/test_utils.py::test_list_all_for_runs - assert 21 == 0
FAILED tests/test_utils/test_utils.py::test_list_all_for_evaluations - assert...
FAILED tests/test_utils/test_utils.py::test_correct_test_server_download_state
= 87 failed, 246 passed, 24 skipped, 1 xfailed, 82 warnings, 5 rerun in 2466.74s (0:41:06) =
